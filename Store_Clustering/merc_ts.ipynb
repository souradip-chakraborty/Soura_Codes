{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import holidays\n",
    "from collections import Counter\n",
    "#from datetime import timedelta, date\n",
    "import statsmodels\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from statsmodels.formula.api import ols\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "\n",
    "from scipy.spatial.distance import euclidean\n",
    "import time\n",
    "#%matplotlib inline\n",
    "\n",
    "import lightgbm as lgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.read_csv('/Users/s0c02nj/Desktop/merch_ts/mode_imp_all.csv')\n",
    "x_test =  pd.read_csv('/Users/s0c02nj/Desktop/merch_ts/test_data_date.csv')\n",
    "#df_test = pd.read_excel('/Users/s0c02nj/Desktop/merch_ts/test_data.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To check if new stores are present or not in test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train['ind'] = 'tr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test['ind'] = 'te'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = x_train[['mds_fam_id','dc_nbr','date','dept_nbr','vendor_nm',\n",
    "                   'unit_cost','corp_retail_price','ind']]\n",
    "\n",
    "y_train = x_train[['actual_packs_order']]\n",
    "\n",
    "\n",
    "df_test = x_test[['mds_fam_id','dc_nbr','date','dept_nbr','vendor_nm',\n",
    "                   'unit_cost','corp_retail_price','ind']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total = pd.concat([df_train,df_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total['date'] = pd.to_datetime(df_total['date'])\n",
    "\n",
    "df_total['week'] =  df_total['date'].dt.week\n",
    "df_total['year'] =  df_total['date'].dt.year\n",
    "df_total['month'] = df_total['date'].dt.month\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total['mds_dc'] = df_total['mds_fam_id'].astype(str) + '_' + df_total['dc_nbr'].astype(str)\n",
    "df_total['dept_dc'] = df_total['dc_nbr'].astype(str) + '_' + df_total['dept_nbr'].astype(str)\n",
    "df_total['dept_mds'] = df_total['mds_fam_id'].astype(str) + '_' + df_total['dept_nbr'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train['dept_week'] = df_train['dept_nbr'].astype(str) + '_' + df_train['week'].astype(str)\n",
    "#df_train['dept_month'] = df_train['dept_nbr'].astype(str) + '_' + df_train['month'].astype(str)\n",
    "df_total['mds_week'] = df_total['mds_fam_id'].astype(str) + '_' + df_total['week'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_p1 = list(y_train['actual_packs_order'].values)\n",
    "y_p2 = [0]*x_test.shape[0]\n",
    "y_p = y_p1 + y_p2\n",
    "\n",
    "df_total['order'] = y_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train1 = df_total[df_total['ind'] == 'tr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['mds_fam_id',\n",
    "             'dc_nbr',\n",
    "             'dept_nbr',\n",
    "             'week',\n",
    "             'year',\n",
    "             'month',\n",
    "             'mds_dc',\n",
    "             'dept_dc',\n",
    "             'dept_mds',\n",
    "             'mds_week']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,col in tqdm(enumerate(cat_cols)):\n",
    "    med = df_train1.groupby(col)['order'].median()\n",
    "    df_total[str(col)+'count'+'1'] = df_total[col].map(med)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total1 = df_total.sort_values(by=['mds_dc','date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total1.index = range(0,len(df_total1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imp_cols = ['mds_fam_id','dc_nbr','date','dept_nbr','corp_retail_price',\n",
    "#             'mds_dc','dept_dc','dept_mds','mds_week','order','ind']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_md_dc = list(df_total1['mds_dc'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    \"\"\"\n",
    "    Frame a time series as a supervised learning dataset.\n",
    "    Arguments:\n",
    "        data: Sequence of observations as a list or NumPy array.\n",
    "        n_in: Number of lag observations as input (X).\n",
    "        n_out: Number of observations as output (y).\n",
    "        dropnan:Boolean whether or not to drop rows with NaN values.\n",
    "    Returns:\n",
    "        Pandas DataFrame of series framed for supervised learning.\n",
    "    \"\"\"\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = pd.DataFrame()\n",
    "\n",
    "\n",
    "x_t1 = df_total1\n",
    "\n",
    "for u_id in tqdm(unique_md_dc) :\n",
    "    \n",
    "    #Groupby\n",
    "    df_temp = x_t1[x_t1['mds_dc'] == u_id].sort_values(by='date')\n",
    "    #df_temp = df_temp.drop(['date'],axis=1)\n",
    "    #print (df_temp.head())\n",
    "    \n",
    "    #Adding Lag\n",
    "    df_temp = series_to_supervised(df_temp, n_in=13, n_out=1, dropnan = True)\n",
    "    df_temp.index = range(0,len(df_temp))\n",
    "    \n",
    "    #Appending\n",
    "    df_combined = pd.concat([df_combined,df_temp],axis=0)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined1 = df_combined[['var10(t-13)','var10(t-12)','var10(t-11)','var10(t-10)','var10(t-9)',\n",
    "                            'var10(t-8)','var10(t-7)','var10(t-6)','var10(t-5)','var10(t-4)',\n",
    "                            'var10(t-3)','var10(t-2)','var10(t-1)', \n",
    "                            'var1(t)','var2(t)', 'var3(t)', 'var4(t)', 'var5(t)', \n",
    "                            'var6(t)', 'var7(t)','var8(t)','var9(t)','var10(t)','var11(t)']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cols = []\n",
    "for i in range(0,len(list(df_combined1.columns))):\n",
    "    new_cols.append('x'+ str(i) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined1.columns = new_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_v1 = df_combined1[df_combined1['x23'] == 'tr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_v1 =  df_combined1[df_combined1['x23'] == 'te']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comb_tr = pd.DataFrame()\n",
    "df_comb_val = pd.DataFrame()\n",
    "\n",
    "\n",
    "x_t1 = df_train_v1\n",
    "\n",
    "for u_id in tqdm(unique_md_dc) :\n",
    "    \n",
    "    #Groupby\n",
    "    df_temp1 = x_t1[x_t1['x8'] == u_id].sort_values(by='x5')\n",
    "    df_temp1 = df_temp1.drop(['x5','x13'],axis=1)\n",
    "    \n",
    "    df_temp1.index = range(0,len(df_temp1))\n",
    "    \n",
    "    #Train-test split\n",
    "    df_temp_tr = df_temp1[0:int(df_temp1.shape[0]*0.99)]\n",
    "    df_temp_val = df_temp1[int(df_temp1.shape[0]*0.01):]\n",
    "    #print (df_temp.head())\n",
    "    \n",
    "    #Appending\n",
    "    df_comb_tr =  pd.concat([df_comb_tr,df_temp_tr],axis=0)\n",
    "    df_comb_val = pd.concat([df_comb_val,df_temp_val],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comb_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = df_comb_tr.drop(['x12'],axis=1)\n",
    "y_train = df_comb_tr['x12']\n",
    "\n",
    "x_val = df_comb_val.drop(['x12'],axis=1)\n",
    "y_val = df_comb_val['x12']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "le_cols = ['x8','x9','x10','x11']\n",
    "\n",
    "for col in tqdm(le_cols):\n",
    "    le = LabelEncoder()\n",
    "    le = le.fit(list(set(x_train[col])) + list(set(x_val[col])) + list(set(df_test_v1[col])))\n",
    "    \n",
    "    x_train[col] = le.transform(x_train[col])\n",
    "    x_val[col] = le.transform(x_val[col])\n",
    "    df_test_v1[col] = le.transform(df_test_v1[col])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy_model =  ols(formula='x12 ~ C(x0)+ C(x1) + C(x2)'\n",
    "#                   '+ C(x3)+C(x4)+C(x6)'\n",
    "#                   '+ C(x7)+C(x8)+C(x9)+C(x10)',\n",
    "#                    data= df_comb_tr).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': 'rmse',\n",
    "    'max_depth': 6, \n",
    "    'learning_rate': 0.1,\n",
    "    'verbose': 1, \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_train = lgb.Dataset(x_train, label = y_train)\n",
    "d_valid = lgb.Dataset(x_val, label = y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = lgb.train(params,\n",
    "                  d_train, \n",
    "                  n_estimators,\n",
    "                  valid_sets = [d_train, d_valid],\n",
    "                  early_stopping_rounds=500,\n",
    "                  verbose_eval=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preds = model.predict(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_val, num_iteration=model.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "r2 = r2_score(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = df_test_v1['x5'].iloc[0]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test_Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_v1 = df_test_v1.sort_values(by=['x8','x5'],ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_v1.index = range(0,len(df_test_v1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id = list(set(df_test_v1['x8']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_v1['x5'] = df_test_v1['x5'].apply(lambda x : x.strftime(\"%Y-%m-%d (%H:%M:%S.%f)\")[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_pred = {}\n",
    "\n",
    "\n",
    "\n",
    "for id_md in tqdm(test_id):\n",
    "    \n",
    "    temp1 = df_test_v1[df_test_v1['x8'] == id_md ]\n",
    "    list_dt = sorted(list(temp1['x5']))\n",
    "    \n",
    "    \n",
    "    for i in range(0,len(list_dt)):\n",
    "        \n",
    "        if i == 0:\n",
    "            temp2 = temp1[temp1['x5'] == list_dt[i]].drop(['x5','x12','x13'],axis=1)\n",
    "            pred = model.predict(temp2)[0]\n",
    "            dict_pred[(id_md,list_dt[i])] = pred\n",
    "        \n",
    "        elif i ==1 :\n",
    "            temp2 = temp1[temp1['x5'] == list_dt[i]].drop(['x5','x12','x13'],axis=1)\n",
    "            temp2['x2'] = dict_pred[(id_md,list_dt[i-1])]\n",
    "            pred = model.predict(temp2)[0]\n",
    "            dict_pred[(id_md,list_dt[i])] = pred\n",
    "        \n",
    "        elif i ==2 :\n",
    "            temp2 = temp1[temp1['x5'] == list_dt[i]].drop(['x5','x12','x13'],axis=1)\n",
    "            temp2['x2'] = dict_pred[(id_md,list_dt[i-1])]\n",
    "            temp2['x1'] = dict_pred[(id_md,list_dt[i-2])]\n",
    "            pred = model.predict(temp2)[0]\n",
    "            dict_pred[(id_md,list_dt[i])] = pred\n",
    "        \n",
    "        elif i >2 :\n",
    "            temp2 = temp1[temp1['x5'] == list_dt[i]].drop(['x5','x12','x13'],axis=1)\n",
    "            temp2['x2'] = dict_pred[(id_md,list_dt[i-1])]\n",
    "            temp2['x1'] = dict_pred[(id_md,list_dt[i-2])]\n",
    "            temp2['x0'] = dict_pred[(id_md,list_dt[i-3])]\n",
    "            pred = model.predict(temp2)[0]\n",
    "            dict_pred[(id_md,list_dt[i])] = pred\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#temp1 = df_test_v1[df_test_v1['x8'] == id_md ]\n",
    "#list_dt = sorted(list(temp1[temp1['x5']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = []\n",
    "\n",
    "for i in tqdm(range(0,len(df_test_v1))):\n",
    "    out = dict_pred[(df_test_v1['x8'].iloc[i],df_test_v1['x5'].iloc[i])]\n",
    "    test_pred.append(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_v1['output'] = test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le1= LabelEncoder()\n",
    "le1.fit(list(df_combined1['x8'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_test_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_v1['x8'] = le1.inverse_transform(df_test_v1['x8'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_pred2 = {}\n",
    "\n",
    "for i in tqdm(range(0,len(df_test_v1))):\n",
    "    id1 = df_test_v1['x8'].iloc[i]\n",
    "    dt = df_test_v1['x5'].iloc[i]\n",
    "    dict_pred2[(id1,dt)] = df_test_v1['output'].iloc[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-87b7629bd093>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfinal_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Users/s0c02nj/Downloads/validation_data.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "final_test = pd.read_csv('/Users/s0c02nj/Downloads/validation_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test['cal_date'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_temp = []\n",
    "for i in range(0,len(final_test)):\n",
    "    \n",
    "    id1 = final_test['mds_fam_id_dc_nbr'].iloc[i]\n",
    "    dt = final_test['cal_date'].iloc[i]\n",
    "    \n",
    "    p_temp.append(dict_pred2[(id1,dt)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test['pred'] = p_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_test.to_csv('/Users/s0c02nj/Desktop/merch_ts/final_test.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = sorted(list(df_test_v1[(df_test_v1['x8'] == 0)]['x5']))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = df_test_v1[(df_test_v1['x8'] == 0)&(df_test_v1['x5'] == '2019-08-10')].drop(['x5','x13','x12'],axis=1)\n",
    "a1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1['x2'] = 10\n",
    "a1['x1'] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p=pd.DataFrame(lag_y)\n",
    "# q =pd.DataFrame(lag_x)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['date'] = pd.to_datetime(df_train['date'])\n",
    "\n",
    "df_train['week'] =  df_train['date'].dt.week\n",
    "df_train['year'] =  df_train['date'].dt.year\n",
    "df_train['month'] = df_train['date'].dt.month\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select country\n",
    "us_holidays = holidays.US()\n",
    "\n",
    "df_train['holiday'] = df_train['date'].apply(lambda x: int(x in us_holidays))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['mds_dc'] = df_train['mds_fam_id'].astype(str) + '_' + df_train['dc_nbr'].astype(str)\n",
    "df_train['dept_dc'] = df_train['dc_nbr'].astype(str) + '_' + df_train['dept_nbr'].astype(str)\n",
    "df_train['dept_mds'] = df_train['mds_fam_id'].astype(str) + '_' + df_train['dept_nbr'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['dept_week'] = df_train['dept_nbr'].astype(str) + '_' + df_train['week'].astype(str)\n",
    "#df_train['dept_month'] = df_train['dept_nbr'].astype(str) + '_' + df_train['month'].astype(str)\n",
    "df_train['mds_week'] = df_train['mds_fam_id'].astype(str) + '_' + df_train['week'].astype(str)\n",
    "#df_train['dept_month'] = df_train['mds_fam_id'].astype(str) + '_' + df_train['month'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['order'] = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_md_dc = list(x_t1['mds_dc'].unique())\n",
    "unique_md_dc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = list(x_t1.columns)\n",
    "# cols = cols + ['date']\n",
    "#list(x_t1.columns)\n",
    "\n",
    "#cols = ['mds_fam_id','dc_nbr','dept_nbr','mds_dc','dept_dc','dept_mds','dept_week','mds_week','order','date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_combined = pd.DataFrame()\n",
    "# x_t1 = df_train[cols]\n",
    "\n",
    "# for u_id in tqdm(unique_md_dc) :\n",
    "    \n",
    "#     #Groupby\n",
    "#     df_temp = x_t1[x_t1['mds_dc'] == u_id].sort_values(by='date')\n",
    "#     df_temp = df_temp.drop(['date'],axis=1)\n",
    "#     #print (df_temp.head())\n",
    "    \n",
    "#     #Adding Lag\n",
    "#     df_temp = series_to_supervised(df_temp, n_in=3, n_out=1, dropnan = True)\n",
    "#     df_temp.index = range(0,len(df_temp))\n",
    "    \n",
    "#     #Appending\n",
    "#     df_combined = pd.concat([df_combined,df_temp],axis=0)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined1 = df_combined[['var9(t-3)','var9(t-2)','var9(t-1)', 'var1(t)','var2(t)', 'var3(t)', 'var4(t)', 'var5(t)', \n",
    "                            'var6(t)', 'var7(t)','var8(t)','var9(t)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_t1['order'] = y_train\n",
    "list(df_combined1.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cols = []\n",
    "for i in range(0,len(list(df_combined1.columns))):\n",
    "    new_cols.append('x'+ str(i) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined1.columns = new_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_model = ols(formula='x11 ~ C(x0)+C(x1)+C(x2)'\n",
    "                  '+ C(x3)+C(x4)+C(x5)'\n",
    "                  '+ C(x6)+C(x7)+C(x8)+C(x9)+C(x10)',\n",
    "                   data= df_combined1).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.distplot(dummy_model.resid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transition Matrix based approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df_train[(df_train['mds_fam_id'] == 105899148) & (df_train['dc_nbr'] == 6006)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.sort_values(by='wm_year_wk_nbr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_states = list(df1['actual_packs_order'])\n",
    "states = list(set(list_states))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "states_enc = le.fit_transform(states)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list_states_enc = le.transform(list_states)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#le.inverse_transform(states_enc-1)\n",
    "#list_states_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_transition_matrix(transitions,k):\n",
    "    \n",
    "    n = len(np.unique(transitions)) #number of states\n",
    "\n",
    "    M = [[0]*n for _ in range(n)]\n",
    "\n",
    "    for (i,j) in zip(transitions,transitions[k:]):\n",
    "        M[i-1][j-1] += 1\n",
    "\n",
    "    #now convert to probabilities:\n",
    "    for row in M:\n",
    "        s = sum(row)\n",
    "        if s > 0:\n",
    "            row[:] = [f/s for f in row]\n",
    "    return M\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transition Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_lag1 = np.array(step_transition_matrix(states_enc,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step_transition_matrix(x,3)\n",
    "#A_lag1\n",
    "A_lag1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No new stores are present"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time Series Analysis on Store Data ------> Temporal Part of the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_dc = list(df_train['dc_nbr'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_mds = list(df_train['mds_fam_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store1_data_analysis\n",
    "#df_s1 = df_train[(df_train['dc_nbr'] == 6042) & (df_train['mds_fam_id'] == 72389674)]\n",
    "df_s1 = df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_s1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['date_in'] = pd.to_datetime(df['date_in'])\n",
    "#df_sorted = df_s1.sort_values(by=['wm_year_wk_nbr'])\n",
    "df_sorted = df_s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_sorted = df_sorted.set_index('wm_year_wk_nbr')\n",
    "plt.plot(df_sorted['actual_packs_order'])\n",
    "#plt.xticks(rotation=70)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Time Series Testing\n",
    "timeseries = df_sorted['actual_packs_order'].values\n",
    "adfTest = adfuller(timeseries, autolag='AIC')\n",
    "adfTest[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "durbin_watson(timeseries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ The Durbin Watson test reports a test statistic, with a value from 0 to 4, where:\n",
    "+ 2 is no autocorrelation.\n",
    "+ 0 to <2 is positive autocorrelation (common in time series data).\n",
    "\n",
    "+ Durbin Watson Test of Serial Correlation indicates that their is serial correlation present in the observations \n",
    "+ and hence we will try to do regression with some independent variables to remove any significant effect\n",
    "\n",
    "In our case, the DW test statistic is near to zero which indicates there is significant impact of time in the above data \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseries = df_sorted['actual_packs_order'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler =  MinMaxScaler(feature_range=(0, 1))\n",
    "timeseries = scaler.fit_transform(np.reshape(timeseries,(-1,1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dividing into Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(timeseries) * 0.9)\n",
    "test_size = len(timeseries) - train_size\n",
    "train, test = timeseries[0:train_size,:], timeseries[train_size:len(timeseries),:]\n",
    "print(len(train), len(test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ The function takes two arguments: the dataset, \n",
    "+ which is a NumPy array that we want to convert into a dataset, \n",
    "+ and the look_back, which is the number of previous time steps \n",
    "+ to use as input variables to predict the next time period — in this case defaulted to 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset, look_back):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        a = dataset[i:(i+look_back), 0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back, 0])\n",
    "    return np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "look_back = 10\n",
    "trainX, trainY = create_dataset(train, look_back)\n",
    "testX, testY = create_dataset(test, look_back)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape input to be [samples, time steps, features]\n",
    "trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and fit the LSTM network\n",
    "model = Sequential()\n",
    "model.add(LSTM(2, input_shape=(1, look_back)))\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(trainX, trainY, epochs=100, batch_size=1, verbose=1,validation_split= 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions\n",
    "trainPredict = model.predict(trainX)\n",
    "testPredict = model.predict(testX)\n",
    "\n",
    "# # # invert predictions\n",
    "trainPredict = scaler.inverse_transform(np.reshape(trainPredict,(-1,1)))\n",
    "trainY = scaler.inverse_transform(np.reshape([trainY],(-1,1)))\n",
    "testPredict = scaler.inverse_transform(np.reshape(testPredict,(-1,1)))\n",
    "testY = scaler.inverse_transform(np.reshape([testY],(-1,1)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shift train predictions for plotting\n",
    "trainPredictPlot = np.empty_like(timeseries)\n",
    "trainPredictPlot[:, :] = np.nan\n",
    "trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n",
    "\n",
    "# shift test predictions for plotting\n",
    "testPredictPlot = np.empty_like(timeseries)\n",
    "testPredictPlot[:, :] = np.nan\n",
    "testPredictPlot[len(trainPredict)+(look_back*2)+1:len(timeseries)-1, :] = testPredict\n",
    "\n",
    "# plot baseline and predictions\n",
    "plt.plot(scaler.inverse_transform(timeseries))\n",
    "plt.plot(trainPredictPlot)\n",
    "#plt.xlim(600,690)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(scaler.inverse_transform(timeseries))\n",
    "plt.plot(testPredictPlot)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

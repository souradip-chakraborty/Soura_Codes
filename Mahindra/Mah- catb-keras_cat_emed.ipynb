{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\")\n",
    "np.random.seed(203)\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Model,Sequential\n",
    "from keras.layers import *\n",
    "from keras.callbacks import Callback, ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras import backend as K\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import RMSprop, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('/Users/s0c02nj/Desktop/Mahindra/train_5CLrC8b/train.csv')\n",
    "#data_dict = pd.read_csv('/Users/s0c02nj/Desktop/train_5CLrC8b/Data_Dictionary.xlsx')\n",
    "data_test = pd.read_csv('/Users/s0c02nj/Desktop/Mahindra/test.csv')\n",
    "data_sub = pd.read_csv('/Users/s0c02nj/Desktop/Mahindra/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_new = data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train data separating the response\n",
    "x_train = data_train_new.drop('amount_spent_per_room_night_scaled',axis=1)\n",
    "y_def =  data_train_new['amount_spent_per_room_night_scaled']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test data and train data merged for pre-processing\n",
    "x_comb = pd.concat([x_train,data_test],sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Missing value current\n",
    "+ season_holidayed_code        149\n",
    "+ state_code_residence        7024\n",
    "\n",
    "Replacing Missing values with 'unknown' token for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_comb = x_comb.replace(np.nan, 0.0, regex=True)\n",
    "#x_comb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_comb['season_holidayed_code'].fillna(x_comb['season_holidayed_code'].mode()[0], inplace=True)\n",
    "x_comb['state_code_residence'].fillna(x_comb['state_code_residence'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time Related features engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta, date\n",
    "x_comb['booking_date'] =  pd.to_datetime(x_comb['booking_date'], format='%d/%m/%y')\n",
    "x_comb['checkin_date'] =  pd.to_datetime(x_comb['checkin_date'], format= '%d/%m/%y')\n",
    "x_comb['checkout_date'] = pd.to_datetime(x_comb['checkout_date'],format= '%d/%m/%y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Duration stay\n",
    "x_comb['Duration_stay'] = x_comb['checkout_date'] - x_comb['checkin_date']\n",
    "x_comb['Duration_stay'] = x_comb['Duration_stay'].apply(lambda x:x.days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(488189, 24)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #Difference from booking date and checkin date\n",
    "# x_comb['diff1'] = x_comb['checkin_date'] - x_comb['booking_date']\n",
    "# x_comb['diff1'] = x_comb['diff1'].apply(lambda x:x.days)\n",
    "\n",
    "# #Difference from booking date and checkout date\n",
    "# x_comb['diff2'] = x_comb['checkout_date'] - x_comb['booking_date']\n",
    "# x_comb['diff2'] = x_comb['diff2'].apply(lambda x:x.days)\n",
    "x_comb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00,  8.53it/s]\n"
     ]
    }
   ],
   "source": [
    "#Date-time year for all the time variables\n",
    "cols =['booking_date','checkin_date','checkout_date']\n",
    "\n",
    "\n",
    "for i in tqdm(cols):\n",
    "    x_comb[i +' '+'month'] = x_comb[i].dt.month\n",
    "    x_comb[i +' '+'week'] =  x_comb[i].dt.week\n",
    "    x_comb[i +' '+'year'] =  x_comb[i].dt.year\n",
    "    x_comb[i +' '+'day'] =   x_comb[i].dt.day\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_comb = x_comb.drop(['booking_date','checkin_date','checkout_date'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['reservation_id', 'channel_code', 'main_product_code', 'numberofadults',\n",
       "       'numberofchildren', 'persontravellingid', 'resort_region_code',\n",
       "       'resort_type_code', 'room_type_booked_code', 'roomnights',\n",
       "       'season_holidayed_code', 'state_code_residence', 'state_code_resort',\n",
       "       'total_pax', 'member_age_buckets', 'booking_type_code', 'memberid',\n",
       "       'cluster_code', 'reservationstatusid_code', 'resort_id',\n",
       "       'Duration_stay', 'booking_date month', 'booking_date week',\n",
       "       'booking_date year', 'booking_date day', 'checkin_date month',\n",
       "       'checkin_date week', 'checkin_date year', 'checkin_date day',\n",
       "       'checkout_date month', 'checkout_date week', 'checkout_date year',\n",
       "       'checkout_date day'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_comb.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_cols = ['channel_code', 'main_product_code', 'numberofadults',\n",
    "       'numberofchildren',  'resort_region_code',\n",
    "       'resort_type_code', 'room_type_booked_code', 'roomnights',\n",
    "       'season_holidayed_code', 'state_code_residence', 'state_code_resort',\n",
    "       'total_pax', 'member_age_buckets', 'booking_type_code',\n",
    "       'cluster_code', 'reservationstatusid_code', 'resort_id',\n",
    "       'Duration_stay', 'booking_date month', 'booking_date week',\n",
    "       'booking_date year', 'booking_date day', 'checkin_date month',\n",
    "       'checkin_date week', 'checkin_date year', 'checkin_date day',\n",
    "       'checkout_date month', 'checkout_date week', 'checkout_date year',\n",
    "       'checkout_date day']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['channel_code', 'main_product_code',\n",
    "        'resort_region_code',\n",
    "       'resort_type_code', 'room_type_booked_code',\n",
    "       'season_holidayed_code', 'state_code_residence', 'state_code_resort',\n",
    "       'member_age_buckets', 'booking_type_code',\n",
    "       'cluster_code', 'reservationstatusid_code', 'resort_id',\n",
    "       'booking_date month', 'booking_date week',\n",
    "       'booking_date year', 'checkin_date month',\n",
    "       'checkin_date week', 'checkin_date year',\n",
    "       'checkout_date month', 'checkout_date week', 'checkout_date year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_cols = list(set(total_cols) - set(cat_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Duration_stay',\n",
       " 'numberofadults',\n",
       " 'numberofchildren',\n",
       " 'booking_date day',\n",
       " 'checkout_date day',\n",
       " 'checkin_date day',\n",
       " 'roomnights',\n",
       " 'total_pax']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cont_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_comb['roomnights'] = x_comb['roomnights'].replace(-45, 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 22/22 [00:00<00:00, 42.82it/s]\n"
     ]
    }
   ],
   "source": [
    "for col in tqdm(cat_cols):\n",
    "    le = LabelEncoder()\n",
    "    x_comb[col] = le.fit_transform(x_comb[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_comb = x_comb.drop(['reservation_id','persontravellingid','memberid'],axis=1)\n",
    "x_comb = x_comb.drop(['memberid'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = x_comb[0:341424]\n",
    "test_x =  x_comb[341424:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cat = train_x[cat_cols]\n",
    "test_cat = test_x[cat_cols]\n",
    "\n",
    "train_cont = train_x[cont_cols]\n",
    "test_cont = test_x[cont_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_data_cat(df):\n",
    "    \n",
    "    data=[]\n",
    "    for col in cat_cols:\n",
    "        data.append(df[col])\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_cat = get_train_test_data_cat(train_x)\n",
    "x_test_cat  = get_train_test_data_cat(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_comb = x_train_cat+[train_cont]\n",
    "x_test_comb = x_test_cat+ [test_cont]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_deep():\n",
    "    \n",
    "    layer_cat  = []\n",
    "    input_cat =  []\n",
    "    \n",
    "    #Categorical_var\n",
    "    for i,categoical_var in tqdm(enumerate((cat_cols))): \n",
    "        \n",
    "        no_of_unique_cat  = x_comb[categoical_var].nunique()\n",
    "        embedding_size = min(np.ceil((no_of_unique_cat)/2), 50 )\n",
    "        embedding_size = int(embedding_size)\n",
    "        \n",
    "        #Defining the input-----> branch_id\n",
    "        input_catg = Input(shape=(1,))\n",
    "        layer_catg =  Embedding(no_of_unique_cat+1 ,embedding_size,input_length=1,trainable=True)(input_catg)\n",
    "        layer_catg =  Flatten()(layer_catg)\n",
    "        layer_cat.append(layer_catg)\n",
    "        input_cat.append(input_catg)\n",
    "    \n",
    "    \n",
    "    #continuous var\n",
    "    input_cont = Input(shape=(8,))\n",
    "    layer_cont = Dense(5, activation='relu')(input_cont)\n",
    "        \n",
    "    #Merging\n",
    "    layer_comb =  layer_cat + [layer_cont]\n",
    "    layer_comb = concatenate(layer_comb)\n",
    "    \n",
    "    layer_dense = Dense(512, activation='relu')(layer_comb)\n",
    "    layer_dense = Dropout(0.5)(layer_dense)\n",
    "    \n",
    "    layer_dense = Dense(256, activation='relu')(layer_comb)\n",
    "    layer_dense = Dropout(0.5)(layer_dense)\n",
    "    \n",
    "    layer_dense = Dense(128, activation='relu')(layer_comb)\n",
    "    layer_dense = Dropout(0.5)(layer_dense)\n",
    "    \n",
    "    #Final output\n",
    "    layer_output = Dense(1,activation='relu')(layer_dense)\n",
    "    \n",
    "    #Comb_inpus\n",
    "    input_comb = input_cat + [input_cont]\n",
    "    \n",
    "    #Final model\n",
    "    model = Model(inputs= input_comb ,outputs=layer_output)\n",
    "    \n",
    "    return model\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22it [00:00, 34.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_72 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_73 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_74 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_75 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_76 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_77 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_78 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_79 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_80 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_81 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_82 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_83 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_84 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_85 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_86 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_87 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_88 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_89 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_90 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_91 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_92 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_93 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_69 (Embedding)        (None, 1, 2)         8           input_72[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_70 (Embedding)        (None, 1, 3)         18          input_73[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_71 (Embedding)        (None, 1, 2)         8           input_74[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_72 (Embedding)        (None, 1, 4)         32          input_75[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_73 (Embedding)        (None, 1, 3)         21          input_76[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_74 (Embedding)        (None, 1, 2)         10          input_77[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_75 (Embedding)        (None, 1, 19)        722         input_78[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_76 (Embedding)        (None, 1, 6)         72          input_79[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_77 (Embedding)        (None, 1, 5)         55          input_80[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_78 (Embedding)        (None, 1, 1)         3           input_81[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_79 (Embedding)        (None, 1, 3)         21          input_82[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_80 (Embedding)        (None, 1, 2)         10          input_83[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_81 (Embedding)        (None, 1, 16)        528         input_84[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_82 (Embedding)        (None, 1, 6)         78          input_85[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_83 (Embedding)        (None, 1, 27)        1458        input_86[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_84 (Embedding)        (None, 1, 3)         21          input_87[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_85 (Embedding)        (None, 1, 6)         78          input_88[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_86 (Embedding)        (None, 1, 27)        1458        input_89[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_87 (Embedding)        (None, 1, 3)         21          input_90[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_88 (Embedding)        (None, 1, 6)         78          input_91[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_89 (Embedding)        (None, 1, 27)        1458        input_92[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "embedding_90 (Embedding)        (None, 1, 3)         21          input_93[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_94 (InputLayer)           (None, 8)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_69 (Flatten)            (None, 2)            0           embedding_69[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_70 (Flatten)            (None, 3)            0           embedding_70[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_71 (Flatten)            (None, 2)            0           embedding_71[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_72 (Flatten)            (None, 4)            0           embedding_72[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_73 (Flatten)            (None, 3)            0           embedding_73[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_74 (Flatten)            (None, 2)            0           embedding_74[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_75 (Flatten)            (None, 19)           0           embedding_75[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_76 (Flatten)            (None, 6)            0           embedding_76[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_77 (Flatten)            (None, 5)            0           embedding_77[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_78 (Flatten)            (None, 1)            0           embedding_78[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_79 (Flatten)            (None, 3)            0           embedding_79[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_80 (Flatten)            (None, 2)            0           embedding_80[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_81 (Flatten)            (None, 16)           0           embedding_81[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_82 (Flatten)            (None, 6)            0           embedding_82[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_83 (Flatten)            (None, 27)           0           embedding_83[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_84 (Flatten)            (None, 3)            0           embedding_84[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_85 (Flatten)            (None, 6)            0           embedding_85[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_86 (Flatten)            (None, 27)           0           embedding_86[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_87 (Flatten)            (None, 3)            0           embedding_87[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_88 (Flatten)            (None, 6)            0           embedding_88[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_89 (Flatten)            (None, 27)           0           embedding_89[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_90 (Flatten)            (None, 3)            0           embedding_90[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 5)            45          input_94[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 181)          0           flatten_69[0][0]                 \n",
      "                                                                 flatten_70[0][0]                 \n",
      "                                                                 flatten_71[0][0]                 \n",
      "                                                                 flatten_72[0][0]                 \n",
      "                                                                 flatten_73[0][0]                 \n",
      "                                                                 flatten_74[0][0]                 \n",
      "                                                                 flatten_75[0][0]                 \n",
      "                                                                 flatten_76[0][0]                 \n",
      "                                                                 flatten_77[0][0]                 \n",
      "                                                                 flatten_78[0][0]                 \n",
      "                                                                 flatten_79[0][0]                 \n",
      "                                                                 flatten_80[0][0]                 \n",
      "                                                                 flatten_81[0][0]                 \n",
      "                                                                 flatten_82[0][0]                 \n",
      "                                                                 flatten_83[0][0]                 \n",
      "                                                                 flatten_84[0][0]                 \n",
      "                                                                 flatten_85[0][0]                 \n",
      "                                                                 flatten_86[0][0]                 \n",
      "                                                                 flatten_87[0][0]                 \n",
      "                                                                 flatten_88[0][0]                 \n",
      "                                                                 flatten_89[0][0]                 \n",
      "                                                                 flatten_90[0][0]                 \n",
      "                                                                 dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 128)          23296       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 128)          0           dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 1)            129         dropout_6[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 29,649\n",
      "Trainable params: 29,649\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model1 = model_deep()\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(y_pred - y_true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(loss=root_mean_squared_error, \n",
    "                   optimizer='Adam',\n",
    "                   metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 286796 samples, validate on 54628 samples\n",
      "Epoch 1/100\n",
      "286796/286796 [==============================] - 5s 18us/step - loss: 1.7659 - mean_squared_error: 3.8927 - val_loss: 1.1192 - val_mean_squared_error: 1.2556\n",
      "Epoch 2/100\n",
      "286796/286796 [==============================] - 4s 13us/step - loss: 1.3777 - mean_squared_error: 1.9006 - val_loss: 1.1085 - val_mean_squared_error: 1.2317\n",
      "Epoch 3/100\n",
      "286796/286796 [==============================] - 4s 13us/step - loss: 1.3335 - mean_squared_error: 1.7809 - val_loss: 1.0837 - val_mean_squared_error: 1.1777\n",
      "Epoch 4/100\n",
      "286796/286796 [==============================] - 4s 13us/step - loss: 1.2910 - mean_squared_error: 1.6691 - val_loss: 1.0774 - val_mean_squared_error: 1.1642\n",
      "Epoch 5/100\n",
      "286796/286796 [==============================] - 4s 13us/step - loss: 1.2598 - mean_squared_error: 1.5894 - val_loss: 1.0693 - val_mean_squared_error: 1.1470\n",
      "Epoch 6/100\n",
      "286796/286796 [==============================] - 4s 13us/step - loss: 1.2321 - mean_squared_error: 1.5204 - val_loss: 1.0745 - val_mean_squared_error: 1.1576\n",
      "Epoch 7/100\n",
      "286796/286796 [==============================] - 4s 14us/step - loss: 1.2048 - mean_squared_error: 1.4539 - val_loss: 1.0783 - val_mean_squared_error: 1.1658\n",
      "Epoch 8/100\n",
      "286796/286796 [==============================] - 4s 15us/step - loss: 1.1778 - mean_squared_error: 1.3895 - val_loss: 1.0694 - val_mean_squared_error: 1.1468\n",
      "Epoch 9/100\n",
      "286796/286796 [==============================] - 4s 16us/step - loss: 1.1529 - mean_squared_error: 1.3314 - val_loss: 1.0703 - val_mean_squared_error: 1.1487\n",
      "Epoch 10/100\n",
      "286796/286796 [==============================] - 4s 14us/step - loss: 1.1308 - mean_squared_error: 1.2807 - val_loss: 1.0646 - val_mean_squared_error: 1.1367\n",
      "Epoch 11/100\n",
      "286796/286796 [==============================] - 4s 12us/step - loss: 1.1077 - mean_squared_error: 1.2293 - val_loss: 1.0686 - val_mean_squared_error: 1.1451\n",
      "Epoch 12/100\n",
      "286796/286796 [==============================] - 4s 13us/step - loss: 1.0883 - mean_squared_error: 1.1865 - val_loss: 1.0679 - val_mean_squared_error: 1.1436\n",
      "Epoch 13/100\n",
      "286796/286796 [==============================] - 4s 12us/step - loss: 1.0705 - mean_squared_error: 1.1481 - val_loss: 1.0581 - val_mean_squared_error: 1.1232\n",
      "Epoch 14/100\n",
      "286796/286796 [==============================] - 4s 12us/step - loss: 1.0570 - mean_squared_error: 1.1196 - val_loss: 1.0573 - val_mean_squared_error: 1.1215\n",
      "Epoch 15/100\n",
      "286796/286796 [==============================] - 4s 12us/step - loss: 1.0444 - mean_squared_error: 1.0930 - val_loss: 1.0637 - val_mean_squared_error: 1.1346\n",
      "Epoch 16/100\n",
      "286796/286796 [==============================] - 4s 12us/step - loss: 1.0321 - mean_squared_error: 1.0673 - val_loss: 1.0565 - val_mean_squared_error: 1.1198\n",
      "Epoch 17/100\n",
      "286796/286796 [==============================] - 4s 13us/step - loss: 1.0230 - mean_squared_error: 1.0488 - val_loss: 1.0574 - val_mean_squared_error: 1.1215\n",
      "Epoch 18/100\n",
      "286796/286796 [==============================] - 604s 2ms/step - loss: 1.0146 - mean_squared_error: 1.0317 - val_loss: 1.0558 - val_mean_squared_error: 1.1184\n",
      "Epoch 19/100\n",
      "286796/286796 [==============================] - 4s 13us/step - loss: 1.0081 - mean_squared_error: 1.0183 - val_loss: 1.0545 - val_mean_squared_error: 1.1156\n",
      "Epoch 20/100\n",
      "286796/286796 [==============================] - 4s 14us/step - loss: 1.0017 - mean_squared_error: 1.0061 - val_loss: 1.0559 - val_mean_squared_error: 1.1184\n",
      "Epoch 21/100\n",
      "286796/286796 [==============================] - 5s 16us/step - loss: 0.9966 - mean_squared_error: 0.9954 - val_loss: 1.0527 - val_mean_squared_error: 1.1117\n",
      "Epoch 22/100\n",
      "286796/286796 [==============================] - 4s 14us/step - loss: 0.9925 - mean_squared_error: 0.9874 - val_loss: 1.0530 - val_mean_squared_error: 1.1126\n",
      "Epoch 23/100\n",
      "286796/286796 [==============================] - 4s 15us/step - loss: 0.9900 - mean_squared_error: 0.9824 - val_loss: 1.0534 - val_mean_squared_error: 1.1132\n",
      "Epoch 24/100\n",
      "286796/286796 [==============================] - 4s 13us/step - loss: 0.9880 - mean_squared_error: 0.9784 - val_loss: 1.0558 - val_mean_squared_error: 1.1181\n",
      "Epoch 25/100\n",
      "286796/286796 [==============================] - 4s 13us/step - loss: 0.9859 - mean_squared_error: 0.9742 - val_loss: 1.0532 - val_mean_squared_error: 1.1130\n",
      "Epoch 26/100\n",
      "286796/286796 [==============================] - 3s 12us/step - loss: 0.9846 - mean_squared_error: 0.9718 - val_loss: 1.0525 - val_mean_squared_error: 1.1114\n",
      "Epoch 27/100\n",
      "286796/286796 [==============================] - 4s 12us/step - loss: 0.9836 - mean_squared_error: 0.9696 - val_loss: 1.0541 - val_mean_squared_error: 1.1145\n",
      "Epoch 28/100\n",
      "286796/286796 [==============================] - 4s 13us/step - loss: 0.9831 - mean_squared_error: 0.9685 - val_loss: 1.0521 - val_mean_squared_error: 1.1108\n",
      "Epoch 29/100\n",
      "286796/286796 [==============================] - 4s 14us/step - loss: 0.9820 - mean_squared_error: 0.9665 - val_loss: 1.0513 - val_mean_squared_error: 1.1088\n",
      "Epoch 30/100\n",
      "286796/286796 [==============================] - 4s 13us/step - loss: 0.9820 - mean_squared_error: 0.9664 - val_loss: 1.0512 - val_mean_squared_error: 1.1087\n",
      "Epoch 31/100\n",
      "286796/286796 [==============================] - 4s 13us/step - loss: 0.9806 - mean_squared_error: 0.9639 - val_loss: 1.0527 - val_mean_squared_error: 1.1117\n",
      "Epoch 32/100\n",
      "286796/286796 [==============================] - 4s 13us/step - loss: 0.9804 - mean_squared_error: 0.9635 - val_loss: 1.0543 - val_mean_squared_error: 1.1149\n",
      "Epoch 33/100\n",
      "286796/286796 [==============================] - 4s 13us/step - loss: 0.9794 - mean_squared_error: 0.9616 - val_loss: 1.0510 - val_mean_squared_error: 1.1083\n",
      "Epoch 34/100\n",
      "286796/286796 [==============================] - 4s 14us/step - loss: 0.9797 - mean_squared_error: 0.9621 - val_loss: 1.0509 - val_mean_squared_error: 1.1080\n",
      "Epoch 35/100\n",
      "286796/286796 [==============================] - 3s 12us/step - loss: 0.9794 - mean_squared_error: 0.9618 - val_loss: 1.0508 - val_mean_squared_error: 1.1080\n",
      "Epoch 36/100\n",
      "286796/286796 [==============================] - 4s 12us/step - loss: 0.9790 - mean_squared_error: 0.9608 - val_loss: 1.0532 - val_mean_squared_error: 1.1127\n",
      "Epoch 37/100\n",
      "286796/286796 [==============================] - 3s 12us/step - loss: 0.9781 - mean_squared_error: 0.9591 - val_loss: 1.0515 - val_mean_squared_error: 1.1091\n",
      "Epoch 38/100\n",
      "286796/286796 [==============================] - 3s 12us/step - loss: 0.9782 - mean_squared_error: 0.9592 - val_loss: 1.0505 - val_mean_squared_error: 1.1073\n",
      "Epoch 39/100\n",
      "286796/286796 [==============================] - 3s 12us/step - loss: 0.9781 - mean_squared_error: 0.9590 - val_loss: 1.0508 - val_mean_squared_error: 1.1077\n",
      "Epoch 40/100\n",
      "286796/286796 [==============================] - 3s 12us/step - loss: 0.9777 - mean_squared_error: 0.9580 - val_loss: 1.0506 - val_mean_squared_error: 1.1073\n",
      "Epoch 41/100\n",
      "286796/286796 [==============================] - 3s 12us/step - loss: 0.9774 - mean_squared_error: 0.9576 - val_loss: 1.0511 - val_mean_squared_error: 1.1084\n",
      "Epoch 42/100\n",
      "286796/286796 [==============================] - 3s 12us/step - loss: 0.9770 - mean_squared_error: 0.9568 - val_loss: 1.0513 - val_mean_squared_error: 1.1090\n",
      "Epoch 43/100\n",
      "286796/286796 [==============================] - 4s 12us/step - loss: 0.9763 - mean_squared_error: 0.9557 - val_loss: 1.0516 - val_mean_squared_error: 1.1095\n",
      "Epoch 44/100\n",
      "286796/286796 [==============================] - 4s 12us/step - loss: 0.9764 - mean_squared_error: 0.9557 - val_loss: 1.0517 - val_mean_squared_error: 1.1095\n",
      "Epoch 45/100\n",
      "286796/286796 [==============================] - 3s 12us/step - loss: 0.9766 - mean_squared_error: 0.9562 - val_loss: 1.0513 - val_mean_squared_error: 1.1088\n",
      "Epoch 46/100\n",
      "286796/286796 [==============================] - 3s 12us/step - loss: 0.9762 - mean_squared_error: 0.9550 - val_loss: 1.0510 - val_mean_squared_error: 1.1084\n",
      "Epoch 47/100\n",
      "286796/286796 [==============================] - 3s 11us/step - loss: 0.9763 - mean_squared_error: 0.9554 - val_loss: 1.0516 - val_mean_squared_error: 1.1095\n",
      "Epoch 48/100\n",
      "286796/286796 [==============================] - 3s 12us/step - loss: 0.9756 - mean_squared_error: 0.9540 - val_loss: 1.0515 - val_mean_squared_error: 1.1093\n",
      "Epoch 49/100\n",
      "286796/286796 [==============================] - 3s 12us/step - loss: 0.9753 - mean_squared_error: 0.9536 - val_loss: 1.0512 - val_mean_squared_error: 1.1087\n",
      "Epoch 50/100\n",
      "286796/286796 [==============================] - 4s 13us/step - loss: 0.9752 - mean_squared_error: 0.9532 - val_loss: 1.0513 - val_mean_squared_error: 1.1089\n",
      "Epoch 51/100\n",
      "286796/286796 [==============================] - 4s 13us/step - loss: 0.9748 - mean_squared_error: 0.9528 - val_loss: 1.0507 - val_mean_squared_error: 1.1077\n",
      "Epoch 52/100\n",
      "286796/286796 [==============================] - 4s 14us/step - loss: 0.9742 - mean_squared_error: 0.9516 - val_loss: 1.0507 - val_mean_squared_error: 1.1078\n",
      "Epoch 53/100\n",
      "286796/286796 [==============================] - 4s 13us/step - loss: 0.9744 - mean_squared_error: 0.9514 - val_loss: 1.0508 - val_mean_squared_error: 1.1078\n",
      "Epoch 54/100\n",
      "286796/286796 [==============================] - 3s 12us/step - loss: 0.9737 - mean_squared_error: 0.9505 - val_loss: 1.0513 - val_mean_squared_error: 1.1089\n",
      "Epoch 55/100\n",
      "286796/286796 [==============================] - 4s 12us/step - loss: 0.9738 - mean_squared_error: 0.9505 - val_loss: 1.0520 - val_mean_squared_error: 1.1102\n",
      "Epoch 56/100\n",
      "286796/286796 [==============================] - 4s 12us/step - loss: 0.9735 - mean_squared_error: 0.9505 - val_loss: 1.0532 - val_mean_squared_error: 1.1125\n",
      "Epoch 57/100\n",
      "286796/286796 [==============================] - 4s 12us/step - loss: 0.9733 - mean_squared_error: 0.9497 - val_loss: 1.0532 - val_mean_squared_error: 1.1125\n",
      "Epoch 58/100\n",
      "286796/286796 [==============================] - 4s 13us/step - loss: 0.9726 - mean_squared_error: 0.9484 - val_loss: 1.0511 - val_mean_squared_error: 1.1087\n",
      "Epoch 59/100\n",
      "286796/286796 [==============================] - 4s 12us/step - loss: 0.9726 - mean_squared_error: 0.9484 - val_loss: 1.0525 - val_mean_squared_error: 1.1112\n",
      "Epoch 60/100\n",
      "286796/286796 [==============================] - 4s 13us/step - loss: 0.9727 - mean_squared_error: 0.9482 - val_loss: 1.0517 - val_mean_squared_error: 1.1097\n",
      "Epoch 61/100\n",
      "286796/286796 [==============================] - 3s 12us/step - loss: 0.9721 - mean_squared_error: 0.9472 - val_loss: 1.0516 - val_mean_squared_error: 1.1095\n",
      "Epoch 62/100\n",
      "286796/286796 [==============================] - 3s 12us/step - loss: 0.9723 - mean_squared_error: 0.9476 - val_loss: 1.0517 - val_mean_squared_error: 1.1097\n",
      "Epoch 63/100\n",
      "286796/286796 [==============================] - 3s 12us/step - loss: 0.9720 - mean_squared_error: 0.9471 - val_loss: 1.0526 - val_mean_squared_error: 1.1116\n",
      "Epoch 64/100\n",
      "286796/286796 [==============================] - 4s 13us/step - loss: 0.9720 - mean_squared_error: 0.9470 - val_loss: 1.0514 - val_mean_squared_error: 1.1092\n",
      "Epoch 65/100\n",
      "286796/286796 [==============================] - 4s 12us/step - loss: 0.9719 - mean_squared_error: 0.9468 - val_loss: 1.0535 - val_mean_squared_error: 1.1133\n",
      "Epoch 66/100\n",
      "286796/286796 [==============================] - 4s 13us/step - loss: 0.9717 - mean_squared_error: 0.9463 - val_loss: 1.0515 - val_mean_squared_error: 1.1096\n",
      "Epoch 67/100\n",
      "286796/286796 [==============================] - 3s 12us/step - loss: 0.9718 - mean_squared_error: 0.9468 - val_loss: 1.0522 - val_mean_squared_error: 1.1110\n",
      "Epoch 68/100\n",
      "286796/286796 [==============================] - 3s 12us/step - loss: 0.9716 - mean_squared_error: 0.9461 - val_loss: 1.0517 - val_mean_squared_error: 1.1099\n",
      "Epoch 69/100\n",
      "286796/286796 [==============================] - 3s 12us/step - loss: 0.9711 - mean_squared_error: 0.9455 - val_loss: 1.0520 - val_mean_squared_error: 1.1103\n",
      "Epoch 70/100\n",
      "286796/286796 [==============================] - 4s 13us/step - loss: 0.9713 - mean_squared_error: 0.9455 - val_loss: 1.0521 - val_mean_squared_error: 1.1107\n",
      "Epoch 71/100\n",
      "286796/286796 [==============================] - 3s 12us/step - loss: 0.9711 - mean_squared_error: 0.9456 - val_loss: 1.0525 - val_mean_squared_error: 1.1113\n",
      "Epoch 72/100\n",
      "286796/286796 [==============================] - 4s 13us/step - loss: 0.9708 - mean_squared_error: 0.9446 - val_loss: 1.0532 - val_mean_squared_error: 1.1128\n",
      "Epoch 73/100\n",
      "286796/286796 [==============================] - 4s 13us/step - loss: 0.9704 - mean_squared_error: 0.9436 - val_loss: 1.0530 - val_mean_squared_error: 1.1126\n",
      "Epoch 74/100\n",
      "286796/286796 [==============================] - 3s 11us/step - loss: 0.9706 - mean_squared_error: 0.9444 - val_loss: 1.0536 - val_mean_squared_error: 1.1137\n",
      "Epoch 75/100\n",
      "286796/286796 [==============================] - 3s 12us/step - loss: 0.9705 - mean_squared_error: 0.9439 - val_loss: 1.0542 - val_mean_squared_error: 1.1149\n",
      "Epoch 76/100\n",
      "286796/286796 [==============================] - 4s 13us/step - loss: 0.9705 - mean_squared_error: 0.9440 - val_loss: 1.0535 - val_mean_squared_error: 1.1138\n",
      "Epoch 77/100\n",
      "286796/286796 [==============================] - 3s 12us/step - loss: 0.9702 - mean_squared_error: 0.9435 - val_loss: 1.0554 - val_mean_squared_error: 1.1173\n",
      "Epoch 78/100\n",
      "286796/286796 [==============================] - 3s 12us/step - loss: 0.9699 - mean_squared_error: 0.9428 - val_loss: 1.0541 - val_mean_squared_error: 1.1146\n",
      "Epoch 79/100\n",
      "286796/286796 [==============================] - 3s 12us/step - loss: 0.9698 - mean_squared_error: 0.9426 - val_loss: 1.0543 - val_mean_squared_error: 1.1154\n",
      "Epoch 80/100\n",
      "286796/286796 [==============================] - 3s 12us/step - loss: 0.9694 - mean_squared_error: 0.9419 - val_loss: 1.0533 - val_mean_squared_error: 1.1130\n",
      "Epoch 81/100\n",
      "286796/286796 [==============================] - 3s 12us/step - loss: 0.9693 - mean_squared_error: 0.9417 - val_loss: 1.0545 - val_mean_squared_error: 1.1157\n",
      "Epoch 82/100\n",
      "286796/286796 [==============================] - 3s 11us/step - loss: 0.9695 - mean_squared_error: 0.9421 - val_loss: 1.0548 - val_mean_squared_error: 1.1162\n",
      "Epoch 83/100\n",
      "286796/286796 [==============================] - 4s 13us/step - loss: 0.9696 - mean_squared_error: 0.9421 - val_loss: 1.0554 - val_mean_squared_error: 1.1175\n",
      "Epoch 84/100\n",
      "286796/286796 [==============================] - 4s 12us/step - loss: 0.9690 - mean_squared_error: 0.9410 - val_loss: 1.0538 - val_mean_squared_error: 1.1144\n",
      "Epoch 85/100\n",
      "286796/286796 [==============================] - 4s 13us/step - loss: 0.9688 - mean_squared_error: 0.9407 - val_loss: 1.0550 - val_mean_squared_error: 1.1167\n",
      "Epoch 86/100\n",
      "286796/286796 [==============================] - 4s 13us/step - loss: 0.9685 - mean_squared_error: 0.9401 - val_loss: 1.0545 - val_mean_squared_error: 1.1157\n",
      "Epoch 87/100\n",
      "286796/286796 [==============================] - 4s 14us/step - loss: 0.9689 - mean_squared_error: 0.9409 - val_loss: 1.0533 - val_mean_squared_error: 1.1132\n",
      "Epoch 88/100\n",
      "286796/286796 [==============================] - 4s 15us/step - loss: 0.9681 - mean_squared_error: 0.9396 - val_loss: 1.0536 - val_mean_squared_error: 1.1138\n",
      "Epoch 89/100\n",
      "286796/286796 [==============================] - 5s 17us/step - loss: 0.9683 - mean_squared_error: 0.9397 - val_loss: 1.0534 - val_mean_squared_error: 1.1134\n",
      "Epoch 90/100\n",
      "286796/286796 [==============================] - 5s 17us/step - loss: 0.9682 - mean_squared_error: 0.9394 - val_loss: 1.0533 - val_mean_squared_error: 1.1131\n",
      "Epoch 91/100\n",
      "286796/286796 [==============================] - 5s 17us/step - loss: 0.9685 - mean_squared_error: 0.9400 - val_loss: 1.0533 - val_mean_squared_error: 1.1131\n",
      "Epoch 92/100\n",
      "215552/286796 [=====================>........] - ETA: 1s - loss: 0.9684 - mean_squared_error: 0.9400"
     ]
    }
   ],
   "source": [
    "history = model1.fit(x_train_comb,y_train,\n",
    "                         batch_size = 512, \n",
    "                         epochs = 100, \n",
    "                         validation_split=0.16, \n",
    "                         verbose = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model1.predict(x_test_comb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sub['amount_spent_per_room_night_scaled']=pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sub.to_csv('/Users/s0c02nj/Desktop/Mahindra/Sub_cat7.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

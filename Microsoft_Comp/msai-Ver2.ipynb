{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, Flatten\n",
    "from keras.layers import Embedding\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.models import Sequential, model_from_json\n",
    "from keras.layers import Dense, LSTM, Dropout, Bidirectional, merge\n",
    "from keras.layers.convolutional import Convolution1D, MaxPooling1D\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from IPython.display import SVG\n",
    "#from keras.utils.visualize_util import model_to_dot\n",
    "#import wikipedia\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from multiprocessing import Pool\n",
    "\n",
    "#from mlutils import dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import Ridge\n",
    "import numpy as np\n",
    "import sklearn.datasets\n",
    "#import sklearn.cross_validation\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import os, sys, re, csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from difflib import SequenceMatcher\n",
    "import math\n",
    "from datetime import datetime\n",
    "#from nltk.tokenize import word_tokenize\n",
    "from itertools import product\n",
    "\n",
    "import time \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from multiprocessing import Pool\n",
    "\n",
    "\n",
    "from scipy.spatial.distance import cosine, cityblock, jaccard, canberra, euclidean, minkowski, braycurtis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Data\n",
    "df_train = pd.read_csv('/Users/s0c02nj/Desktop/Personal Edu doc/Competitions /Microsoft/data/data.tsv', \n",
    "                       delimiter=\"\\t\",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test Data\n",
    "df_test = pd.read_csv('/Users/s0c02nj/Desktop/Personal Edu doc/Competitions /Microsoft/data/eval1_unlabelled.tsv',\n",
    "                      delimiter=\"\\t\",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.columns = [\"id\", \"question\", \"answer\", \"is_ans\", \"seq_no\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>is_ans</th>\n",
       "      <th>seq_no</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>131</td>\n",
       "      <td>. what is a corporation?</td>\n",
       "      <td>A company is incorporated in a specific nation...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>131</td>\n",
       "      <td>. what is a corporation?</td>\n",
       "      <td>Today, there is a growing community of more th...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>131</td>\n",
       "      <td>. what is a corporation?</td>\n",
       "      <td>Corporation definition, an association of indi...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>131</td>\n",
       "      <td>. what is a corporation?</td>\n",
       "      <td>Examples of corporation in a Sentence. 1  He w...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                  question  \\\n",
       "0  131  . what is a corporation?   \n",
       "1  131  . what is a corporation?   \n",
       "2  131  . what is a corporation?   \n",
       "3  131  . what is a corporation?   \n",
       "\n",
       "                                              answer  is_ans  seq_no  \n",
       "0  A company is incorporated in a specific nation...       0       0  \n",
       "1  Today, there is a growing community of more th...       0       1  \n",
       "2  Corporation definition, an association of indi...       0       2  \n",
       "3  Examples of corporation in a Sentence. 1  He w...       0       3  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cosine(str1, str2):\n",
    "    \n",
    "    #Counter forms a dictionary----> Frequency of words as values and key is the word\n",
    "    vec1 = Counter(str1.split())\n",
    "    vec2 = Counter(str2.split())\n",
    "    \n",
    "    #Intersection contains the set of common words\n",
    "    intersection = set(vec1.keys()) & set(vec2.keys())\n",
    "    \n",
    "    #W1W2W2=[1,2,3] and W1W2W3=[2,4,6] ,it finds the a.b value\n",
    "    numerator = sum([vec1[x] * vec2[x] for x in intersection])\n",
    "\n",
    "    #|a| and |b| are computed through the process\n",
    "    sum1 = sum([vec1[x]**2 for x in vec1.keys()])\n",
    "    sum2 = sum([vec2[x]**2 for x in vec2.keys()])\n",
    "    denominator = math.sqrt(sum1) * math.sqrt(sum2)\n",
    "\n",
    "    #cosine value is computed\n",
    "    if not denominator:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return float(numerator) / denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DistJaccard(str1, str2):\n",
    "    str1 = set(str1.split())\n",
    "    str2 = set(str2.split())\n",
    "    #a_intersection_b ---unique\n",
    "    numerator = len(str1 & str2)\n",
    "    #a_union_b---unique\n",
    "    denominator = len(str1 | str2)\n",
    "    if not denominator:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return float(numerator) / denominator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shared_2gram(q1, q2):\n",
    "    #zip will combine the first doc with the second doc element by element\n",
    "    q1_2gram = set([i for i in zip(q1.split(), q1.split()[1:])])\n",
    "    q2_2gram = set([i for i in zip(q2.split(), q2.split()[1:])])\n",
    "    shared_2gram = q1_2gram.intersection(q2_2gram)\n",
    "    if len(q1_2gram)==0 or len(q2_2gram) == 0:\n",
    "        return 0\n",
    "    return len(shared_2gram)*2.0/(len(q1_2gram) + len(q2_2gram))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shared_3gram(q1, q2):\n",
    "    q1_3gram = set([i for i in zip(q1.split(), q1.split()[1:], q1.split()[2:])])\n",
    "    q2_3gram = set([i for i in zip(q2.split(), q2.split()[1:], q2.split()[2:])])\n",
    "    shared_3gram = q1_3gram.intersection(q2_3gram)\n",
    "    if len(q1_3gram)==0 or len(q2_3gram) == 0:\n",
    "        return 0\n",
    "    return len(shared_3gram)*1.0/(len(q1_3gram) + len(q2_3gram))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def worker(data):\n",
    "    cosine_sim, jaccard_sim, shared_2gram_sim, shared_3gram_sim = np.zeros((len(data), )), np.zeros((len(data), )), np.zeros((len(data), )), np.zeros((len(data), ))\n",
    "    #print '*'*50\n",
    "    for i in range(0,len(data)):\n",
    "        d=data.iloc[i]\n",
    "        cosine_sim[i] =   get_cosine(str(d[1]), str(d[2]))\n",
    "        #abb_desc_sim[i] = get_desc_sim(str(d[1]), str(d[2]))\n",
    "        jaccard_sim[i] =  DistJaccard(str(d[1]), str(d[2]))\n",
    "        shared_2gram_sim[i] = shared_2gram(str(d[1]), str(d[2]))\n",
    "        shared_3gram_sim[i] = shared_3gram(str(d[1]), str(d[2]))\n",
    "    result = pd.DataFrame()\n",
    "    result['cosine'] = pd.Series(list(cosine_sim))\n",
    "    result['jaccard'] = pd.Series(list(jaccard_sim))\n",
    "    result['shared_2gram'] = pd.Series(list(shared_2gram_sim))\n",
    "    result['shared_3gram'] = pd.Series(list(shared_3gram_sim))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallelize_dataframe(df, func):\n",
    "    df_split = np.array_split(df, num_partitions)\n",
    "    pool = Pool(n_cores)\n",
    "    df = pd.concat(pool.map(func, df_split))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "t1=time.time()\n",
    "num_partitions = 16\n",
    "n_cores=8\n",
    "dist_df = parallelize_dataframe(df_train, worker)\n",
    "t2=time.time()\n",
    "\n",
    "print t2-t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_feat=dist_df\n",
    "y=df_train['is_ans']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_feat.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(x_feat[y==0]['cosine'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(x_feat[y==1]['cosine'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(x_feat[y==0]['jaccard'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(x_feat[y==1]['jaccard'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(x_feat[y==0]['shared_2gram'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(x_feat[y==1]['shared_2gram'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(x_feat[y==0]['shared_3gram'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(x_feat[y==1]['shared_3gram'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding the Sentiment part"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1.Vader takes into account exclaimation mark\n",
    "2.Vader takes into account Capital letters\n",
    "3.Vader takes into account smileys\n",
    "4.Vader takes into account context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyser = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_sentiment_scores(sentence):\n",
    "    snt = analyser.polarity_scores(sentence)\n",
    "    print(\"{:-<40} {}\".format(sentence, str(snt)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The food is bad------------------------- {'neg': 0.538, 'neu': 0.462, 'pos': 0.0, 'compound': -0.5423}\n"
     ]
    }
   ],
   "source": [
    "print_sentiment_scores('The food is bad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "        \"objective\" : \"regression\",\n",
    "        \"metric\" : \"rmse\", \n",
    "        \"num_leaves\" : 10,\n",
    "        \"min_child_samples\" : 100,\n",
    "        \"n_estimators\":1000,\n",
    "        \"learning_rate\" : 0.03,\n",
    "        \"bagging_fraction\" : 0.7,\n",
    "        \"feature_fraction\" : 0.5,\n",
    "        \"bagging_frequency\" : 5,\n",
    "        \"bagging_seed\" : 2018,\n",
    "        \"subsample\" : .9,\n",
    "        \"colsample_bytree\": .9,\n",
    "        \"verbosity\" : -1,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgtrain = lgb.Dataset(x_train, label=y_train)\n",
    "lgb_model = lgb.train(params, lgtrain,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob=lgb_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.true_divide(len(x_train[y==1]),len(x_train[y==0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred_prob[0:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEST PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.columns = [\"id\", \"question\", \"answer\", \"seq_no\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "t1=time.time()\n",
    "num_partitions = 16\n",
    "n_cores=7\n",
    "dist_df_test = parallelize_dataframe(df_test, worker)\n",
    "t2=time.time()\n",
    "\n",
    "print t2-t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=lgb_model.predict(dist_df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scores = {}\n",
    "i=-1\n",
    "for qid, pred in zip(df_test['id'], predictions):\n",
    "        i=i+1\n",
    "        all_scores[qid] = predictions[0+i:10+i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(all_scores.keys())\n",
    "all_scores = {}\n",
    " \n",
    "for qid, pred in zip(df_test['id'], predictions):\n",
    "   \n",
    "    if qid in all_scores:\n",
    "        all_scores[qid].append(pred)\n",
    "    else:\n",
    "        all_scores[qid] = [pred]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submissionFileName = \"answer2.tsv\"\n",
    "fw = open(submissionFileName, \"w\")\n",
    " \n",
    "for query_id in all_scores:\n",
    "    scores = all_scores[query_id]\n",
    "    scores_str = [str(sc) for sc in scores] # convert all scores to string values\n",
    "    scores_str = \"\\t\".join(scores_str) # join all scores in list to make it one string with  tab delimiter. \n",
    "    fw.write(str(query_id)+\"\\t\"+scores_str+\"\\n\")\n",
    "fw.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.google_search_results import GoogleSearchResults\n",
    "query = GoogleSearchResults({\"q\":\"what is a corporate\"})\n",
    "json_results = query.get_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "#json_results\n",
    "# a=json_results['organic_results'][0]['snippet']\n",
    "# a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 4000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "#json_results['knowledge_graph']['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'The symptoms are similar but the mouse will be in much worse condition: runny eyes. sneezing. wheezing. shaking. fluctuating body temperature. tiredness. loss of appetite. dull coat.'"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=json_results['organic_results'][0]['snippet']\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=json_results['organic_results'][1]['snippet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u\"The symptoms are similar but the mouse will be in much worse condition: runny eyes. sneezing. wheezing. shaking. fluctuating body temperature. tiredness. loss of appetite. dull coat.Mice can become unwell and go downhill quickly, but may often only show subtle signs of being in pain/distress/suffering, until it's very severe. Pain/distress/suffering can usually be indicated by behavioural changes. Taking to a vet immediately if showing signs of illness.\""
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-f71000c76a0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'answer'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_train' is not defined"
     ]
    }
   ],
   "source": [
    "df_train.iloc[15]['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_feat, y, test_size=0.05, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log_model = LogisticRegression(random_state=0)\n",
    "log_model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_model.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print (recall_score(y_test, log_model.predict(x_test)))\n",
    "#print (precision_score(y_test, log_model.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=log_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

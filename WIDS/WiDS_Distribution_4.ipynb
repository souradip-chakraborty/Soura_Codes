{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import metrics, preprocessing\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from catboost import Pool, CatBoostClassifier\n",
    "import lightgbm as lgb\n",
    "import seaborn as sns\n",
    "#from itertools import izip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing\n",
    "train_data = pd.read_csv('/Users/s0c02nj/Desktop/OneDrive - Walmart Inc/WiDS/training_v2.csv')\n",
    "test_data =  pd.read_csv('/Users/s0c02nj/Desktop/OneDrive - Walmart Inc/WiDS/unlabeled.csv')\n",
    "\n",
    "sub_data =  pd.read_csv('/Users/s0c02nj/Desktop/OneDrive - Walmart Inc/WiDS/samplesubmission.csv')\n",
    "data_dict = pd.read_csv('/Users/s0c02nj/Desktop/OneDrive - Walmart Inc/WiDS/WiDS Datathon 2020 Dictionary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data.groupby('hospital_death').hist()\n",
    "#list_plot = list(np.arange(169,173))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = train_data.iloc[:,list_plot]\n",
    "# df['hospital_death'] = train_data['hospital_death']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.groupby('hospital_death').hist()\n",
    "#train_data[['height','hospital_death']].groupby('hospital_death').hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_classt(x): \n",
    "    if pd.isna(x):\n",
    "        return np.nan\n",
    "    elif x < 15: \n",
    "        return 'very severely underweight' \n",
    "    elif x >= 15 and x < 16: \n",
    "        return 'severely weight' \n",
    "    elif x >=16 and x < 18.5: \n",
    "        return 'underweight' \n",
    "    elif x >= 18.5 and x < 25: \n",
    "        return 'healthy weight' \n",
    "    elif x >= 25 and x < 30: \n",
    "        return 'overweight'\n",
    "    elif x >= 30 and x < 35: \n",
    "        return 'class 1' \n",
    "    elif x >= 35 and x < 40: \n",
    "        return 'class 2' \n",
    "    else: \n",
    "        return 'class 3' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['weightclass'] = train_data['bmi'].map(weighted_classt)\n",
    "test_data['weightclass'] = test_data['bmi'].map(weighted_classt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_var = list(data_dict[data_dict['Data Type'].isin(['binary','string','integer'])]['Variable Name'])\n",
    "cat_var.remove('icu_admit_type')\n",
    "cat_var.remove('bmi')\n",
    "cat_var = cat_var[1:]\n",
    "\n",
    "#to_label_encode = list(data_dict[data_dict['Data Type'].isin(['string'])]['Variable Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_var = cat_var + ['weightclass']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_var = list(data_dict[data_dict['Data Type'].isin(['numeric'])]['Variable Name'])\n",
    "cont_var.remove('pred')\n",
    "cont_var = cont_var + ['bmi']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_data.drop('hospital_death',axis=1)\n",
    "y_train = train_data['hospital_death']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = test_data.drop('hospital_death',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_comb = pd.concat([x_train,x_test],sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_comb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_drop = ['hospital_id','icu_id','encounter_id', 'patient_id', 'readmission_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Remove Features with more than 70 percent missing values\n",
    "#x_comb = x_comb.drop(['readmission_status'],axis = 1)\n",
    "x_comb = x_comb.drop(list_drop,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_comb['hospital_admit_source'] = x_comb['hospital_admit_source'].replace({'Other ICU': 'ICU',\n",
    "                                                                           'ICU to SDU':'SDU', \n",
    "                                                                           'Step-Down Unit (SDU)': 'SDU',        \n",
    "                                                                           'Other Hospital':'Other',\n",
    "                                                                           'Observation': 'Recovery Room',\n",
    "                                                                           'Acute Care/Floor': 'Acute Care'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_comb['icu_type'] = x_comb['icu_type'].replace({'CCU-CTICU': \n",
    "                                                 'Grpd_CICU', \n",
    "                                                 'CTICU':'Grpd_CICU', \n",
    "                                                 'Cardiac ICU':'Grpd_CICU'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_comb['apache_2_bodysystem'] = x_comb['apache_2_bodysystem'].replace({'Undefined diagnoses': \n",
    "                                                                       'Undefined Diagnoses'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_comb[\"apache_4a_hospital_death_prob\"] = x_comb[\"apache_4a_hospital_death_prob\"].replace(-1, np.nan)\n",
    "x_comb[\"apache_4a_icu_death_prob\"] =  x_comb[\"apache_4a_icu_death_prob\"].replace(-1, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_comb['new_bmi'] = (x_comb['weight']*10000)/(x_comb['height']*x_comb['height'])\n",
    "x_comb[['bmi', 'new_bmi', 'weight', 'height']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_comb['bmi'] = x_comb['bmi'].fillna(x_comb['new_bmi'])\n",
    "x_comb[['bmi', 'new_bmi', 'weight', 'height']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_comb = x_comb.drop(['new_bmi'], axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sodium_apache(x) : \n",
    "    \n",
    "    if pd.isna(x):\n",
    "        return np.nan\n",
    "    \n",
    "    if x < 111:\n",
    "        return 4\n",
    "    \n",
    "    elif x>=111 and x<120:\n",
    "        return 3\n",
    "    \n",
    "    elif x>=120 and x<130 :\n",
    "        return 2\n",
    "    \n",
    "    elif x>=130 and x<150 :\n",
    "        return 0\n",
    "    \n",
    "    elif x>=150 and x<155 :\n",
    "        return 1\n",
    "    \n",
    "    elif x>=155 and x<160 :\n",
    "        return 2\n",
    "    \n",
    "    elif x>=160 and x<180 :\n",
    "        return 3\n",
    "    \n",
    "    elif x>=180 :\n",
    "        return 4\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_comb['sodium_apache'] = x_comb['sodium_apache'].apply(lambda x:get_sodium_apache(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_creatinine_apache(x) : \n",
    "    \n",
    "    if pd.isna(x):\n",
    "        return np.nan\n",
    "    \n",
    "    if x < 0.62:\n",
    "        return 4\n",
    "    \n",
    "    elif x>=0.62 and x<1.47:\n",
    "        return 0\n",
    "    \n",
    "    elif x>=1.47 and x<1.98 :\n",
    "        return 4\n",
    "    \n",
    "    elif x>=1.98 and x<3.39 :\n",
    "        return 2\n",
    "    \n",
    "    elif x>=3.39:\n",
    "        return 8\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_comb['creatinine_apache']  = x_comb['creatinine_apache'].apply(lambda x:get_creatinine_apache(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hematocrit_apache(x) : \n",
    "    \n",
    "    if pd.isna(x):\n",
    "        return np.nan\n",
    "    \n",
    "    if x < 20:\n",
    "        return 4\n",
    "    \n",
    "    elif x>=20 and x<30:\n",
    "        return 2\n",
    "    \n",
    "    elif x>=30 and x<46 :\n",
    "        return 0\n",
    "    \n",
    "    elif x>=46 and x<50 :\n",
    "        return 1\n",
    "    \n",
    "    elif x>=50 and x<60 :\n",
    "        return 2\n",
    "    \n",
    "    elif x>=60 :\n",
    "        return 4\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_comb['hematocrit_apache']  = x_comb['hematocrit_apache'].apply(lambda x:get_hematocrit_apache(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_comb['comb_gcs'] = x_comb['gcs_eyes_apache'] + x_comb['gcs_motor_apache'] + x_comb['gcs_verbal_apache']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_map_apache(x) : \n",
    "    \n",
    "    if pd.isna(x):\n",
    "        return np.nan\n",
    "    \n",
    "    if x < 50:\n",
    "        return 4\n",
    "    \n",
    "    elif x>=50 and x<70:\n",
    "        return 2\n",
    "    \n",
    "    elif x>=70 and x<110 :\n",
    "        return 0\n",
    "    \n",
    "    elif x>=110 and x<130 :\n",
    "        return 2\n",
    "    \n",
    "    elif x>=130 and x<160 :\n",
    "        return 3\n",
    "    \n",
    "    elif x>=160 :\n",
    "        return 4\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_comb['map_apache'] = x_comb['map_apache'].apply(lambda x:get_map_apache(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_heart_rate_apache(x) : \n",
    "    \n",
    "    if pd.isna(x):\n",
    "        return np.nan\n",
    "    \n",
    "    if x < 40:\n",
    "        return 4\n",
    "    \n",
    "    elif x>=40 and x<55:\n",
    "        return 3\n",
    "    \n",
    "    elif x>=55 and x<110 :\n",
    "        return 0\n",
    "    \n",
    "    elif x>=110 and x<140 :\n",
    "        return 2\n",
    "    \n",
    "    elif x>=140 and x<180 :\n",
    "        return 3\n",
    "    \n",
    "    elif x>=180 :\n",
    "        return 4\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_comb['heart_rate_apache'] = x_comb['heart_rate_apache'].apply(lambda x:get_heart_rate_apache(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_resprate_apache(x) : \n",
    "    \n",
    "    if pd.isna(x):\n",
    "        return np.nan\n",
    "    \n",
    "    if x < 6:\n",
    "        return 4\n",
    "    \n",
    "    elif x>=6 and x<10:\n",
    "        return 3\n",
    "    \n",
    "    elif x>=10 and x<12 :\n",
    "        return 2\n",
    "    \n",
    "    elif x>=12 and x<25 :\n",
    "        return 0\n",
    "    \n",
    "    elif x>=25 and x<35 :\n",
    "        return 2\n",
    "    \n",
    "    elif x>=35 and x<50 :\n",
    "        return 3\n",
    "    \n",
    "    elif x>=50 :\n",
    "        return 4\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_comb['resprate_apache'] = x_comb['resprate_apache'].apply(lambda x:get_resprate_apache(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pao2_apache(x) : \n",
    "    \n",
    "    if pd.isna(x):\n",
    "        return np.nan\n",
    "    \n",
    "    if x < 200:\n",
    "        return 0\n",
    "    \n",
    "    elif x>=200 and x<350:\n",
    "        return 2\n",
    "    \n",
    "    elif x>=350 and x<500 :\n",
    "        return 3\n",
    "    \n",
    "    elif x>=500 :\n",
    "        return 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_comb['pao2_apache'] = x_comb['pao2_apache'].apply(lambda x:get_pao2_apache(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ph_apache(x) : \n",
    "    \n",
    "    if pd.isna(x):\n",
    "        return np.nan\n",
    "    \n",
    "    if x < 7.15:\n",
    "        return 4\n",
    "    \n",
    "    elif x>=7.15 and x<7.25:\n",
    "        return 3\n",
    "    \n",
    "    elif x>=7.25 and x<7.33 :\n",
    "        return 2\n",
    "    \n",
    "    elif x>=7.33 and x<7.5 :\n",
    "        return 0\n",
    "    \n",
    "    elif x>=7.5 and x<7.6 :\n",
    "        return 1\n",
    "    \n",
    "    elif x>=7.6 and x<7.7 :\n",
    "        return 3\n",
    "    \n",
    "    elif x>=7.7 :\n",
    "        return 4\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_comb['ph_apache'] = x_comb['ph_apache'].apply(lambda x:get_ph_apache(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_comb['dis_ind'] = x_comb['aids'] + x_comb['cirrhosis'] + x_comb['diabetes_mellitus'] + x_comb['hepatic_failure'] + x_comb['immunosuppression'] + x_comb['leukemia'] + x_comb['lymphoma'] + x_comb['solid_tumor_with_metastasis']\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cat_var = list(set(cat_var).intersection(set(x_comb.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rajesh features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in tqdm(new_cat_var):\n",
    "    le = LabelEncoder()\n",
    "    x_comb[col] = le.fit_transform(x_comb[col].astype(str))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_cat = []\n",
    "\n",
    "for i in tqdm(range(0,len(x_comb))):\n",
    "    \n",
    "    val = x_comb['age'].iloc[i]\n",
    "    \n",
    "    if val >= 15 and val <= 24: \n",
    "        age_cat.append('igen')\n",
    "    \n",
    "    elif val >= 25 and val <= 54: \n",
    "       age_cat.append('Prime_working_Age')\n",
    "    \n",
    "    elif val >= 55 and val <= 64: \n",
    "        age_cat.append('Mature_working_Age')\n",
    "        \n",
    "    else: \n",
    "        age_cat.append('Elderly_working_Age')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_comb['age_category'] = age_cat\n",
    "le = LabelEncoder()\n",
    "x_comb['age_category'] = le.fit_transform(x_comb['age_category'].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_cols_nans = list(data_dict[data_dict['Category'].isin(['vitals','labs','labs blood gas'])]['Variable Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_cols_nans = list(set(list_cols_nans).intersection(set(x_comb.columns)))\n",
    "#list_cols_nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_var = []\n",
    "for i,col in tqdm(enumerate(new_cat_var)):\n",
    "    counter = Counter(x_comb[col])\n",
    "    x_comb[str(col)+'count'] = x_comb[col].apply(lambda x:counter[x])\n",
    "    count_var.append(str(col)+'count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List to be biined -----> VITALS\n",
    "to_binned_columns = list(data_dict[data_dict['Category'] == 'labs blood gas']['Variable Name'].unique())\n",
    "to_binned_columns = list(set(to_binned_columns).intersection(set(x_comb.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binned_cols = []\n",
    "\n",
    "for cols in tqdm(to_binned_columns) :\n",
    "    x_comb[cols+'_binned'] = list(pd.cut(x_comb[cols], 10 ,labels=False))\n",
    "    binned_cols.append(cols+'_binned')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_comb['height'+'_binned'] = list(pd.cut(x_comb['height'], 8,labels=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featured_cols = binned_cols + ['age_category','height'+'_binned']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2way interaction\n",
    "bias_cols = ['gender','age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_cols6 = []\n",
    "\n",
    "for i in tqdm(bias_cols):\n",
    "    \n",
    "    for j in binned_cols :\n",
    "        \n",
    "        x_comb[i+'_'+j] = x_comb[i].astype(str) + '_' + x_comb[j].astype(str)\n",
    "        \n",
    "        inter_cols6.append(i+'_'+j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Critical -3way interaction\n",
    "\n",
    "\n",
    "x_comb['age'+'gender'+'weighted_classt'] = x_comb['age'].astype(str) + '_' + x_comb['gender'].astype(str) + '_' + x_comb['weightclass'].astype(str)\n",
    "x_comb['age'+'gender'+'ethnicity'] = x_comb['age'].astype(str) + '_' + x_comb['gender'].astype(str) + '_' + x_comb['ethnicity'].astype(str)\n",
    "x_comb['age'+'gender'+'ethnicity' +'weighted_classt' ] = x_comb['age'].astype(str) + '_' + x_comb['gender'].astype(str) + '_' + x_comb['ethnicity'].astype(str) +'_' + x_comb['weightclass'].astype(str)\n",
    "\n",
    "\n",
    "inter_cols6 = inter_cols6 + ['age'+'gender'+'weighted_classt'] +['age'+'gender'+'ethnicity'] + ['age'+'gender'+'ethnicity'+'weighted_classt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cols in tqdm(inter_cols6):\n",
    "    le = LabelEncoder()\n",
    "    x_comb[cols] = le.fit_transform(x_comb[cols].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_illness = ['aids',\n",
    "                'cirrhosis',\n",
    "                'diabetes_mellitus',\n",
    "                'hepatic_failure',\n",
    "                'immunosuppression',\n",
    "                'leukemia',\n",
    "                'lymphoma',\n",
    "                'solid_tumor_with_metastasis']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_cols1 = []\n",
    "\n",
    "for col in tqdm(list_illness) :\n",
    "    #x_comb['hospital_id'+str(col)] = x_comb['hospital_id'].astype(str) + '_' + x_comb[col].astype(str)\n",
    "    x_comb['gender'+str(col)] = x_comb['gender'].astype(str) + '_' + x_comb[col].astype(str)\n",
    "    x_comb['age'+str(col)] = x_comb['age'].astype(str) + '_' + x_comb[col].astype(str)\n",
    "    x_comb['bmi'+str(col)] = x_comb['bmi'].astype(str) + '_' + x_comb[col].astype(str)\n",
    "    \n",
    "    #inter_cols1.append('hospital_id'+str(col))\n",
    "    inter_cols1.append('gender'+str(col))\n",
    "    inter_cols1.append('age'+str(col))\n",
    "    inter_cols1.append('bmi'+str(col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cols in tqdm(inter_cols1):\n",
    "    le = LabelEncoder()\n",
    "    x_comb[cols] = le.fit_transform(x_comb[cols])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter_cols2 = []\n",
    "\n",
    "for col in tqdm(list_illness) :\n",
    "    x_comb['age_category'+str(col)] = x_comb['age_category'].astype(str) + '_' + x_comb[col].astype(str)\n",
    "    inter_cols2.append('age_category'+str(col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cols in tqdm(inter_cols2):\n",
    "    le = LabelEncoder()\n",
    "    x_comb[cols] = le.fit_transform(x_comb[cols])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_train = x_train.copy()\n",
    "temp_train['hospital_death'] = train_data['hospital_death']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_count_var = []\n",
    "\n",
    "for i,col in tqdm(enumerate(new_cat_var)):\n",
    "    mean = temp_train['hospital_death'].mean()\n",
    "    \n",
    "    #Compute the number of values and the mean of each group\n",
    "    agg = temp_train.groupby(col)['hospital_death'].agg(['count', 'mean'])\n",
    "    counts = agg['count']\n",
    "    means =  agg['mean']\n",
    "    \n",
    "    #Compute the \"smoothed\" means\n",
    "    m= 3\n",
    "    smooth = (counts * means + m * mean) / (counts + m)\n",
    "    \n",
    "    #Final_val\n",
    "    x_comb[str(col)+'count_new'] = x_comb[col].map(smooth)\n",
    "    cat_count_var.append(str(col)+'count_new')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggs = {}\n",
    "# aggs['apache_4a_hospital_death_prob'] = ['median', 'mean', 'max', 'min']\n",
    "# aggs['apache_4a_icu_death_prob'] = ['median', 'mean', 'max', 'min']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cat_var = list(set(new_cat_var).intersection(x_comb.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Remove Features with more than 70 percent missing values\n",
    "data_missing = (x_comb.isnull().sum() / len(x_comb)).sort_values(ascending = False)\n",
    "data_missing = data_missing.index[data_missing > 0.9]\n",
    "\n",
    "x_comb = x_comb.drop(columns = data_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_count_var_new = list(set(cat_count_var).intersection(x_comb.columns))\n",
    "#x_comb.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in tqdm(cat_count_var_new):\n",
    "    le = LabelEncoder()\n",
    "    x_comb[col] = le.fit_transform(x_comb[col].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mode(x):\n",
    "    return Counter(x).most_common(1)[0][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggs = {}\n",
    "\n",
    "for col in tqdm(new_cat_var):\n",
    "    aggs[col] = [mode]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cat_var = list(set(new_cat_var).intersection(set(x_comb.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in tqdm(new_cat_var):\n",
    "    \n",
    "    aggs_temp = aggs.copy()\n",
    "    aggs_temp.pop(col)\n",
    "    \n",
    "    agg_df = x_comb.groupby(col).agg(aggs_temp).reset_index()\n",
    "    agg_df.columns = [col] + [col + '_' + c[0] +'_' + c[1] for c in agg_df.columns[1:]]\n",
    "    \n",
    "    x_comb = pd.merge(left = x_comb, right= agg_df, how='left',\n",
    "                    left_on=[col], right_on=[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_comb['hospital_icu_id'] = x_comb['hospital_id'].astype(str) + '_' +  x_comb['icu_id'].astype(str)\n",
    "\n",
    "# le = LabelEncoder()\n",
    "# x_comb['hospital_icu_id'] = le.fit_transform(x_comb['hospital_icu_id'].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_comb = x_comb.drop(['encounter_id','patient_id'],axis=1)\n",
    "#x_comb = x_comb.drop(list_unimp,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_comb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = x_comb[0:91713]\n",
    "test_x = x_comb[91713:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_train, x1_val, y1_train, y1_val = train_test_split(train_x, y_train, \n",
    "                                                      test_size=0.2,\n",
    "                                                      random_state=0,\n",
    "                                                      stratify = y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random_state = 42\n",
    "# np.random.seed(random_state)\n",
    "\n",
    "lgb_params = {\n",
    "    'boost': 'gbdt',\n",
    "    'learning_rate': 0.01,\n",
    "    'max_depth':6,\n",
    "    'metric':{'auc'},\n",
    "    'num_threads': -1,\n",
    "    'objective': 'binary',\n",
    "    'verbosity': 1,\n",
    "    'num_leaves':15,\n",
    "    'bagging_fraction':0.5, #rows\n",
    "    'bagging_frequency':5,\n",
    "    'min_data_in_leaf':50,\n",
    "    'feature_fraction':0.4, # features\n",
    "    'lambda_l1':10,\n",
    "    'lambda_l2':15,\n",
    "    'bagging_seed':2019,\n",
    "    'min_gain_split':0.3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_data = lgb.Dataset(x1_train, label= y1_train)\n",
    "val_data = lgb.Dataset(x1_val,  label=  y1_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lgb_clf = lgb.train(lgb_params,\n",
    "                    trn_data,\n",
    "                    15000,\n",
    "                    valid_sets = [trn_data, val_data],\n",
    "                    early_stopping_rounds=1500,\n",
    "                    verbose_eval=200\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lgb_clf.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sub = x_test[['encounter_id']]\n",
    "data_sub['hospital_death'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sub.to_csv('/Users/s0c02nj/Desktop/OneDrive - Walmart Inc/WiDS/sample_try_24thfeb.csv',index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_imp = pd.DataFrame(sorted(zip(lgb_clf.feature_importance(), \n",
    "                                      x_comb.columns), reverse=True), columns=['Value','Feature'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_unimp = list(feature_imp[feature_imp['Value'] == 0]['Feature'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_imp[feature_imp['Feature'] == 'map_apache']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(12,30))\n",
    "# lgb.plot_importance(lgb_clf, max_num_features=130, height=0.8, ax=ax)\n",
    "# ax.grid(False)\n",
    "# plt.title(\"LightGBM - Feature Importance\", fontsize=12)\n",
    "# plt.show()\n",
    "# #data_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits=10, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "oof = np.zeros(len(x_train))\n",
    "predictions = np.zeros(len(x_test))\n",
    "num_models = 0\n",
    "\n",
    "for train_index, valid_index in tqdm(kf.split(train_x, y_train)):\n",
    "    \n",
    "    d_train = lgb.Dataset(train_x.iloc[train_index], label=y_train[train_index])\n",
    "    d_val = lgb.Dataset(train_x.iloc[valid_index], label=y_train[valid_index])\n",
    "\n",
    "    clf = lgb.train(lgb_params, d_train, 13000, verbose_eval=1000, \n",
    "                    valid_sets = [d_train, d_val])\n",
    "    \n",
    "\n",
    "    \n",
    "    num_models += 1\n",
    "    \n",
    "    oof[valid_index] = clf.predict(train_x.iloc[valid_index])\n",
    "    predictions += clf.predict(test_x, num_iteration = clf.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_10 = predictions /10.0\n",
    "data_sub = x_test[['encounter_id']]\n",
    "data_sub['hospital_death'] = predictions_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sub.to_csv('/Users/s0c02nj/Desktop/OneDrive - Walmart Inc/WiDS/final_fold10_dart_24thfeb.csv',index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature_imp = pd.DataFrame(sorted(zip(lgb_clf.feature_importance(), \n",
    "#                                      x_comb.columns), reverse=True), columns=['Value','Feature'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature_imp[feature_imp['Feature'] == 'weightclass']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature_imp[feature_imp['Value'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 =  pd.read_csv('/Users/s0c02nj/Desktop/sub_10fold_keep_missing_as_it_is_18thFeb2020_newfeat.csv')\n",
    "a2 =  pd.read_csv('/Users/s0c02nj/Desktop/OneDrive - Walmart Inc/WiDS/ensemble_till_now_12thfeb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a1 =  pd.read_csv('/Users/s0c02nj/Desktop/WiDS/ensemble4_lgbold_10thfeb_new_bmi_impute.csv')\n",
    "# a2 =  pd.read_csv('/Users/s0c02nj/Desktop/WiDS/sub_10fold_keep_missing_as_it_is_10thFeb2020_lgb_type4_ff_20_na_bmi.csv')\n",
    "# #a2 =  pd.read_csv('/Users/s0c02nj/Desktop/WiDS/sub_10fold_keep_missing_as_it_is_9thFeb2020_lgb_type3_ff_27.csv')\n",
    "# a3 =  pd.read_csv('/Users/s0c02nj/Desktop/WiDS/sub_type1_type2_ensemble_5thFeb2020.csv')\n",
    "# a4 =  pd.read_csv('/Users/s0c02nj/Desktop/WiDS/sub_10fold_keep_missing_as_it_is_11thFeb2020_lgb_type3_ff_27.csv')\n",
    "# a5 =  pd.read_csv('/Users/s0c02nj/Desktop/WiDS/pred_lgb_keeping_cat_cont_interchanged_11th_feb.csv')\n",
    "# a6 = pd.read_csv('/Users/s0c02nj/Desktop/WiDS/ensemble4tillnpw_11thfeb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame()\n",
    "sub['encounter_id'] = a1['encounter_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ens = (a1['hospital_death'] + a2['hospital_death']\n",
    "           )/2.0\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['hospital_death'] = pred_ens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('/Users/s0c02nj/Desktop/OneDrive - Walmart Inc/WiDS/ensemble_till_now_18thfeb.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def hospital_type(x):\n",
    "    \n",
    "#     if pd.isna(x):\n",
    "#         return np.nan\n",
    "    \n",
    "#     elif x <= 4:\n",
    "#         return \"less_icu\"\n",
    "    \n",
    "#     elif x > 8:\n",
    "#         return \"more_icu\"\n",
    "#     else:\n",
    "#         return \"med_icu\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import metrics, preprocessing\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from catboost import Pool, CatBoostClassifier\n",
    "import lightgbm as lgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing\n",
    "train_data = pd.read_csv('/Users/s0c02nj/Desktop/WiDS/training_v2.csv')\n",
    "test_data =  pd.read_csv('/Users/s0c02nj/Desktop/WiDS/unlabeled.csv')\n",
    "\n",
    "sub_data = pd.read_csv('/Users/s0c02nj/Desktop/WiDS/samplesubmission.csv')\n",
    "data_dict = pd.read_csv('/Users/s0c02nj/Desktop/WiDS/WiDS Datathon 2020 Dictionary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_classt(x): \n",
    "    if pd.isna(x):\n",
    "        return np.nan\n",
    "    elif x < 15: \n",
    "        return 'very severely underweight' \n",
    "    elif x >= 15 and x < 16: \n",
    "        return 'severely weight' \n",
    "    elif x >=16 and x < 18.5: \n",
    "        return 'underweight' \n",
    "    elif x >= 18.5 and x < 25: \n",
    "        return 'healthy weight' \n",
    "    elif x >= 25 and x < 30: \n",
    "        return 'overweight'\n",
    "    elif x >= 30 and x < 35: \n",
    "        return 'class 1' \n",
    "    elif x >= 35 and x < 40: \n",
    "        return 'class 2' \n",
    "    else: \n",
    "        return 'class 3' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['weightclass'] = train_data['bmi'].map(weighted_classt)\n",
    "test_data['weightclass'] = test_data['bmi'].map(weighted_classt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_var = list(data_dict[data_dict['Data Type'].isin(['binary','string'])]['Variable Name'])\n",
    "cat_var.remove('icu_admit_type')\n",
    "cat_var.remove('bmi')\n",
    "cat_var = cat_var[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cat_var = cat_var[1:]\n",
    "#cat_var = cat_var[1:]\n",
    "cat_var = cat_var + ['weightclass']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_var = list(data_dict[data_dict['Data Type'].isin(['integer','numeric'])]['Variable Name'])\n",
    "cont_var.remove('pred')\n",
    "cont_var = cont_var + ['bmi']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_data.drop('hospital_death',axis=1)\n",
    "y_train = train_data['hospital_death']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = test_data.drop('hospital_death',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_comb = pd.concat([x_train,x_test],sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131021/131021 [00:10<00:00, 12016.41it/s]\n"
     ]
    }
   ],
   "source": [
    "### impute bmi values based on height and weight\n",
    "count = 0\n",
    "bmi_list = []\n",
    "for i in tqdm(range(x_comb.shape[0])):\n",
    "    \n",
    "    if pd.isnull(x_comb[\"weight\"].iloc[i]) or pd.isnull(x_comb[\"height\"].iloc[i]):\n",
    "        bmi_list.append(x_comb[\"bmi\"].iloc[i])\n",
    "        continue\n",
    "    else:\n",
    "        \n",
    "        count += 1\n",
    "        bmi_list.append(x_comb[\"weight\"].iloc[i] / ((x_comb[\"height\"].iloc[i]/100) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_comb['bmi'] = bmi_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cat_var = list(set(cat_var).intersection(set(x_comb.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:03<00:00,  7.21it/s]\n"
     ]
    }
   ],
   "source": [
    "for col in tqdm(new_cat_var):\n",
    "    le = LabelEncoder()\n",
    "    x_comb[col] = le.fit_transform(x_comb[col].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cont_var = list(set(cont_var).intersection(set(x_comb.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in tqdm(new_cont_var):\n",
    "#     x_comb[col] = x_comb[col].fillna(x_comb[col].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26it [00:02,  9.06it/s]\n"
     ]
    }
   ],
   "source": [
    "count_var = []\n",
    "for i,col in tqdm(enumerate(new_cat_var)):\n",
    "    counter = Counter(x_comb[col])\n",
    "    x_comb[str(col)+'count'] = x_comb[col].apply(lambda x:counter[x])\n",
    "    count_var.append(str(col)+'count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131021/131021 [00:03<00:00, 40550.03it/s]\n"
     ]
    }
   ],
   "source": [
    "age_cat = []\n",
    "\n",
    "for i in tqdm(range(0,len(x_comb))):\n",
    "    \n",
    "    val = x_comb['age'].iloc[i]\n",
    "    \n",
    "    if val >= 15 and val <= 24: \n",
    "        age_cat.append('igen')\n",
    "    \n",
    "    elif val >= 25 and val <= 54: \n",
    "       age_cat.append('Prime_working_Age')\n",
    "    \n",
    "    elif val >= 55 and val <= 64: \n",
    "        age_cat.append('Mature_working_Age')\n",
    "        \n",
    "    else: \n",
    "        age_cat.append('Elderly_working_Age')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_comb['age_category'] = age_cat\n",
    "le = LabelEncoder()\n",
    "x_comb['age_category'] = le.fit_transform(x_comb['age_category'].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_illness = ['aids',\n",
    "                'cirrhosis',\n",
    "                'diabetes_mellitus',\n",
    "                'hepatic_failure',\n",
    "                'immunosuppression',\n",
    "                'leukemia',\n",
    "                'lymphoma',\n",
    "                'solid_tumor_with_metastasis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:09<00:00,  1.22s/it]\n"
     ]
    }
   ],
   "source": [
    "inter_cols1 = []\n",
    "\n",
    "for col in tqdm(list_illness) :\n",
    "    x_comb['hospital_id'+str(col)] = x_comb['hospital_id'].astype(str) + '_' + x_comb[col].astype(str)\n",
    "    x_comb['gender'+str(col)] = x_comb['gender'].astype(str) + '_' + x_comb[col].astype(str)\n",
    "    x_comb['age'+str(col)] = x_comb['age'].astype(str) + '_' + x_comb[col].astype(str)\n",
    "    x_comb['bmi'+str(col)] = x_comb['bmi'].astype(str) + '_' + x_comb[col].astype(str)\n",
    "    \n",
    "    inter_cols1.append('hospital_id'+str(col))\n",
    "    inter_cols1.append('gender'+str(col))\n",
    "    inter_cols1.append('age'+str(col))\n",
    "    inter_cols1.append('bmi'+str(col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:02<00:00, 11.89it/s]\n"
     ]
    }
   ],
   "source": [
    "for cols in tqdm(inter_cols1):\n",
    "    le = LabelEncoder()\n",
    "    x_comb[cols] = le.fit_transform(x_comb[cols])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:02<00:00,  2.88it/s]\n"
     ]
    }
   ],
   "source": [
    "inter_cols2 = []\n",
    "\n",
    "for col in tqdm(list_illness) :\n",
    "    x_comb['age_category'+str(col)] = x_comb['age_category'].astype(str) + '_' + x_comb[col].astype(str)\n",
    "    inter_cols2.append('age_category'+str(col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 19.76it/s]\n"
     ]
    }
   ],
   "source": [
    "for cols in tqdm(inter_cols2):\n",
    "    le = LabelEncoder()\n",
    "    x_comb[cols] = le.fit_transform(x_comb[cols])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:16<00:00,  2.05s/it]\n"
     ]
    }
   ],
   "source": [
    "inter_cols3 = []\n",
    "\n",
    "for col1 in tqdm(list_illness) :\n",
    "    for col2 in list_illness:\n",
    "        if col1 !=col2 :\n",
    "            x_comb[col1+col2] = x_comb[col1].astype(str) + '_' + x_comb[col2].astype(str)\n",
    "            inter_cols3.append(col1+col2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56/56 [00:01<00:00, 36.30it/s]\n"
     ]
    }
   ],
   "source": [
    "for cols in tqdm(inter_cols3):\n",
    "    le = LabelEncoder()\n",
    "    x_comb[cols] = le.fit_transform(x_comb[cols])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:03<00:00,  1.45it/s]\n"
     ]
    }
   ],
   "source": [
    "#train_data.columns[0:100]\n",
    "\n",
    "list_imp_cols = ['icu_type','bmi','age','gender','d1_heartrate_max']\n",
    "\n",
    "inter_cols4 = []\n",
    "\n",
    "for col1 in tqdm(list_imp_cols) :\n",
    "    for col2 in list_imp_cols:\n",
    "        if col1 !=col2 :\n",
    "            x_comb[col1+col2] = x_comb[col1].astype(str) + '_' + x_comb[col2].astype(str)\n",
    "            inter_cols4.append(col1+col2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:02<00:00,  8.30it/s]\n"
     ]
    }
   ],
   "source": [
    "for cols in tqdm(inter_cols4):\n",
    "    le = LabelEncoder()\n",
    "    x_comb[cols] = le.fit_transform(x_comb[cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_cat_var = new_cat_var + count_var + ['age_category'] + inter_cols1 + inter_cols2 + inter_cols3 + inter_cols4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Target Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_train = x_train.copy()\n",
    "temp_train['hospital_death'] = train_data['hospital_death']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26it [00:02, 12.84it/s]\n"
     ]
    }
   ],
   "source": [
    "cat_count_var = []\n",
    "\n",
    "for i,col in tqdm(enumerate(new_cat_var)):\n",
    "    mean = temp_train['hospital_death'].mean()\n",
    "    \n",
    "    #Compute the number of values and the mean of each group\n",
    "    agg = temp_train.groupby(col)['hospital_death'].agg(['count', 'mean'])\n",
    "    counts = agg['count']\n",
    "    means =  agg['mean']\n",
    "    \n",
    "    #Compute the \"smoothed\" means\n",
    "    m=3\n",
    "    smooth = (counts * means + m * mean) / (counts + m)\n",
    "    \n",
    "    #Final_val\n",
    "    x_comb[str(col)+'count_new'] = x_comb[col].map(smooth)\n",
    "    cat_count_var.append(str(col)+'count_new')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Remove Features with more than 70 percent missing values\n",
    "data_missing = (x_comb.isnull().sum() / len(x_comb)).sort_values(ascending = False)\n",
    "data_missing = data_missing.index[data_missing > 0.93]\n",
    "\n",
    "x_comb = x_comb.drop(columns = data_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_count_var_new = list(set(cat_count_var).intersection(x_comb.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:07<00:00,  2.04it/s]\n"
     ]
    }
   ],
   "source": [
    "for col in tqdm(cat_count_var_new):\n",
    "    le = LabelEncoder()\n",
    "    x_comb[col] = le.fit_transform(x_comb[col].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:00<00:00, 45287.34it/s]\n"
     ]
    }
   ],
   "source": [
    "aggs = {}\n",
    "\n",
    "for col in tqdm(count_var):\n",
    "    aggs[col] = ['nunique']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [02:59<00:00,  6.92s/it]\n"
     ]
    }
   ],
   "source": [
    "for col in tqdm(count_var):\n",
    "    \n",
    "    aggs_temp = aggs.copy()\n",
    "    aggs_temp.pop(col)\n",
    "    \n",
    "    agg_df = x_comb.groupby(col).agg(aggs_temp).reset_index()\n",
    "    agg_df.columns = [col] + [col + '_' + c[0] +'_' + c[1] for c in agg_df.columns[1:]]\n",
    "    \n",
    "    x_comb = pd.merge(left = x_comb, right= agg_df, how='left',\n",
    "                    left_on=[col], right_on=[col])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_comb = x_comb.drop(['encounter_id','patient_id'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = x_comb[0:91713]\n",
    "test_x = x_comb[91713:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(131021, 992)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_comb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_train, x1_val, y1_train, y1_val = train_test_split(train_x, y_train, \n",
    "                                                      test_size=0.2,\n",
    "                                                      random_state=0,\n",
    "                                                      stratify = y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42\n",
    "np.random.seed(random_state)\n",
    "\n",
    "lgb_params = {\n",
    "    'boost': 'gbdt',\n",
    "    'learning_rate': 0.01,\n",
    "    'max_depth':8,\n",
    "    'metric':{'auc'},\n",
    "    'num_threads': -1,\n",
    "    'objective': 'binary',\n",
    "    'verbosity': 1,\n",
    "    'num_leaves':16,\n",
    "    'bagging_fraction':0.5, #rows\n",
    "    'bagging_frequency':5,\n",
    "    'min_data_in_leaf':50,\n",
    "    'feature_fraction':0.3, # features\n",
    "    'lambda_l1':10,\n",
    "    'lambda_l2':15,\n",
    "    'bagging_seed':2019,\n",
    "    'min_gain_split':0.3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_data = lgb.Dataset(x1_train, label= y1_train)\n",
    "val_data = lgb.Dataset(x1_val,  label=  y1_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[200]\ttraining's auc: 0.896157\tvalid_1's auc: 0.884783\n",
      "[400]\ttraining's auc: 0.905967\tvalid_1's auc: 0.891729\n",
      "[600]\ttraining's auc: 0.912826\tvalid_1's auc: 0.896235\n",
      "[800]\ttraining's auc: 0.91766\tvalid_1's auc: 0.898817\n",
      "[1000]\ttraining's auc: 0.921626\tvalid_1's auc: 0.900568\n",
      "[1200]\ttraining's auc: 0.925089\tvalid_1's auc: 0.901852\n",
      "[1400]\ttraining's auc: 0.928243\tvalid_1's auc: 0.902786\n",
      "[1600]\ttraining's auc: 0.931031\tvalid_1's auc: 0.903512\n",
      "[1800]\ttraining's auc: 0.933448\tvalid_1's auc: 0.904094\n",
      "[2000]\ttraining's auc: 0.93567\tvalid_1's auc: 0.904548\n",
      "[2200]\ttraining's auc: 0.937659\tvalid_1's auc: 0.904831\n",
      "[2400]\ttraining's auc: 0.93963\tvalid_1's auc: 0.905132\n",
      "[2600]\ttraining's auc: 0.94139\tvalid_1's auc: 0.905349\n",
      "[2800]\ttraining's auc: 0.943053\tvalid_1's auc: 0.905587\n",
      "[3000]\ttraining's auc: 0.944694\tvalid_1's auc: 0.905816\n",
      "[3200]\ttraining's auc: 0.946286\tvalid_1's auc: 0.905932\n",
      "[3400]\ttraining's auc: 0.947869\tvalid_1's auc: 0.906084\n",
      "[3600]\ttraining's auc: 0.94931\tvalid_1's auc: 0.906197\n",
      "[3800]\ttraining's auc: 0.950745\tvalid_1's auc: 0.906314\n",
      "[4000]\ttraining's auc: 0.952133\tvalid_1's auc: 0.906339\n",
      "[4200]\ttraining's auc: 0.953472\tvalid_1's auc: 0.906446\n",
      "[4400]\ttraining's auc: 0.954726\tvalid_1's auc: 0.906555\n",
      "[4600]\ttraining's auc: 0.956007\tvalid_1's auc: 0.906623\n",
      "[4800]\ttraining's auc: 0.957195\tvalid_1's auc: 0.906627\n",
      "[5000]\ttraining's auc: 0.958396\tvalid_1's auc: 0.906649\n",
      "[5200]\ttraining's auc: 0.959518\tvalid_1's auc: 0.906629\n",
      "[5400]\ttraining's auc: 0.960677\tvalid_1's auc: 0.906684\n",
      "[5600]\ttraining's auc: 0.961746\tvalid_1's auc: 0.906636\n",
      "[5800]\ttraining's auc: 0.962819\tvalid_1's auc: 0.906689\n",
      "[6000]\ttraining's auc: 0.963869\tvalid_1's auc: 0.906709\n",
      "[6200]\ttraining's auc: 0.964911\tvalid_1's auc: 0.906724\n",
      "[6400]\ttraining's auc: 0.965919\tvalid_1's auc: 0.906725\n",
      "[6600]\ttraining's auc: 0.966923\tvalid_1's auc: 0.906747\n",
      "[6800]\ttraining's auc: 0.967851\tvalid_1's auc: 0.906775\n",
      "[7000]\ttraining's auc: 0.968755\tvalid_1's auc: 0.90679\n",
      "[7200]\ttraining's auc: 0.969644\tvalid_1's auc: 0.90675\n",
      "[7400]\ttraining's auc: 0.970558\tvalid_1's auc: 0.906713\n",
      "[7600]\ttraining's auc: 0.97141\tvalid_1's auc: 0.906755\n",
      "[7800]\ttraining's auc: 0.972223\tvalid_1's auc: 0.906721\n",
      "[8000]\ttraining's auc: 0.973028\tvalid_1's auc: 0.906688\n",
      "[8200]\ttraining's auc: 0.973717\tvalid_1's auc: 0.906676\n",
      "[8400]\ttraining's auc: 0.974511\tvalid_1's auc: 0.906697\n",
      "[8600]\ttraining's auc: 0.97525\tvalid_1's auc: 0.906706\n",
      "[8800]\ttraining's auc: 0.975998\tvalid_1's auc: 0.906678\n",
      "[9000]\ttraining's auc: 0.976722\tvalid_1's auc: 0.906701\n",
      "[9200]\ttraining's auc: 0.977404\tvalid_1's auc: 0.906695\n",
      "[9400]\ttraining's auc: 0.978076\tvalid_1's auc: 0.906674\n",
      "[9600]\ttraining's auc: 0.978729\tvalid_1's auc: 0.906662\n",
      "Early stopping, best iteration is:\n",
      "[6747]\ttraining's auc: 0.967637\tvalid_1's auc: 0.906806\n"
     ]
    }
   ],
   "source": [
    "lgb_clf = lgb.train(lgb_params,\n",
    "                    trn_data,\n",
    "                    13000,\n",
    "                    valid_sets = [trn_data, val_data],\n",
    "                    early_stopping_rounds=3000,\n",
    "                    verbose_eval=200\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = lgb_clf.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sub = x_test[['encounter_id']]\n",
    "data_sub['hospital_death'] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sub.to_csv('/Users/s0c02nj/Desktop/WiDS/sub2_lgb_01022020.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits=10, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.920117\tvalid_1's auc: 0.902579\n",
      "[2000]\ttraining's auc: 0.933235\tvalid_1's auc: 0.9062\n",
      "[3000]\ttraining's auc: 0.942008\tvalid_1's auc: 0.907603\n",
      "[4000]\ttraining's auc: 0.949123\tvalid_1's auc: 0.907968\n",
      "[5000]\ttraining's auc: 0.955403\tvalid_1's auc: 0.908222\n",
      "[6000]\ttraining's auc: 0.961027\tvalid_1's auc: 0.908363\n",
      "[7000]\ttraining's auc: 0.965895\tvalid_1's auc: 0.908313\n",
      "[8000]\ttraining's auc: 0.970086\tvalid_1's auc: 0.908272\n",
      "[9000]\ttraining's auc: 0.973905\tvalid_1's auc: 0.908333\n",
      "Early stopping, best iteration is:\n",
      "[6689]\ttraining's auc: 0.964456\tvalid_1's auc: 0.908451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [03:19, 199.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.91915\tvalid_1's auc: 0.907779\n",
      "[2000]\ttraining's auc: 0.93256\tvalid_1's auc: 0.912249\n",
      "[3000]\ttraining's auc: 0.941381\tvalid_1's auc: 0.913636\n",
      "[4000]\ttraining's auc: 0.948432\tvalid_1's auc: 0.914318\n",
      "[5000]\ttraining's auc: 0.954674\tvalid_1's auc: 0.914627\n",
      "[6000]\ttraining's auc: 0.960264\tvalid_1's auc: 0.914629\n",
      "[7000]\ttraining's auc: 0.965177\tvalid_1's auc: 0.914662\n",
      "[8000]\ttraining's auc: 0.96958\tvalid_1's auc: 0.914632\n",
      "[9000]\ttraining's auc: 0.973376\tvalid_1's auc: 0.914619\n",
      "[10000]\ttraining's auc: 0.976803\tvalid_1's auc: 0.914397\n",
      "Early stopping, best iteration is:\n",
      "[7470]\ttraining's auc: 0.967341\tvalid_1's auc: 0.914704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [07:08, 208.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.91979\tvalid_1's auc: 0.906365\n",
      "[2000]\ttraining's auc: 0.933239\tvalid_1's auc: 0.909961\n",
      "[3000]\ttraining's auc: 0.941983\tvalid_1's auc: 0.910819\n",
      "[4000]\ttraining's auc: 0.949013\tvalid_1's auc: 0.91113\n",
      "[5000]\ttraining's auc: 0.955154\tvalid_1's auc: 0.91148\n",
      "[6000]\ttraining's auc: 0.960444\tvalid_1's auc: 0.911583\n",
      "[7000]\ttraining's auc: 0.965163\tvalid_1's auc: 0.911543\n",
      "[8000]\ttraining's auc: 0.969458\tvalid_1's auc: 0.911692\n",
      "[9000]\ttraining's auc: 0.973301\tvalid_1's auc: 0.91153\n",
      "[10000]\ttraining's auc: 0.97662\tvalid_1's auc: 0.911349\n",
      "[11000]\ttraining's auc: 0.979638\tvalid_1's auc: 0.911259\n",
      "Early stopping, best iteration is:\n",
      "[8007]\ttraining's auc: 0.969483\tvalid_1's auc: 0.911703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [10:56, 214.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.9201\tvalid_1's auc: 0.900133\n",
      "[2000]\ttraining's auc: 0.93318\tvalid_1's auc: 0.904405\n",
      "[3000]\ttraining's auc: 0.941898\tvalid_1's auc: 0.905543\n",
      "[4000]\ttraining's auc: 0.949183\tvalid_1's auc: 0.905759\n",
      "[5000]\ttraining's auc: 0.955345\tvalid_1's auc: 0.906217\n",
      "[6000]\ttraining's auc: 0.960727\tvalid_1's auc: 0.906109\n",
      "[7000]\ttraining's auc: 0.965616\tvalid_1's auc: 0.906291\n",
      "[8000]\ttraining's auc: 0.969912\tvalid_1's auc: 0.906279\n",
      "[9000]\ttraining's auc: 0.973743\tvalid_1's auc: 0.906083\n",
      "[10000]\ttraining's auc: 0.977037\tvalid_1's auc: 0.906081\n",
      "Early stopping, best iteration is:\n",
      "[7198]\ttraining's auc: 0.966446\tvalid_1's auc: 0.906351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [14:31, 214.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.920608\tvalid_1's auc: 0.895588\n",
      "[2000]\ttraining's auc: 0.933818\tvalid_1's auc: 0.898823\n",
      "[3000]\ttraining's auc: 0.942431\tvalid_1's auc: 0.899759\n",
      "[4000]\ttraining's auc: 0.949439\tvalid_1's auc: 0.900026\n",
      "[5000]\ttraining's auc: 0.955541\tvalid_1's auc: 0.900146\n",
      "[6000]\ttraining's auc: 0.960913\tvalid_1's auc: 0.900638\n",
      "[7000]\ttraining's auc: 0.965769\tvalid_1's auc: 0.900762\n",
      "[8000]\ttraining's auc: 0.9701\tvalid_1's auc: 0.900705\n",
      "[9000]\ttraining's auc: 0.973856\tvalid_1's auc: 0.900684\n",
      "[10000]\ttraining's auc: 0.977302\tvalid_1's auc: 0.900382\n",
      "Early stopping, best iteration is:\n",
      "[7102]\ttraining's auc: 0.966275\tvalid_1's auc: 0.900792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "5it [17:49, 209.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.9197\tvalid_1's auc: 0.903462\n",
      "[2000]\ttraining's auc: 0.932827\tvalid_1's auc: 0.90745\n",
      "[3000]\ttraining's auc: 0.941541\tvalid_1's auc: 0.908864\n",
      "[4000]\ttraining's auc: 0.948567\tvalid_1's auc: 0.909714\n",
      "[5000]\ttraining's auc: 0.954807\tvalid_1's auc: 0.910207\n",
      "[6000]\ttraining's auc: 0.960327\tvalid_1's auc: 0.910669\n",
      "[7000]\ttraining's auc: 0.965064\tvalid_1's auc: 0.910788\n",
      "[8000]\ttraining's auc: 0.969458\tvalid_1's auc: 0.910879\n",
      "[9000]\ttraining's auc: 0.973243\tvalid_1's auc: 0.910997\n",
      "[10000]\ttraining's auc: 0.97669\tvalid_1's auc: 0.91114\n",
      "[11000]\ttraining's auc: 0.979693\tvalid_1's auc: 0.911236\n",
      "[12000]\ttraining's auc: 0.982321\tvalid_1's auc: 0.911209\n",
      "[13000]\ttraining's auc: 0.984637\tvalid_1's auc: 0.911093\n",
      "Early stopping, best iteration is:\n",
      "[10676]\ttraining's auc: 0.978779\tvalid_1's auc: 0.911252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6it [22:09, 224.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.920379\tvalid_1's auc: 0.899626\n",
      "[2000]\ttraining's auc: 0.933612\tvalid_1's auc: 0.903387\n",
      "[3000]\ttraining's auc: 0.942232\tvalid_1's auc: 0.904285\n",
      "[4000]\ttraining's auc: 0.949305\tvalid_1's auc: 0.904866\n",
      "[5000]\ttraining's auc: 0.955561\tvalid_1's auc: 0.905141\n",
      "[6000]\ttraining's auc: 0.961023\tvalid_1's auc: 0.905359\n",
      "[7000]\ttraining's auc: 0.965815\tvalid_1's auc: 0.905533\n",
      "[8000]\ttraining's auc: 0.970027\tvalid_1's auc: 0.905591\n",
      "[9000]\ttraining's auc: 0.973759\tvalid_1's auc: 0.905658\n",
      "[10000]\ttraining's auc: 0.977003\tvalid_1's auc: 0.905333\n",
      "[11000]\ttraining's auc: 0.979949\tvalid_1's auc: 0.905232\n",
      "[12000]\ttraining's auc: 0.982579\tvalid_1's auc: 0.905057\n",
      "Early stopping, best iteration is:\n",
      "[9117]\ttraining's auc: 0.974128\tvalid_1's auc: 0.90571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "7it [26:03, 227.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.919652\tvalid_1's auc: 0.906756\n",
      "[2000]\ttraining's auc: 0.933024\tvalid_1's auc: 0.909294\n",
      "[3000]\ttraining's auc: 0.94179\tvalid_1's auc: 0.909996\n",
      "[4000]\ttraining's auc: 0.948716\tvalid_1's auc: 0.910027\n",
      "[5000]\ttraining's auc: 0.954873\tvalid_1's auc: 0.910182\n",
      "[6000]\ttraining's auc: 0.960384\tvalid_1's auc: 0.910146\n",
      "[7000]\ttraining's auc: 0.965259\tvalid_1's auc: 0.909813\n",
      "Early stopping, best iteration is:\n",
      "[4622]\ttraining's auc: 0.952661\tvalid_1's auc: 0.910191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "8it [28:35, 204.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.919853\tvalid_1's auc: 0.903987\n",
      "[2000]\ttraining's auc: 0.933147\tvalid_1's auc: 0.907318\n",
      "[3000]\ttraining's auc: 0.94201\tvalid_1's auc: 0.908192\n",
      "[4000]\ttraining's auc: 0.949046\tvalid_1's auc: 0.908357\n",
      "[5000]\ttraining's auc: 0.955068\tvalid_1's auc: 0.908437\n",
      "[6000]\ttraining's auc: 0.960661\tvalid_1's auc: 0.908455\n",
      "[7000]\ttraining's auc: 0.965638\tvalid_1's auc: 0.908523\n",
      "[8000]\ttraining's auc: 0.969926\tvalid_1's auc: 0.90834\n",
      "[9000]\ttraining's auc: 0.973737\tvalid_1's auc: 0.908257\n",
      "[10000]\ttraining's auc: 0.977115\tvalid_1's auc: 0.907904\n",
      "Early stopping, best iteration is:\n",
      "[7124]\ttraining's auc: 0.96619\tvalid_1's auc: 0.908576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "9it [31:53, 202.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.919515\tvalid_1's auc: 0.906062\n",
      "[2000]\ttraining's auc: 0.932855\tvalid_1's auc: 0.910475\n",
      "[3000]\ttraining's auc: 0.941545\tvalid_1's auc: 0.911891\n",
      "[4000]\ttraining's auc: 0.948608\tvalid_1's auc: 0.912366\n",
      "[5000]\ttraining's auc: 0.954897\tvalid_1's auc: 0.912562\n",
      "[6000]\ttraining's auc: 0.960501\tvalid_1's auc: 0.912759\n",
      "[7000]\ttraining's auc: 0.965461\tvalid_1's auc: 0.912784\n",
      "[8000]\ttraining's auc: 0.969787\tvalid_1's auc: 0.912835\n",
      "[9000]\ttraining's auc: 0.973611\tvalid_1's auc: 0.912665\n",
      "[10000]\ttraining's auc: 0.977027\tvalid_1's auc: 0.912705\n",
      "Early stopping, best iteration is:\n",
      "[7393]\ttraining's auc: 0.967148\tvalid_1's auc: 0.912876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [35:13, 211.38s/it]\n"
     ]
    }
   ],
   "source": [
    "predictions = np.zeros(len(x_test))\n",
    "num_models = 0\n",
    "\n",
    "for train_index, valid_index in tqdm(kf.split(train_x, y_train)):\n",
    "    \n",
    "    d_train = lgb.Dataset(train_x.iloc[train_index], label=y_train[train_index])\n",
    "    d_val = lgb.Dataset(train_x.iloc[valid_index], label=y_train[valid_index])\n",
    "\n",
    "    clf = lgb.train(lgb_params, d_train, 130000, verbose_eval=1000, \n",
    "                    valid_sets = [d_train, d_val], early_stopping_rounds = 3000)\n",
    "    \n",
    "\n",
    "    \n",
    "    num_models += 1\n",
    "    \n",
    "    predictions += clf.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_10 = predictions / 10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sub = x_test[['encounter_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/s0c02nj/anaconda2/envs/graph/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "data_sub['hospital_death'] = predictions_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sub.to_csv('/Users/s0c02nj/Desktop/WiDS/sub_lgb_keeping_missing_as_it_is_no_cat_agg_10th_feb.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = pd.read_csv('/Users/s0c02nj/Desktop/WiDS/Submission/sub_ensemble.csv')\n",
    "a2 = pd.read_csv('/Users/s0c02nj/Desktop/WiDS/Submission/sub_ensemble_gm.csv')\n",
    "a3 = pd.read_csv('/Users/s0c02nj/Desktop/WiDS/Submission/sub_ensemble_gm1.csv')\n",
    "a4 = pd.read_csv('/Users/s0c02nj/Desktop/WiDS/sub_ensemble_gm2.csv')\n",
    "a5 = pd.read_csv('/Users/s0c02nj/Desktop/WiDS/sub8_lgb_10fold1.csv')\n",
    "a6 = pd.read_csv('/Users/s0c02nj/Desktop/WiDS/sub8_lgb_10fold.csv')\n",
    "a7 = pd.read_csv('/Users/s0c02nj/Desktop/WiDS/sub10_lgb_kfold2.csv')\n",
    "a8 = pd.read_csv('/Users/s0c02nj/Desktop/WiDS/xgboost.csv')\n",
    "a9 = pd.read_csv('/Users/s0c02nj/Desktop/WiDS/sub11_ensemble_imp1.csv')\n",
    "a10 = pd.read_csv('/Users/s0c02nj/Desktop/WiDS/sub12_catb.csv')\n",
    "a11 = pd.read_csv('/Users/s0c02nj/Desktop/WiDS/sub3_lgb_ensemble1_01022020.csv')\n",
    "a12 = pd.read_csv('/Users/s0c02nj/Desktop/WiDS/sub4_ensemble1_01022020.csv')\n",
    "a13 = pd.read_csv('/Users/s0c02nj/Desktop/WiDS/sub2_lgb_01022020.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame()\n",
    "sub['encounter_id'] = a1['encounter_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ens = (a1['hospital_death'] + a2['hospital_death'] + a3['hospital_death'] + \n",
    "            a4['hospital_death'] + a5['hospital_death'] + a6['hospital_death'] +\n",
    "            a7['hospital_death'] + a8['hospital_death'] + a9['hospital_death'] +\n",
    "            a10['hospital_death'] + a11['hospital_death'] + a12['hospital_death'] +\n",
    "            a13['hospital_death']\n",
    "           )/13.0\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['hospital_death'] = pred_ens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('/Users/s0c02nj/Desktop/WiDS/sub3_ensemble_01022020.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_x['encounter_id'].unique().shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#last let us make the submission,note that you have to make the pred to be int!\n",
    "pred = model.predict_proba(test_x)\n",
    "preds= pred[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sub = x_test[['encounter_id']]\n",
    "data_sub['hospital_death'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sub.to_csv('/Users/s0c02nj/Desktop/WiDS/sub2.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

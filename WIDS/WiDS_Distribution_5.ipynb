{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import metrics, preprocessing\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from catboost import Pool, CatBoostClassifier\n",
    "import lightgbm as lgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing\n",
    "train_data = pd.read_csv('/Users/s0c02nj/Desktop/WiDS/training_v2.csv')\n",
    "test_data =  pd.read_csv('/Users/s0c02nj/Desktop/WiDS/unlabeled.csv')\n",
    "\n",
    "sub_data = pd.read_csv('/Users/s0c02nj/Desktop/WiDS/samplesubmission.csv')\n",
    "data_dict = pd.read_csv('/Users/s0c02nj/Desktop/WiDS/WiDS Datathon 2020 Dictionary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_classt(x): \n",
    "    if pd.isna(x):\n",
    "        return np.nan\n",
    "    elif x < 15: \n",
    "        return 'very severely underweight' \n",
    "    elif x >= 15 and x < 16: \n",
    "        return 'severely weight' \n",
    "    elif x >=16 and x < 18.5: \n",
    "        return 'underweight' \n",
    "    elif x >= 18.5 and x < 25: \n",
    "        return 'healthy weight' \n",
    "    elif x >= 25 and x < 30: \n",
    "        return 'overweight'\n",
    "    elif x >= 30 and x < 35: \n",
    "        return 'class 1' \n",
    "    elif x >= 35 and x < 40: \n",
    "        return 'class 2' \n",
    "    else: \n",
    "        return 'class 3' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['weightclass'] = train_data['bmi'].map(weighted_classt)\n",
    "test_data['weightclass'] = test_data['bmi'].map(weighted_classt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_var = list(data_dict[data_dict['Data Type'].isin(['binary','string','integer'])]['Variable Name'])\n",
    "cat_var.remove('icu_admit_type')\n",
    "cat_var.remove('bmi')\n",
    "cat_var = cat_var[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cat_var = cat_var[1:]\n",
    "#cat_var = cat_var[1:]\n",
    "cat_var = cat_var + ['weightclass']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_var = list(data_dict[data_dict['Data Type'].isin(['numeric'])]['Variable Name'])\n",
    "cont_var.remove('pred')\n",
    "cont_var = cont_var + ['bmi']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_data.drop('hospital_death',axis=1)\n",
    "y_train = train_data['hospital_death']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = test_data.drop('hospital_death',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_comb = pd.concat([x_train,x_test],sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131021/131021 [00:06<00:00, 20221.92it/s]\n"
     ]
    }
   ],
   "source": [
    "### impute bmi values based on height and weight\n",
    "count = 0\n",
    "bmi_list = []\n",
    "for i in tqdm(range(x_comb.shape[0])):\n",
    "    \n",
    "    if pd.isnull(x_comb[\"weight\"].iloc[i]) or pd.isnull(x_comb[\"height\"].iloc[i]):\n",
    "        bmi_list.append(x_comb[\"bmi\"].iloc[i])\n",
    "        continue\n",
    "    else:\n",
    "        \n",
    "        count += 1\n",
    "        bmi_list.append(x_comb[\"weight\"].iloc[i] / ((x_comb[\"height\"].iloc[i]/100) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_comb['bmi'] = bmi_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_comb['apache_2_bodysystem'] = x_comb['apache_2_bodysystem'].str.replace('Undefined Diagnoses', 'Undefined diagnoses', regex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_comb[\"apache_4a_hospital_death_prob\"] = x_comb[\"apache_4a_hospital_death_prob\"].replace(-1, np.nan)\n",
    "x_comb[\"apache_4a_icu_death_prob\"] = x_comb[\"apache_4a_icu_death_prob\"].replace(-1, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cat_var = list(set(cat_var).intersection(set(x_comb.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:03<00:00,  8.56it/s]\n"
     ]
    }
   ],
   "source": [
    "for col in tqdm(new_cat_var):\n",
    "    le = LabelEncoder()\n",
    "    x_comb[col] = le.fit_transform(x_comb[col].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cont_var = list(set(cont_var).intersection(set(x_comb.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62.00996491901006"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_comb[\"age\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in tqdm(new_cont_var):\n",
    "#     x_comb[col] = x_comb[col].fillna(x_comb[col].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32it [00:01, 17.57it/s]\n"
     ]
    }
   ],
   "source": [
    "count_var = []\n",
    "for i,col in tqdm(enumerate(new_cat_var)):\n",
    "    counter = Counter(x_comb[col])\n",
    "    x_comb[str(col)+'count'] = x_comb[col].apply(lambda x:counter[x])\n",
    "    count_var.append(str(col)+'count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131021/131021 [00:01<00:00, 73236.18it/s]\n"
     ]
    }
   ],
   "source": [
    "age_cat = []\n",
    "\n",
    "for i in tqdm(range(0,len(x_comb))):\n",
    "    \n",
    "    val = x_comb['age'].iloc[i]\n",
    "    \n",
    "    if val >= 15 and val <= 24: \n",
    "        age_cat.append('igen')\n",
    "    \n",
    "    elif val >= 25 and val <= 54: \n",
    "       age_cat.append('Prime_working_Age')\n",
    "    \n",
    "    elif val >= 55 and val <= 64: \n",
    "        age_cat.append('Mature_working_Age')\n",
    "        \n",
    "    else: \n",
    "        age_cat.append('Elderly_working_Age')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_comb['age_category'] = age_cat\n",
    "le = LabelEncoder()\n",
    "x_comb['age_category'] = le.fit_transform(x_comb['age_category'].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List to be biined -----> VITALS\n",
    "to_binned_columns = list(data_dict[data_dict['Category'] == 'APACHE covariate']['Variable Name'].unique())\n",
    "to_binned_columns = list(set(to_binned_columns).intersection(set(x_comb.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 36.68it/s]\n"
     ]
    }
   ],
   "source": [
    "#inter_cols3\n",
    "#x_comb['d1_heartrate_max_cat'] = \n",
    "\n",
    "binned_cols = []\n",
    "\n",
    "for cols in tqdm(to_binned_columns) :\n",
    "    x_comb[cols+'_binned'] = list(pd.cut(x_comb[cols], 10,labels=False))\n",
    "    binned_cols.append(cols+'_binned')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_comb['height'+'_binned'] = list(pd.cut(x_comb['height'], 10,labels=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#binned_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data.columns[0:100]\n",
    "\n",
    "# list_imp_cols = ['icu_type','weightclass','age_category','gender','d1_heartrate_max_binned','height_binned']\n",
    "\n",
    "# inter_cols4 = []\n",
    "\n",
    "# for col1 in tqdm(list_imp_cols) :\n",
    "#     for col2 in list_imp_cols:\n",
    "#         if col1 !=col2 :\n",
    "#             x_comb[col1+col2] = x_comb[col1].astype(str) + '_' + x_comb[col2].astype(str)\n",
    "#             inter_cols4.append(col1+col2)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for cols in tqdm(inter_cols4):\n",
    "#     le = LabelEncoder()\n",
    "#     x_comb[cols] = le.fit_transform(x_comb[cols].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2way interaction\n",
    "bias_cols = ['gender','age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:07<00:00,  3.60s/it]\n"
     ]
    }
   ],
   "source": [
    "inter_cols6 = []\n",
    "\n",
    "for i in tqdm(bias_cols):\n",
    "    \n",
    "    for j in binned_cols :\n",
    "        \n",
    "        x_comb[i+'_'+j] = x_comb[i].astype(str) + '_' + x_comb[j].astype(str)\n",
    "        \n",
    "        inter_cols6.append(i+'_'+j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Critical -3way interaction\n",
    "\n",
    "# inter_cols6 = []\n",
    "\n",
    "x_comb['age'+'gender'+'weighted_classt'] = x_comb['age'].astype(str) + '_' + x_comb['gender'].astype(str) + '_' + x_comb['weightclass'].astype(str)\n",
    "x_comb['age'+'gender'+'ethnicity'] = x_comb['age'].astype(str) + '_' + x_comb['gender'].astype(str) + '_' + x_comb['ethnicity'].astype(str)\n",
    "\n",
    "inter_cols6 = inter_cols6 + ['age'+'gender'+'weighted_classt'] +['age'+'gender'+'ethnicity']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 58/58 [00:02<00:00, 26.31it/s]\n"
     ]
    }
   ],
   "source": [
    "for cols in tqdm(inter_cols6):\n",
    "    le = LabelEncoder()\n",
    "    x_comb[cols] = le.fit_transform(x_comb[cols].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_cat_var = new_cat_var + count_var + ['age_category'] + inter_cols1 + inter_cols2 + inter_cols3 + inter_cols4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Target Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_train = x_train.copy()\n",
    "temp_train['hospital_death'] = train_data['hospital_death']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32it [00:00, 56.82it/s]\n"
     ]
    }
   ],
   "source": [
    "cat_count_var = []\n",
    "\n",
    "for i,col in tqdm(enumerate(new_cat_var)):\n",
    "    mean = temp_train['hospital_death'].mean()\n",
    "    \n",
    "    #Compute the number of values and the mean of each group\n",
    "    agg = temp_train.groupby(col)['hospital_death'].agg(['count', 'mean'])\n",
    "    counts = agg['count']\n",
    "    means =  agg['mean']\n",
    "    \n",
    "    #Compute the \"smoothed\" means\n",
    "    m= 3\n",
    "    smooth = (counts * means + m * mean) / (counts + m)\n",
    "    \n",
    "    #Final_val\n",
    "    x_comb[str(col)+'count_new'] = x_comb[col].map(smooth)\n",
    "    cat_count_var.append(str(col)+'count_new')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(131021, 338)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_comb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Remove Features with more than 70 percent missing values\n",
    "data_missing = (x_comb.isnull().sum() / len(x_comb)).sort_values(ascending = False)\n",
    "data_missing = data_missing.index[data_missing > 0.9]\n",
    "\n",
    "x_comb = x_comb.drop(columns = data_missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_count_var_new = list(set(cat_count_var).intersection(x_comb.columns))\n",
    "#x_comb.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:05<00:00,  4.04it/s]\n"
     ]
    }
   ],
   "source": [
    "for col in tqdm(cat_count_var_new):\n",
    "    le = LabelEncoder()\n",
    "    x_comb[col] = le.fit_transform(x_comb[col].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:00<00:00, 58584.78it/s]\n"
     ]
    }
   ],
   "source": [
    "aggs = {}\n",
    "\n",
    "for col in tqdm(new_cat_var):\n",
    "    aggs[col] = ['nunique','count']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cat_var = list(set(new_cat_var).intersection(set(x_comb.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_cat_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [09:34<00:00, 17.95s/it]\n"
     ]
    }
   ],
   "source": [
    "for col in tqdm(new_cat_var):\n",
    "    \n",
    "    aggs_temp = aggs.copy()\n",
    "    aggs_temp.pop(col)\n",
    "    \n",
    "    agg_df = x_comb.groupby(col).agg(aggs_temp).reset_index()\n",
    "    agg_df.columns = [col] + [col + '_' + c[0] +'_' + c[1] for c in agg_df.columns[1:]]\n",
    "    \n",
    "    x_comb = pd.merge(left = x_comb, right= agg_df, how='left',\n",
    "                    left_on=[col], right_on=[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_comb['hospital_icu_id'] = x_comb['hospital_id'].astype(str) + '_' +  x_comb['icu_id'].astype(str)\n",
    "\n",
    "le = LabelEncoder()\n",
    "x_comb['hospital_icu_id'] = le.fit_transform(x_comb['hospital_icu_id'].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_comb = x_comb.drop(['encounter_id','patient_id'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = x_comb[0:91713]\n",
    "test_x = x_comb[91713:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(131021, 2304)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_comb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_train, x1_val, y1_train, y1_val = train_test_split(train_x, y_train, \n",
    "                                                      test_size=0.2,\n",
    "                                                      random_state=0,\n",
    "                                                      stratify = y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42\n",
    "np.random.seed(random_state)\n",
    "\n",
    "lgb_params = {\n",
    "    'boost': 'gbdt',\n",
    "    'learning_rate': 0.01,\n",
    "    'max_depth':8,\n",
    "    'metric':{'auc'},\n",
    "    'num_threads': -1,\n",
    "    'objective': 'binary',\n",
    "    'verbosity': 1,\n",
    "    'num_leaves':16,\n",
    "    'bagging_fraction':0.5, #rows\n",
    "    'bagging_frequency':5,\n",
    "    'min_data_in_leaf':50,\n",
    "    'feature_fraction':0.22, # features\n",
    "    'lambda_l1':10,\n",
    "    'lambda_l2':15,\n",
    "    'bagging_seed':2019,\n",
    "    'min_gain_split':0.3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_data = lgb.Dataset(x1_train, label= y1_train)\n",
    "val_data = lgb.Dataset(x1_val,  label=  y1_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 2000 rounds.\n",
      "[200]\ttraining's auc: 0.896847\tvalid_1's auc: 0.885632\n",
      "[400]\ttraining's auc: 0.906869\tvalid_1's auc: 0.892779\n",
      "[600]\ttraining's auc: 0.913636\tvalid_1's auc: 0.897051\n",
      "[800]\ttraining's auc: 0.918444\tvalid_1's auc: 0.899408\n",
      "[1000]\ttraining's auc: 0.922192\tvalid_1's auc: 0.900987\n",
      "[1200]\ttraining's auc: 0.925495\tvalid_1's auc: 0.902081\n",
      "[1400]\ttraining's auc: 0.928392\tvalid_1's auc: 0.902944\n",
      "[1600]\ttraining's auc: 0.931022\tvalid_1's auc: 0.90354\n",
      "[1800]\ttraining's auc: 0.933479\tvalid_1's auc: 0.904095\n",
      "[2000]\ttraining's auc: 0.935665\tvalid_1's auc: 0.904533\n",
      "[2200]\ttraining's auc: 0.937692\tvalid_1's auc: 0.904851\n",
      "[2400]\ttraining's auc: 0.939616\tvalid_1's auc: 0.905111\n",
      "[2600]\ttraining's auc: 0.941415\tvalid_1's auc: 0.905327\n",
      "[2800]\ttraining's auc: 0.943145\tvalid_1's auc: 0.905545\n",
      "[3000]\ttraining's auc: 0.944767\tvalid_1's auc: 0.905721\n",
      "[3200]\ttraining's auc: 0.946368\tvalid_1's auc: 0.905913\n",
      "[3400]\ttraining's auc: 0.947951\tvalid_1's auc: 0.905984\n",
      "[3600]\ttraining's auc: 0.94946\tvalid_1's auc: 0.906146\n",
      "[3800]\ttraining's auc: 0.950918\tvalid_1's auc: 0.906284\n",
      "[4000]\ttraining's auc: 0.952328\tvalid_1's auc: 0.906354\n",
      "[4200]\ttraining's auc: 0.953665\tvalid_1's auc: 0.906429\n",
      "[4400]\ttraining's auc: 0.954941\tvalid_1's auc: 0.906499\n",
      "[4600]\ttraining's auc: 0.956235\tvalid_1's auc: 0.906569\n",
      "[4800]\ttraining's auc: 0.957462\tvalid_1's auc: 0.906592\n",
      "[5000]\ttraining's auc: 0.958628\tvalid_1's auc: 0.906642\n",
      "[5200]\ttraining's auc: 0.959793\tvalid_1's auc: 0.906698\n",
      "[5400]\ttraining's auc: 0.960965\tvalid_1's auc: 0.906681\n",
      "[5600]\ttraining's auc: 0.962021\tvalid_1's auc: 0.906756\n",
      "[5800]\ttraining's auc: 0.963106\tvalid_1's auc: 0.906761\n",
      "[6000]\ttraining's auc: 0.96417\tvalid_1's auc: 0.906843\n",
      "[6200]\ttraining's auc: 0.96517\tvalid_1's auc: 0.906887\n",
      "[6400]\ttraining's auc: 0.966201\tvalid_1's auc: 0.906871\n",
      "[6600]\ttraining's auc: 0.967149\tvalid_1's auc: 0.906867\n",
      "[6800]\ttraining's auc: 0.968099\tvalid_1's auc: 0.906887\n",
      "[7000]\ttraining's auc: 0.96896\tvalid_1's auc: 0.90692\n",
      "[7200]\ttraining's auc: 0.969859\tvalid_1's auc: 0.906872\n",
      "[7400]\ttraining's auc: 0.970716\tvalid_1's auc: 0.906893\n",
      "[7600]\ttraining's auc: 0.971481\tvalid_1's auc: 0.906858\n",
      "[7800]\ttraining's auc: 0.972279\tvalid_1's auc: 0.906903\n",
      "[8000]\ttraining's auc: 0.973068\tvalid_1's auc: 0.906882\n",
      "[8200]\ttraining's auc: 0.973827\tvalid_1's auc: 0.906923\n",
      "[8400]\ttraining's auc: 0.974545\tvalid_1's auc: 0.906886\n",
      "[8600]\ttraining's auc: 0.97527\tvalid_1's auc: 0.906869\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-1f5c321777ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0mvalid_sets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtrn_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                     \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                     \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m                     )\n",
      "\u001b[0;32m~/anaconda2/envs/graph/lib/python3.6/site-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    216\u001b[0m                                     evaluation_result_list=None))\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m         \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mevaluation_result_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/graph/lib/python3.6/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   1800\u001b[0m             _safe_call(_LIB.LGBM_BoosterUpdateOneIter(\n\u001b[1;32m   1801\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1802\u001b[0;31m                 ctypes.byref(is_finished)))\n\u001b[0m\u001b[1;32m   1803\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__is_predicted_cur_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mFalse\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__num_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1804\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mis_finished\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lgb_clf = lgb.train(lgb_params,\n",
    "                    trn_data,\n",
    "                    13000,\n",
    "                    valid_sets = [trn_data, val_data],\n",
    "                    early_stopping_rounds=2000,\n",
    "                    verbose_eval=200\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = lgb_clf.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sub = x_test[['encounter_id']]\n",
    "data_sub['hospital_death'] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sub.to_csv('/Users/s0c02nj/Desktop/WiDS/sub31_5thFeb2020_binned_labs blood gas.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(figsize=(12,30))\n",
    "# lgb.plot_importance(lgb_clf, max_num_features=250, height=0.8, ax=ax)\n",
    "# ax.grid(False)\n",
    "# plt.title(\"LightGBM - Feature Importance\", fontsize=12)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = StratifiedKFold(n_splits=10, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.920417\tvalid_1's auc: 0.902754\n",
      "[2000]\ttraining's auc: 0.933226\tvalid_1's auc: 0.906563\n",
      "[3000]\ttraining's auc: 0.942091\tvalid_1's auc: 0.908105\n",
      "[4000]\ttraining's auc: 0.949379\tvalid_1's auc: 0.908666\n",
      "[5000]\ttraining's auc: 0.95565\tvalid_1's auc: 0.908981\n",
      "[6000]\ttraining's auc: 0.961051\tvalid_1's auc: 0.909103\n",
      "[7000]\ttraining's auc: 0.965872\tvalid_1's auc: 0.909136\n",
      "[8000]\ttraining's auc: 0.970041\tvalid_1's auc: 0.909164\n",
      "[9000]\ttraining's auc: 0.973656\tvalid_1's auc: 0.909047\n",
      "[10000]\ttraining's auc: 0.976991\tvalid_1's auc: 0.908961\n",
      "Early stopping, best iteration is:\n",
      "[7672]\ttraining's auc: 0.968739\tvalid_1's auc: 0.909209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "1it [05:51, 351.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.919719\tvalid_1's auc: 0.909166\n",
      "[2000]\ttraining's auc: 0.932692\tvalid_1's auc: 0.913696\n",
      "[3000]\ttraining's auc: 0.941439\tvalid_1's auc: 0.915035\n",
      "[4000]\ttraining's auc: 0.948543\tvalid_1's auc: 0.915442\n",
      "[5000]\ttraining's auc: 0.954818\tvalid_1's auc: 0.915607\n",
      "[6000]\ttraining's auc: 0.960237\tvalid_1's auc: 0.915833\n",
      "[7000]\ttraining's auc: 0.965021\tvalid_1's auc: 0.915728\n",
      "[8000]\ttraining's auc: 0.969325\tvalid_1's auc: 0.915539\n",
      "Early stopping, best iteration is:\n",
      "[5872]\ttraining's auc: 0.95959\tvalid_1's auc: 0.915885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [10:43, 333.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.92012\tvalid_1's auc: 0.908038\n",
      "[2000]\ttraining's auc: 0.933179\tvalid_1's auc: 0.911522\n",
      "[3000]\ttraining's auc: 0.942034\tvalid_1's auc: 0.912424\n",
      "[4000]\ttraining's auc: 0.949271\tvalid_1's auc: 0.912649\n",
      "[5000]\ttraining's auc: 0.95542\tvalid_1's auc: 0.912638\n",
      "[6000]\ttraining's auc: 0.960768\tvalid_1's auc: 0.912654\n",
      "[7000]\ttraining's auc: 0.965441\tvalid_1's auc: 0.912841\n",
      "[8000]\ttraining's auc: 0.969617\tvalid_1's auc: 0.912914\n",
      "[9000]\ttraining's auc: 0.97341\tvalid_1's auc: 0.912822\n",
      "[10000]\ttraining's auc: 0.976686\tvalid_1's auc: 0.912814\n",
      "Early stopping, best iteration is:\n",
      "[7875]\ttraining's auc: 0.969133\tvalid_1's auc: 0.912954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [16:39, 340.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.920719\tvalid_1's auc: 0.900629\n",
      "[2000]\ttraining's auc: 0.933298\tvalid_1's auc: 0.905078\n",
      "[3000]\ttraining's auc: 0.942022\tvalid_1's auc: 0.906122\n",
      "[4000]\ttraining's auc: 0.94932\tvalid_1's auc: 0.906536\n",
      "[5000]\ttraining's auc: 0.955529\tvalid_1's auc: 0.906821\n",
      "[6000]\ttraining's auc: 0.96086\tvalid_1's auc: 0.907004\n",
      "[7000]\ttraining's auc: 0.965545\tvalid_1's auc: 0.907111\n",
      "[8000]\ttraining's auc: 0.969773\tvalid_1's auc: 0.907282\n",
      "[9000]\ttraining's auc: 0.97354\tvalid_1's auc: 0.90717\n",
      "[10000]\ttraining's auc: 0.97689\tvalid_1's auc: 0.907151\n",
      "Early stopping, best iteration is:\n",
      "[7810]\ttraining's auc: 0.969004\tvalid_1's auc: 0.907311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [22:28, 342.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.921042\tvalid_1's auc: 0.896435\n",
      "[2000]\ttraining's auc: 0.933953\tvalid_1's auc: 0.8994\n",
      "[3000]\ttraining's auc: 0.942675\tvalid_1's auc: 0.900335\n",
      "[4000]\ttraining's auc: 0.949764\tvalid_1's auc: 0.900519\n",
      "[5000]\ttraining's auc: 0.955953\tvalid_1's auc: 0.900407\n",
      "[6000]\ttraining's auc: 0.961332\tvalid_1's auc: 0.900429\n",
      "Early stopping, best iteration is:\n",
      "[3546]\ttraining's auc: 0.946666\tvalid_1's auc: 0.900589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "5it [26:18, 309.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.920248\tvalid_1's auc: 0.903826\n",
      "[2000]\ttraining's auc: 0.932846\tvalid_1's auc: 0.907943\n",
      "[3000]\ttraining's auc: 0.941505\tvalid_1's auc: 0.909012\n",
      "[4000]\ttraining's auc: 0.948738\tvalid_1's auc: 0.909934\n",
      "[5000]\ttraining's auc: 0.954889\tvalid_1's auc: 0.910558\n",
      "[6000]\ttraining's auc: 0.960416\tvalid_1's auc: 0.911064\n",
      "[7000]\ttraining's auc: 0.965193\tvalid_1's auc: 0.911387\n",
      "[8000]\ttraining's auc: 0.969346\tvalid_1's auc: 0.911499\n",
      "[9000]\ttraining's auc: 0.973164\tvalid_1's auc: 0.911667\n",
      "[10000]\ttraining's auc: 0.976583\tvalid_1's auc: 0.911836\n",
      "[11000]\ttraining's auc: 0.979513\tvalid_1's auc: 0.911937\n",
      "[12000]\ttraining's auc: 0.98216\tvalid_1's auc: 0.911944\n",
      "[13000]\ttraining's auc: 0.984403\tvalid_1's auc: 0.911959\n",
      "[14000]\ttraining's auc: 0.986455\tvalid_1's auc: 0.912015\n",
      "[15000]\ttraining's auc: 0.988225\tvalid_1's auc: 0.911932\n",
      "[16000]\ttraining's auc: 0.989792\tvalid_1's auc: 0.91176\n",
      "[17000]\ttraining's auc: 0.991139\tvalid_1's auc: 0.911747\n",
      "Early stopping, best iteration is:\n",
      "[14573]\ttraining's auc: 0.987505\tvalid_1's auc: 0.91203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6it [34:57, 372.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.920902\tvalid_1's auc: 0.900675\n",
      "[2000]\ttraining's auc: 0.933816\tvalid_1's auc: 0.904187\n",
      "[3000]\ttraining's auc: 0.942452\tvalid_1's auc: 0.905307\n",
      "[4000]\ttraining's auc: 0.949599\tvalid_1's auc: 0.905808\n",
      "[5000]\ttraining's auc: 0.955836\tvalid_1's auc: 0.906222\n",
      "[6000]\ttraining's auc: 0.961135\tvalid_1's auc: 0.906259\n",
      "[7000]\ttraining's auc: 0.965807\tvalid_1's auc: 0.906153\n",
      "[8000]\ttraining's auc: 0.970017\tvalid_1's auc: 0.90627\n",
      "[9000]\ttraining's auc: 0.973719\tvalid_1's auc: 0.90608\n",
      "[10000]\ttraining's auc: 0.977014\tvalid_1's auc: 0.905968\n",
      "[11000]\ttraining's auc: 0.97994\tvalid_1's auc: 0.905742\n",
      "Early stopping, best iteration is:\n",
      "[8172]\ttraining's auc: 0.97072\tvalid_1's auc: 0.906302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "7it [41:00, 369.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.920281\tvalid_1's auc: 0.907598\n",
      "[2000]\ttraining's auc: 0.933158\tvalid_1's auc: 0.909488\n",
      "[3000]\ttraining's auc: 0.941894\tvalid_1's auc: 0.91028\n",
      "[4000]\ttraining's auc: 0.949008\tvalid_1's auc: 0.910479\n",
      "[5000]\ttraining's auc: 0.955155\tvalid_1's auc: 0.910622\n",
      "[6000]\ttraining's auc: 0.960645\tvalid_1's auc: 0.910528\n",
      "[7000]\ttraining's auc: 0.96544\tvalid_1's auc: 0.910308\n",
      "[8000]\ttraining's auc: 0.969778\tvalid_1's auc: 0.910237\n",
      "Early stopping, best iteration is:\n",
      "[5004]\ttraining's auc: 0.955177\tvalid_1's auc: 0.910631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "8it [45:31, 339.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.920399\tvalid_1's auc: 0.904998\n",
      "[2000]\ttraining's auc: 0.933391\tvalid_1's auc: 0.907967\n",
      "[3000]\ttraining's auc: 0.942153\tvalid_1's auc: 0.908789\n",
      "[4000]\ttraining's auc: 0.949503\tvalid_1's auc: 0.909081\n",
      "[5000]\ttraining's auc: 0.955666\tvalid_1's auc: 0.909056\n",
      "[6000]\ttraining's auc: 0.960991\tvalid_1's auc: 0.908901\n",
      "Early stopping, best iteration is:\n",
      "[3909]\ttraining's auc: 0.948893\tvalid_1's auc: 0.909102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "9it [49:31, 309.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 3000 rounds.\n",
      "[1000]\ttraining's auc: 0.920017\tvalid_1's auc: 0.906426\n",
      "[2000]\ttraining's auc: 0.933081\tvalid_1's auc: 0.909915\n",
      "[3000]\ttraining's auc: 0.94173\tvalid_1's auc: 0.910957\n",
      "[4000]\ttraining's auc: 0.948812\tvalid_1's auc: 0.911517\n",
      "[5000]\ttraining's auc: 0.955061\tvalid_1's auc: 0.91176\n",
      "[6000]\ttraining's auc: 0.960491\tvalid_1's auc: 0.911846\n",
      "[7000]\ttraining's auc: 0.965332\tvalid_1's auc: 0.91191\n",
      "[8000]\ttraining's auc: 0.969622\tvalid_1's auc: 0.911831\n",
      "[9000]\ttraining's auc: 0.973454\tvalid_1's auc: 0.911653\n",
      "[10000]\ttraining's auc: 0.976781\tvalid_1's auc: 0.911549\n",
      "Early stopping, best iteration is:\n",
      "[7106]\ttraining's auc: 0.965792\tvalid_1's auc: 0.911943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [55:01, 330.10s/it]\n"
     ]
    }
   ],
   "source": [
    "predictions = np.zeros(len(x_test))\n",
    "num_models = 0\n",
    "\n",
    "for train_index, valid_index in tqdm(kf.split(train_x, y_train)):\n",
    "    \n",
    "    d_train = lgb.Dataset(train_x.iloc[train_index], label=y_train[train_index])\n",
    "    d_val = lgb.Dataset(train_x.iloc[valid_index], label=y_train[valid_index])\n",
    "\n",
    "    clf = lgb.train(lgb_params, d_train, 130000, verbose_eval=1000, \n",
    "                    valid_sets = [d_train, d_val], early_stopping_rounds = 3000)\n",
    "    \n",
    "\n",
    "    \n",
    "    num_models += 1\n",
    "    \n",
    "    predictions += clf.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_10 = predictions / 10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sub = x_test[['encounter_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/s0c02nj/anaconda2/envs/graph/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "data_sub['hospital_death'] = predictions_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sub.to_csv('/Users/s0c02nj/Desktop/WiDS/sub_type5_10thFeb2020_withmissing.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a1 =  pd.read_csv('/Users/s0c02nj/Desktop/WiDS/Submission/sub_ensemble.csv')\n",
    "# a2 =  pd.read_csv('/Users/s0c02nj/Desktop/WiDS/Submission/sub_ensemble_gm.csv')\n",
    "# a3 =  pd.read_csv('/Users/s0c02nj/Desktop/WiDS/Submission/sub_ensemble_gm1.csv')\n",
    "# a4 =  pd.read_csv('/Users/s0c02nj/Desktop/WiDS/sub_ensemble_gm2.csv')\n",
    "# a5 =  pd.read_csv('/Users/s0c02nj/Desktop/WiDS/sub8_lgb_10fold1.csv')\n",
    "# a6 =  pd.read_csv('/Users/s0c02nj/Desktop/WiDS/sub8_lgb_10fold.csv')\n",
    "# a7 =  pd.read_csv('/Users/s0c02nj/Desktop/WiDS/sub10_lgb_kfold2.csv')\n",
    "# a8 =  pd.read_csv('/Users/s0c02nj/Desktop/WiDS/sub5_lgb_ensemble12_fold_01022020.csv')\n",
    "# a9 =  pd.read_csv('/Users/s0c02nj/Desktop/WiDS/sub11_ensemble_imp1.csv')\n",
    "# a10 = pd.read_csv('/Users/s0c02nj/Desktop/WiDS/sub12_catb.csv')\n",
    "a11 = pd.read_csv('/Users/s0c02nj/Desktop/WiDS/sub3_lgb_ensemble1_01022020.csv')\n",
    "a12 = pd.read_csv('/Users/s0c02nj/Desktop/WiDS/sub4_ensemble1_01022020.csv')\n",
    "a13 = pd.read_csv('/Users/s0c02nj/Desktop/WiDS/sub5_lgb_ensemble12_fold_01022020.csv')\n",
    "a14 = pd.read_csv('/Users/s0c02nj/Desktop/WiDS/sub3_10fold_4thFeb2020.csv')\n",
    "a15 = pd.read_csv('/Users/s0c02nj/Desktop/WiDS/sub_ensemble_gm3.csv')\n",
    "a16 = pd.read_csv('/Users/s0c02nj/Desktop/WiDS/sub6_10fold_4thFeb2020.csv')\n",
    "a17 = pd.read_csv('/Users/s0c02nj/Desktop/WiDS/sub60_10fold_4thFeb2020.csv')\n",
    "a18 = pd.read_csv('/Users/s0c02nj/Desktop/WiDS/sub2_ensemble_5thFeb2020.csv')\n",
    "a19 = pd.read_csv('/Users/s0c02nj/Desktop/WiDS/sub_type1_type2_ensemble_5thFeb2020.csv')\n",
    "a20 = pd.read_csv('/Users/s0c02nj/Desktop/WiDS/sub31_5thFeb2020_binned_labs blood gas.csv')\n",
    "a21 = pd.read_csv('/Users/s0c02nj/Desktop/WiDS/sub_type4_6thFeb2020.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame()\n",
    "sub['encounter_id'] = a18['encounter_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ens = (\n",
    "#             a1['hospital_death'] + a2['hospital_death'] + a3['hospital_death'] + \n",
    "#             a4['hospital_death'] + a5['hospital_death'] + a6['hospital_death'] +\n",
    "#             a7['hospital_death'] + a8['hospital_death'] + a9['hospital_death'] +\n",
    "#             a10['hospital_death'] + \n",
    "            a11['hospital_death'] + a12['hospital_death'] +\n",
    "            a13['hospital_death'] + a14['hospital_death'] + a15['hospital_death'] +\n",
    "            a16['hospital_death'] + a17['hospital_death'] + a18['hospital_death'] +\n",
    "            a19['hospital_death'] + a20['hospital_death'] + a21['hospital_death']\n",
    "            \n",
    "           )/11.0\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['hospital_death'] = pred_ens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('/Users/s0c02nj/Desktop/WiDS/sub2_ensemble_6thFeb2020.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_x['encounter_id'].unique().shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#last let us make the submission,note that you have to make the pred to be int!\n",
    "pred = model.predict_proba(test_x)\n",
    "preds= pred[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sub = x_test[['encounter_id']]\n",
    "data_sub['hospital_death'] = preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sub.to_csv('/Users/s0c02nj/Desktop/WiDS/sub2.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/s0c02nj/anaconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import Ridge\n",
    "import numpy as np\n",
    "import sklearn.datasets\n",
    "#import sklearn.cross_validation\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn import ensemble\n",
    "import time\n",
    "import pickle\n",
    "import random\n",
    "from keras.layers import Dense, Flatten, LSTM, Conv1D, MaxPooling1D, Dropout, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "import keras \n",
    "from keras import backend as K\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding,Bidirectional\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras.layers import RepeatVector\n",
    "from keras.layers import Permute\n",
    "from keras.layers import merge\n",
    "from keras.layers import Lambda\n",
    "from keras.layers import multiply\n",
    "from keras.layers import concatenate\n",
    "from keras.layers import Convolution1D\n",
    "from keras.layers import MaxPooling1D\n",
    "from keras.layers import GlobalAveragePooling1D\n",
    "from keras.layers import GlobalMaxPooling1D\n",
    "\n",
    "import tensorflow as tf\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test and Train Data\n",
    "train = pd.read_csv(\"/Users/s0c02nj/Desktop/DataQuora//train.csv\",encoding=\"utf-8\")\n",
    "test = pd.read_csv(\"/Users/s0c02nj/Desktop/DataQuora//test.csv\",encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Submission File\n",
    "sub = pd.read_csv('/Users/s0c02nj/Desktop/DataQuora//sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00014894849d00ba98a9</td>\n",
       "      <td>My voice range is A2-C5. My chest voice goes u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000156468431f09b3cae</td>\n",
       "      <td>How much does a tutor earn in Bangalore?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000227734433360e1aae</td>\n",
       "      <td>What are the best made pocket knives under $20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0005e06fbe3045bd2a92</td>\n",
       "      <td>Why would they add a hypothetical scenario tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00068a0f7f41f50fc399</td>\n",
       "      <td>What is the dresscode for Techmahindra freshers?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    qid                                      question_text\n",
       "0  00014894849d00ba98a9  My voice range is A2-C5. My chest voice goes u...\n",
       "1  000156468431f09b3cae           How much does a tutor earn in Bangalore?\n",
       "2  000227734433360e1aae  What are the best made pocket knives under $20...\n",
       "3  0005e06fbe3045bd2a92  Why would they add a hypothetical scenario tha...\n",
       "4  00068a0f7f41f50fc399   What is the dresscode for Techmahindra freshers?"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1225312\n",
       "1      80810\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Counting the no of zeros and ones\n",
    "train['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distribution of words for train \n",
    "train_count=[]\n",
    "for i in train['question_text'] :\n",
    "    cnt=len(i)\n",
    "    train_count.append(cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# puncts = [',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', \"'\", '$', '&', '/', '[', ']', '>', '%', '=', '#', '*', '+', '\\\\', '•',  '~', '@', '£', \n",
    "#  '·', '_', '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', '›',  '♥', '←', '×', '§', '″', '′', 'Â', '█', '½', 'à', '…', \n",
    "#  '“', '★', '”', '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾', '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', \n",
    "#  '▒', '：', '¼', '⊕', '▼', '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲', 'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', \n",
    "#  '∙', '）', '↓', '、', '│', '（', '»', '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø', '¹', '≤', '‡', '√', ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing numbers with #\n",
    "def clean_numbers(x):\n",
    "    #Replacing 5digit numbers(0-9) numbers with ####\n",
    "    x = re.sub('[0-9]{5,}', '#####', x)\n",
    "    #Replacing 4digit numbers(0-9) numbers with ####\n",
    "    x = re.sub('[0-9]{4}', '####', x)\n",
    "    #Replacing 3digit numbers(0-9) numbers with ####\n",
    "    x = re.sub('[0-9]{3}', '###', x)\n",
    "    #Replacing 2digit numbers(0-9) numbers with ####\n",
    "    x = re.sub('[0-9]{2}', '##', x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word2vec['###']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mispell_dict = {\"aren't\" : \"are not\",\n",
    "\"can't\" : \"cannot\",\n",
    "\"couldn't\" : \"could not\",\n",
    "\"didn't\" : \"did not\",\n",
    "\"doesn't\" : \"does not\",\n",
    "\"don't\" : \"do not\",\n",
    "\"hadn't\" : \"had not\",\n",
    "\"hasn't\" : \"has not\",\n",
    "\"haven't\" : \"have not\",\n",
    "\"he'd\" : \"he would\",\n",
    "\"he'll\" : \"he will\",\n",
    "\"he's\" : \"he is\",\n",
    "\"i'd\" : \"I would\",\n",
    "\"i'd\" : \"I had\",\n",
    "\"i'll\" : \"I will\",\n",
    "\"i'm\" : \"I am\",\n",
    "\"isn't\" : \"is not\",\n",
    "\"it's\" : \"it is\",\n",
    "\"it'll\":\"it will\",\n",
    "\"i've\" : \"I have\",\n",
    "\"let's\" : \"let us\",\n",
    "\"mightn't\" : \"might not\",\n",
    "\"mustn't\" : \"must not\",\n",
    "\"shan't\" : \"shall not\",\n",
    "\"she'd\" : \"she would\",\n",
    "\"she'll\" : \"she will\",\n",
    "\"she's\" : \"she is\",\n",
    "\"shouldn't\" : \"should not\",\n",
    "\"that's\" : \"that is\",\n",
    "\"there's\" : \"there is\",\n",
    "\"they'd\" : \"they would\",\n",
    "\"they'll\" : \"they will\",\n",
    "\"they're\" : \"they are\",\n",
    "\"they've\" : \"they have\",\n",
    "\"we'd\" : \"we would\",\n",
    "\"we're\" : \"we are\",\n",
    "\"weren't\" : \"were not\",\n",
    "\"we've\" : \"we have\",\n",
    "\"what'll\" : \"what will\",\n",
    "\"what're\" : \"what are\",\n",
    "\"what's\" : \"what is\",\n",
    "\"what've\" : \"what have\",\n",
    "\"where's\" : \"where is\",\n",
    "\"who'd\" : \"who would\",\n",
    "\"who'll\" : \"who will\",\n",
    "\"who're\" : \"who are\",\n",
    "\"who's\" : \"who is\",\n",
    "\"who've\" : \"who have\",\n",
    "\"won't\" : \"will not\",\n",
    "\"wouldn't\" : \"would not\",\n",
    "\"you'd\" : \"you would\",\n",
    "\"you'll\" : \"you will\",\n",
    "\"you're\" : \"you are\",\n",
    "\"you've\" : \"you have\",\n",
    "\"'re\": \" are\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'll\":\" will\",\n",
    "\"didn't\": \"did not\",\n",
    "\"tryin'\":\"trying\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00002165364db923c7e6</td>\n",
       "      <td>How did Quebec nationalists see their province...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000032939017120e6e44</td>\n",
       "      <td>Do you have an adopted dog, how would you enco...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0000412ca6e4628ce2cf</td>\n",
       "      <td>Why does velocity affect time? Does velocity a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000042bf85aa498cd78e</td>\n",
       "      <td>How did Otto von Guericke used the Magdeburg h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0000455dfa3e01eae3af</td>\n",
       "      <td>Can I convert montra helicon D to a mountain b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    qid                                      question_text  \\\n",
       "0  00002165364db923c7e6  How did Quebec nationalists see their province...   \n",
       "1  000032939017120e6e44  Do you have an adopted dog, how would you enco...   \n",
       "2  0000412ca6e4628ce2cf  Why does velocity affect time? Does velocity a...   \n",
       "3  000042bf85aa498cd78e  How did Otto von Guericke used the Magdeburg h...   \n",
       "4  0000455dfa3e01eae3af  Can I convert montra helicon D to a mountain b...   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(train_count)\n",
    "plt.xlim(0,300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distribution of words for test \n",
    "test_count=[]\n",
    "for i in test['question_text'] :\n",
    "    cnt=len(i)\n",
    "    test_count.append(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(test_count)\n",
    "plt.xlim(0,300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyser = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_analyzer_scores(sentence):\n",
    "    score = analyser.polarity_scores(sentence)\n",
    "    #print(\"{:-<40} {}\".format(sentence, str(score)))\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=sentiment_analyzer_scores(\"Has the United States become the largest dictatorship in the world?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg=[]\n",
    "neu=[]\n",
    "pos=[]\n",
    "comp=[]\n",
    "for i in train['question_text'] :\n",
    "    sent=sentiment_analyzer_scores(i)\n",
    "    neg.append(sent['neg'])\n",
    "    neu.append(sent['neu'])\n",
    "    pos.append(sent['pos'])\n",
    "    comp.append(sent['compound'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Negative Sentiment']= neg\n",
    "train['Positive Sentiment']= pos\n",
    "train['Neutral Sentiment']= neu\n",
    "train['Compound Sentiment']= comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg=np.reshape(neg,(-1,1))\n",
    "pos=np.reshape(pos,(-1,1))\n",
    "neu=np.reshape(neu,(-1,1))\n",
    "comp=np.reshape(comp,(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenizing the text\n",
    "max_features = 50000\n",
    "tokenizer = Tokenizer(lower = True, filters='', num_words=max_features)\n",
    "full_text = list(train['question_text'].values) + list(test['question_text'].values)\n",
    "tokenizer.fit_on_texts(full_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenizing the documents---- convert to strings\n",
    "train_tokenized = tokenizer.texts_to_sequences(train['question_text'].fillna('missing'))\n",
    "test_tokenized = tokenizer.texts_to_sequences(test['question_text'].fillna('missing'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Padding the same\n",
    "max_len = 70\n",
    "X_train = pad_sequences(train_tokenized, maxlen = max_len,padding='pre')\n",
    "X_test = pad_sequences(test_tokenized, maxlen = max_len,padding='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(sparse=False)\n",
    "#y_ohe = ohe.fit_transform(train['target'].values.reshape(-1, 1))\n",
    "y= keras.utils.to_categorical(train['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       ...,\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 462667 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "#word_index is dictionary of the words and the sequence\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path= '/Users/s0c02nj/Downloads/glove.6B/glove.6B.300d.txt'\n",
    "f=open(folder_path)\n",
    "doc=f.readlines()\n",
    "#****VIP\n",
    "#**WORD TO VEC DICTIONARY\n",
    "#Forming a dictionary-word2vec\n",
    "word2vec={}\n",
    "key=[]\n",
    "#looping though the doc.in the doc the entire thing is saved and is separated by a space bar.\n",
    "for line in doc:\n",
    "    #parts contains every word separately for doc1\n",
    "    parts=line.split(' ')\n",
    "    #part[0] contains the word\n",
    "    word=parts[0]\n",
    "    key.append(word)\n",
    "    #embed contains the vector\n",
    "    embed=np.array(parts[1:],dtype='float32')\n",
    "    #filling up the dictionary\n",
    "    word2vec[word]=embed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null word embeddings: 1\n"
     ]
    }
   ],
   "source": [
    "#Embedding matrix creation\n",
    "nb_words = min(max_features, len(word_index)+1)\n",
    "embedding_matrix = np.zeros((nb_words, 300))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    #print i\n",
    "    if i >= nb_words:\n",
    "        continue\n",
    "    if word in word2vec:\n",
    "        embedding_vector = word2vec[word]\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        \n",
    "print('Null word embeddings: %d' % np.sum(np.sum(embedding_matrix, axis=1) == 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "keras.layers.Embedding(input_dim, output_dim, embeddings_initializer='uniform', \n",
    "                      embeddings_regularizer=None, activity_regularizer=None, \n",
    "                      embeddings_constraint=None, mask_zero=False, input_length=None)\n",
    "\n",
    "input_length: Length of input sequences, when it is constant.\n",
    "\n",
    "2D tensor with shape: (batch_size, sequence_length).\n",
    "\n",
    "\n",
    "3D tensor with shape: (batch_size, sequence_length, output_dim).\n",
    "embedding_matrix.shape\n",
    "\n",
    "nb_wordsEMBEDDING_DIM\n",
    "\n",
    "Embedding(vocabulary_size, 50, input_length=200, weights=[embedding_matrix], trainable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "shape: A shape tuple (integers), not including the batch size. For instance, shape=(32,) \n",
    "indicates that the expected input will be batches of 32-dimensional vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "keras.layers.Conv1D(filters, kernel_size, strides=1, padding='valid', \n",
    "                    data_format='channels_last', dilation_rate=1, \n",
    "                    activation=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##CNN 1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_cnn_1D():\n",
    "    \n",
    "    inputs = Input(shape=(max_len,), dtype='int32')\n",
    "    layer =  Embedding(max_features ,50,input_length=max_len,trainable=False,weights = [embedding_matrix])(inputs)\n",
    "    \n",
    "    #Convolution with Filter size 2\n",
    "    x3 = Convolution1D(128, 2, activation='relu')(layer)\n",
    "    x3 = MaxPooling1D(69)(x3)\n",
    "    x3 = Flatten()(x3)\n",
    "    \n",
    "    \n",
    "    #Convolution with Filter size 3\n",
    "    x1 = Convolution1D(128, 3, activation='relu')(layer)\n",
    "    x1 = MaxPooling1D(68)(x1)\n",
    "    x1 = Flatten()(x1)\n",
    "    \n",
    "    #Convolution with Filter size 4\n",
    "    x2 = Convolution1D(128, 4, activation='relu')(layer)\n",
    "    x2 = MaxPooling1D(67)(x2)\n",
    "    x2 = Flatten()(x2)\n",
    "    \n",
    "    #Concatenating\n",
    "    merged = concatenate([x1,x2,x3],axis=1)\n",
    "    \n",
    "    #Dense Layer\n",
    "    layer_dense = Dense(128, activation='relu')(merged)\n",
    "    layer_dense = Dropout(0.2)(layer_dense)\n",
    "    \n",
    "    #Output Layer\n",
    "    probabilities = Dense(2,activation='softmax')(layer_dense)\n",
    "\n",
    "    model = Model(inputs=inputs,outputs=probabilities)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_9 (InputLayer)            (None, 70)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_9 (Embedding)         (None, 70, 50)       2500000     input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 68, 128)      19328       embedding_9[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 67, 128)      25728       embedding_9[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 69, 128)      12928       embedding_9[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling1D) (None, 1, 128)       0           conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling1D) (None, 1, 128)       0           conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1D)  (None, 1, 128)       0           conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_8 (Flatten)             (None, 128)          0           max_pooling1d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_9 (Flatten)             (None, 128)          0           max_pooling1d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)             (None, 128)          0           max_pooling1d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 384)          0           flatten_8[0][0]                  \n",
      "                                                                 flatten_9[0][0]                  \n",
      "                                                                 flatten_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          49280       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 128)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 2)            258         dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 2,607,522\n",
      "Trainable params: 107,522\n",
      "Non-trainable params: 2,500,000\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model= model_cnn_1D()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = \"binary_crossentropy\", optimizer = Adam(), metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1175509 samples, validate on 130613 samples\n",
      "Epoch 1/2\n",
      "1175509/1175509 [==============================] - 444s 377us/step - loss: 0.1384 - acc: 0.9485 - val_loss: 0.1377 - val_acc: 0.9489\n",
      "Epoch 2/2\n",
      "1175509/1175509 [==============================] - 470s 399us/step - loss: 0.1246 - acc: 0.9526 - val_loss: 0.1258 - val_acc: 0.9521\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train ,y, batch_size = 512, epochs = 2, validation_split=0.1, \n",
    "                        verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_test, batch_size = 1024, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.round(np.argmax(pred, axis=1)).astype(int)\n",
    "sub['prediction'] = predictions\n",
    "sub.to_csv(\"/Users/s0c02nj/Desktop/Data/submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def model_attn_bilstm():\n",
    "#     inputs = Input(shape=(max_len,))\n",
    "#     layer =  Embedding(max_features ,50,input_length=max_len,trainable=False,weights = [embedding_matrix])(inputs)\n",
    "#     layer =  Bidirectional(LSTM(64,return_sequences=True))(layer)\n",
    "    \n",
    "#     #Attention\n",
    "#     activations_weights = Dense(1, activation='tanh')(layer)\n",
    "#     activations_weights = Flatten()(activations_weights)\n",
    "#     activations_weights = Activation('softmax')(activations_weights)\n",
    "#     activations_weights = RepeatVector(128)(activations_weights)\n",
    "#     activations_weights = Permute([2, 1])(activations_weights)\n",
    "#     activations_weighted = multiply([layer, activations_weights])\n",
    "#     sent_representation = Lambda(lambda x: K.sum(x, axis=-2))(activations_weighted)\n",
    "    \n",
    "#     #Defining inputs for sentiment scores\n",
    "#     input_neg=Input(shape=(1,))\n",
    "#     input_pos=Input(shape=(1,))\n",
    "#     input_neu=Input(shape=(1,))\n",
    "#     input_comp=Input(shape=(1,))\n",
    "    \n",
    "#     #Concatenating\n",
    "#     layer_sentiment = concatenate([sent_representation,input_neg,input_pos,input_neu,input_comp],axis=1)\n",
    "    \n",
    "#     #Dense Layer\n",
    "#     layer_sentiment= Dense(20, activation='tanh')(layer_sentiment)\n",
    "    \n",
    "#     #Output Layer\n",
    "#     probabilities = Dense(2,activation='softmax')(layer_sentiment)\n",
    "\n",
    "#     model = Model(inputs=[inputs,input_neg,input_pos,input_neu,input_comp],outputs=probabilities)\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_lstm_atten():\n",
    "    inp = Input(shape=(max_len,))\n",
    "    x = Embedding(max_features, 300, weights=[embedding_matrix], trainable=False)(inp)\n",
    "    #x = SpatialDropout1D(0.1)(x)\n",
    "    x = Bidirectional(LSTM(128, return_sequences=True))(x)\n",
    "    y = Bidirectional(LSTM(128, return_sequences=True))(x)\n",
    "\n",
    "    #atten_1 = Attention(maxlen)(x) # skip connect\n",
    "    #atten_2 = Attention(maxlen)(y)\n",
    "    avg_pool = GlobalAveragePooling1D()(y)\n",
    "    max_pool = GlobalMaxPooling1D()(y)\n",
    "\n",
    "    #conc = concatenate([atten_1, atten_2, avg_pool, max_pool])\n",
    "    #conc = Dense(64, activation=\"elu\", kernel_initializer=\"he_normal\")(conc)\n",
    "    #conc = Dropout(0.1)(conc)\n",
    "\n",
    "    #conc = Dense(32, activation=\"elu\", kernel_initializer=\"he_normal\")(conc)\n",
    "    #conc = Dropout(0.1)(conc)\n",
    "\n",
    "    #outp = Dense(1, activation=\"sigmoid\")(conc)\n",
    "\n",
    "    model = Model(inputs=inp, outputs=max_pool)\n",
    "    #model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.001))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         (None, 70)                0         \n",
      "_________________________________________________________________\n",
      "embedding_6 (Embedding)      (None, 70, 300)           15000000  \n",
      "_________________________________________________________________\n",
      "bidirectional_8 (Bidirection (None, 70, 256)           439296    \n",
      "_________________________________________________________________\n",
      "bidirectional_9 (Bidirection (None, 70, 256)           394240    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_3 (Glob (None, 256)               0         \n",
      "=================================================================\n",
      "Total params: 15,833,536\n",
      "Trainable params: 833,536\n",
      "Non-trainable params: 15,000,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=model_lstm_atten()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model():\n",
    "   seq_input = Input(shape=(MAX_SEQUENCE_LENGTH,))\n",
    "   embedded_sequences = embedding_layer(seq_input)\n",
    "   x = Conv1D(256, 2, activation='relu')(embedded_sequences)\n",
    "   x = AveragePooling1D(2)(x)\n",
    "   x = Conv1D(256, 2, activation='relu')(x)\n",
    "   x = AveragePooling1D(2)(x)\n",
    "   x = Conv1D(256, 2, activation='relu')(x)\n",
    "   x = AveragePooling1D(2)(x)\n",
    "   x = Flatten()(x)\n",
    "   x = Dense(256, activation='relu')(x)\n",
    "   pred = Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "\n",
    "\n",
    "   model = Model(seq_input, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ques = pd.read_pickle('/Users/s0c02nj/Downloads/MS_marco_subset/df_query_ms_500.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res = pd.read_pickle('/Users/s0c02nj/Downloads/MS_marco_subset/df_result_ms_500.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import helpers, Elasticsearch\n",
    "import csv\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize\n",
    "from inflection import singularize\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import cosine as cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'm-c02wv1jnhtd5',\n",
       " 'cluster_name': 'elasticsearch',\n",
       " 'cluster_uuid': 'i0Q_KCKeTLGlRZzF8qt__A',\n",
       " 'version': {'number': '7.6.2',\n",
       "  'build_flavor': 'default',\n",
       "  'build_type': 'tar',\n",
       "  'build_hash': 'ef48eb35cf30adf4db14086e8aabd07ef6fb113f',\n",
       "  'build_date': '2020-03-26T06:34:37.794943Z',\n",
       "  'build_snapshot': False,\n",
       "  'lucene_version': '8.4.0',\n",
       "  'minimum_wire_compatibility_version': '6.8.0',\n",
       "  'minimum_index_compatibility_version': '6.0.0-beta1'},\n",
       " 'tagline': 'You Know, for Search'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es = Elasticsearch([{'host': 'localhost', 'port': 9200}])\n",
    "es.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocessing(text):\n",
    "    text= text.lower()\n",
    "    text= re.sub(r'[^a-z]',' ',text)\n",
    "    #text= \" \".join([s for s in text.split() if len(s)>2])\n",
    "    #text= \" \".join([x for x in text.split() if x not in stopwords.words('english')])\n",
    "    #text= \" \".join([inflection.singularize(x) for x in text.split()])\n",
    "    text= text.strip()\n",
    "    return(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 497308/497308 [00:12<00:00, 40181.06it/s]\n",
      "100%|██████████| 497308/497308 [00:02<00:00, 222430.36it/s]\n"
     ]
    }
   ],
   "source": [
    "df_ques['passage'] = df_ques['passage'].progress_apply(lambda x: text_preprocessing(x))\n",
    "\n",
    "df_ques['query'] = df_ques['query'].progress_apply(lambda x: text_preprocessing(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "index='index_k1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_generator(data,index):\n",
    "    df_iter= data.iterrows()\n",
    "    \n",
    "    for index,document in df_iter:\n",
    "        yield{\n",
    "            \"_index\": 'index_k1',\n",
    "            \"_type\": \"_doc\",\n",
    "            \"_id\" : f\"{index}\",\n",
    "            \"_source\": document.to_json()\n",
    "        }\n",
    "    raise StopIteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "497308it [01:25, 5849.52it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'_shards': {'total': 2, 'successful': 1, 'failed': 0}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for success,info in tqdm(helpers.parallel_bulk(es,doc_generator(df_ques[['pid','passage']],index))):\n",
    "    if not success:\n",
    "        print('A document failed:', info)\n",
    "es.indices.refresh(index=index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SEARCH(text,index,field):\n",
    "    \n",
    "    res= es.search(index=index,body={\"query\":{\"match\":{field:{\"query\":text,\"operator\":\"or\",\"fuzziness\": \"0\"\n",
    "                                                            }}}},size = 10)\n",
    "    \n",
    "    return([(x.get('_source'),x.get('_score')) for x in res['hits']['hits']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "index='index_k1'\n",
    "field = 'passage'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SEARCH('corporation',index,field)\n",
    "question_un = list(df_ques['query'].unique())\n",
    "\n",
    "df_new = pd.DataFrame()\n",
    "df_new['question'] = question_un"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(question_un)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_generator(df):\n",
    "    while True:\n",
    "        yield (df_new['question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object query_generator at 0x117dd8d00>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_generator(df_new[['question']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 2865.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 595 ms, sys: 153 ms, total: 748 ms\n",
      "Wall time: 5.22 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "queries=[]\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    queries={executor.submit(SEARCH, query,index,'passage'): query for query in tqdm(df_new.question)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 276268.21it/s]\n"
     ]
    }
   ],
   "source": [
    "out = [x.result() for x in tqdm(queries)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_std_ref_match(data_current):\n",
    "    \n",
    "    #UPC to match\n",
    "    questions = []\n",
    "    \n",
    "    #Original\n",
    "    answers = []\n",
    "    \n",
    "    #Score\n",
    "    score_bm25 = []\n",
    "    \n",
    "    #qid\n",
    "    #qs_id = []\n",
    "    \n",
    "    #pid\n",
    "    ps_id = []\n",
    "    \n",
    "        \n",
    "    \n",
    "    #Reindex\n",
    "    data_current.index = range(0,len(data_current))\n",
    "    \n",
    "    \n",
    "    for i in tqdm(range(0,len(data_current))):\n",
    "\n",
    "            #indexing\n",
    "            #data_current.index = range(0,len(data_current))\n",
    "            \n",
    "            #question\n",
    "            qs = data_current['question'].iloc[i]\n",
    "            \n",
    "           \n",
    "            #Getting the search result\n",
    "            temp_out = out[i]\n",
    "            val = len(temp_out)\n",
    "\n",
    "            if val ==0:\n",
    "                \n",
    "                #questions\n",
    "                questions.append(qs)\n",
    "                \n",
    "\n",
    "                #answer\n",
    "                answers.append('NA')\n",
    "                \n",
    "                #qs_id ps_9d\n",
    "                #qs_id.append('NA')\n",
    "                ps_id.append('NA')\n",
    "                \n",
    "                #Score\n",
    "                score_bm25.append('NA')\n",
    "                \n",
    "             \n",
    "            else:\n",
    "                for j in np.arange(val):\n",
    "\n",
    "                    #clean_ingred\n",
    "                    questions.append(qs)\n",
    "                \n",
    "\n",
    "                    #Creating temp\n",
    "                    temp2 = temp_out[j]\n",
    "\n",
    "                    #Separting the tuple\n",
    "                    doc_txt = temp2[0]['passage']\n",
    "                    \n",
    "                    #qs_i = temp2[0]['qid']\n",
    "                    ps_i = temp2[0]['pid']\n",
    "                    \n",
    "                    #query,passage ids\n",
    "                    #qs_id.append(qs_i)\n",
    "                    ps_id.append(ps_i)\n",
    "\n",
    "                    #bm25\n",
    "                    doc_scr = temp2[1]\n",
    "\n",
    "\n",
    "                    #matched answers\n",
    "                    answers.append(doc_txt)\n",
    "                    \n",
    "\n",
    "                    #Score\n",
    "                    score_bm25.append(doc_scr)\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "    \n",
    "\n",
    "    #Converting to a Dataframe   \n",
    "    df_out = pd.DataFrame()\n",
    "    #df_result['qid'] = qs_id\n",
    "    df_out['pid'] = ps_id\n",
    "    df_out['questions'] = questions\n",
    "    df_out['passage'] = answers\n",
    "    df_out['score'] = score_bm25\n",
    "\n",
    "    return df_out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:00<00:00, 20890.88it/s]\n"
     ]
    }
   ],
   "source": [
    "df_out = get_std_ref_match(df_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ques_id = df_ques[['qid','query']]\n",
    "\n",
    "df_ques_id = df_ques_id.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out1 = pd.merge(left= df_out ,\n",
    "                     right= df_ques_id,\n",
    "                     left_on= 'questions',\n",
    "                     right_on = 'query')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out1 = df_out1.drop(['query'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = df_out1.sort_values(by=['questions','score'],ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred['indices'] = range(0,len(df_pred))\n",
    "df_pred['rank'] = (df_pred.groupby('questions')['indices'].rank(ascending=True))\n",
    "df_pred = df_pred.drop(['indices'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_pred.groupby('questions').head(10).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_v1 = df_final[['qid','pid','rank']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "MaxMRRRank = 10\n",
    "def compute_metrics(qids_to_relevant_passageids, qids_to_ranked_candidate_passages):\n",
    "    \"\"\"Compute MRR metric\n",
    "    Args:    \n",
    "    p_qids_to_relevant_passageids (dict): dictionary of query-passage mapping\n",
    "        Dict as read in with load_reference or load_reference_from_stream\n",
    "    p_qids_to_ranked_candidate_passages (dict): dictionary of query-passage candidates\n",
    "    Returns:\n",
    "        dict: dictionary of metrics {'MRR': <MRR Score>}\n",
    "    \"\"\"\n",
    "    all_scores = {}\n",
    "    MRR = 0\n",
    "    qids_with_relevant_passages = 0\n",
    "    ranking = []\n",
    "    list1=list(set(qids_to_ranked_candidate_passages['qid'].to_list()))\n",
    "    #print(list1)\n",
    "    list2=qids_to_relevant_passageids['qid'].to_list()\n",
    "    for qid in list1:\n",
    "        if qid in list2:\n",
    "            ranking.append(0)\n",
    "            target_pid = list(qids_to_relevant_passageids[qids_to_relevant_passageids['qid']==qid]['pid'])\n",
    "            candidate_pid = list(qids_to_ranked_candidate_passages[qids_to_ranked_candidate_passages['qid']==qid]['pid'])\n",
    "            for i in range(0,MaxMRRRank):\n",
    "                if candidate_pid[i] in target_pid:\n",
    "                    MRR += 1/(i + 1)\n",
    "                    #print(MRR)\n",
    "#                     ranking.pop()\n",
    "#                     ranking.append(i+1)\n",
    "                    break\n",
    "#     if len(ranking) == 0:\n",
    "#         raise IOError(\"No matching QIDs found. Are you sure you are scoring the evaluation set?\")\n",
    "# #     print(MRR)\n",
    "#     print(len(qids_to_relevant_passageids))\n",
    "    MRR = MRR/len(list1)\n",
    "    all_scores['MRR @10'] = MRR\n",
    "    all_scores['QueriesRanked'] = qids_to_ranked_candidate_passages['qid'].nunique()\n",
    "    return all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrr = compute_metrics(df_res, df_final_v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MRR @10': 0.13552063492063499, 'QueriesRanked': 500}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_final_v1['qid'].unique()[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_final_v1[df_final_v1['qid'] == 1066792]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAX_RANK = 10\n",
    "\n",
    "# hits = pd.merge(df_res, df_final_v1,\n",
    "#     on=[\"qid\", \"pid\"],\n",
    "#     how=\"left\").fillna(MAX_RANK)\n",
    "\n",
    "# mrr = (1 / hits.groupby('qid')['rank'].min()).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

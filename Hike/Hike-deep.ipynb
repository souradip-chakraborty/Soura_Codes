{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import re\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.manifold import TSNE\n",
    "import networkx as nx\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.layers import Dense, Flatten, LSTM, Conv1D, MaxPooling1D, Dropout, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "import keras \n",
    "import scipy\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.text import Tokenizer, one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Flatten,Activation,Dropout,Input,Embedding,RepeatVector,Permute,merge,Lambda\n",
    "\n",
    "from keras.layers import Multiply ,concatenate ,Subtract,add,Add,Reshape                   \n",
    "from keras.optimizers import RMSprop ,Adam\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('/Users/s0c02nj/Desktop/Personal Edu doc/Competitions /Hike/train/train.csv')\n",
    "train_feat = pd.read_csv('/Users/s0c02nj/Desktop/Personal Edu doc/Competitions /Hike/train/user_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('/Users/s0c02nj/Desktop/Personal Edu doc/Competitions /Hike/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70661802, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rows to remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rem_row = np.load('/Users/s0c02nj/Desktop/Personal Edu doc/Competitions /Hike/same_node_train_ids.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "903488"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rem_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1413236"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train_data_new = train_data[0:706618]\n",
    "706618*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_new = train_data[15132360:35132360]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All nodes are present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data1 = train_data_new[['node1_id']]\n",
    "train_data2 = train_data_new[['node2_id']]\n",
    "\n",
    "y_train = train_data_new['is_chat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cat = to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data1 = test_data[['node1_id']]\n",
    "test_data2 = test_data[['node2_id']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bringing the Train Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feat1 = pd.merge(left = train_data1, right= train_feat, how='left', \n",
    "                 left_on=['node1_id'], right_on=['node_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feat2 = pd.merge(left = train_data2, right= train_feat, how='left', \n",
    "                 left_on=['node2_id'], right_on=['node_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bringing Test Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_feat1 = pd.merge(left = test_data1, right= train_feat, how='left', \n",
    "                 left_on=['node1_id'], right_on=['node_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_feat2 = pd.merge(left = test_data2, right= train_feat, how='left', \n",
    "                 left_on=['node2_id'], right_on=['node_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_feat1[train_feat1['node1_id']== 8446602]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardizing Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_std = ['f1','f2','f3','f4','f5', 'f6','f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feat1_fin = train_feat1[cols_std]\n",
    "train_feat2_fin = train_feat2[cols_std]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_feat1_fin = test_feat2[cols_std]\n",
    "test_feat2_fin = test_feat2[cols_std]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the Node vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = '/Users/s0c02nj/Desktop/Hike/node2vec.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count = 0\n",
    "# vectors_list = []\n",
    "\n",
    "# for o in tqdm(open(path)):\n",
    "    \n",
    "#     values = o.split()\n",
    "#     values[0] = int(values[0])\n",
    "#     values[1:] = list(map(float, values[1:]))\n",
    "    \n",
    "#     vectors_list.append(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols = []\n",
    "# for i in range(0,16):\n",
    "#     cols.append('data'+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cols = ['node_id']+cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# node_vec = pd.DataFrame(vectors_list)\n",
    "# node_vec.columns = cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#node_vec = node_vec.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#node_vec.index = range(0,len(node_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Joining with the node_vec features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feat1_fin = pd.merge(left = train_feat1, right= node_vec, how='left', \n",
    "                 left_on=['node1_id'], right_on=['node_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feat2_fin = pd.merge(left = train_feat2, right= node_vec, how='left', \n",
    "                 left_on=['node2_id'], right_on=['node_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_feat1_fin = pd.merge(left = test_feat1, right= node_vec, how='left', \n",
    "                 left_on=['node1_id'], right_on=['node_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_feat2_fin = pd.merge(left = test_feat2, right= node_vec, how='left', \n",
    "                 left_on=['node2_id'], right_on=['node_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = []\n",
    "for i in range(0,16):\n",
    "    cols.append('data'+str(i))\n",
    "cols_total = cols_std + cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feat1_fin = train_feat1_fin[cols_total]\n",
    "train_feat2_fin = train_feat2_fin[cols_total]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_feat1_fin = test_feat1_fin[cols_total]\n",
    "test_feat2_fin = test_feat2_fin[cols_total]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep Learning Archi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_deep():\n",
    "    \n",
    "    #Defining the input-----> Continuous Variable\n",
    "    inputs1 = Input(shape=(13,))\n",
    "    \n",
    "    #Defining the input-----> Categorical Variable\n",
    "    inputs2 = Input(shape=(13,))\n",
    "    \n",
    "    #Subtraction\n",
    "    subtracted = Subtract()([inputs1, inputs2])\n",
    "    \n",
    "    #multiply\n",
    "    multiply =  Multiply()([inputs1, inputs2])\n",
    "    \n",
    "    \n",
    "    #Defining the -----> Complaint-reason\n",
    "    layer_merge = concatenate([inputs1,inputs2,subtracted,multiply])\n",
    "    \n",
    "\n",
    "    #Dense Layer-----> This will be the Weight Matrix W (n*k)\n",
    "    layer_dense = Dense(150, activation='relu')(layer_merge)\n",
    "    layer_dense = Dropout(0.5)(layer_dense)\n",
    "    \n",
    "    layer_dense = Dense(30, activation='relu')(layer_merge)\n",
    "    layer_dense = Dropout(0.5)(layer_dense)\n",
    "    \n",
    "    layer_dense = Dense(20, activation='relu')(layer_merge)\n",
    "    layer_dense = Dropout(0.5)(layer_dense)\n",
    "    \n",
    "    #Total Loss to Minimize\n",
    "    loss_total = Dense(2,activation='softmax')(layer_dense)\n",
    "    \n",
    "    \n",
    "    model = Model(inputs=[inputs1,inputs2], outputs= loss_total)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_9 (InputLayer)            (None, 13)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_10 (InputLayer)           (None, 13)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "subtract_4 (Subtract)           (None, 13)           0           input_9[0][0]                    \n",
      "                                                                 input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_4 (Multiply)           (None, 13)           0           input_9[0][0]                    \n",
      "                                                                 input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 52)           0           input_9[0][0]                    \n",
      "                                                                 input_10[0][0]                   \n",
      "                                                                 subtract_4[0][0]                 \n",
      "                                                                 multiply_4[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 20)           1060        concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 20)           0           dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 2)            42          dropout_12[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 1,102\n",
      "Trainable params: 1,102\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = model_deep()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc(y_true, y_pred):\n",
    "    auc = tf.metrics.auc(y_true, y_pred)[1]\n",
    "    K.get_session().run(tf.local_variables_initializer())\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = \"binary_crossentropy\", optimizer = Adam(lr=0.001), metrics = [auc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18000000 samples, validate on 2000000 samples\n",
      "Epoch 1/4\n",
      "18000000/18000000 [==============================] - 145s 8us/step - loss: 2.1395 - auc: 0.8964 - val_loss: 1.7214 - val_auc: 0.9081\n",
      "Epoch 2/4\n",
      "18000000/18000000 [==============================] - 141s 8us/step - loss: 1.7825 - auc: 0.9044 - val_loss: 1.6973 - val_auc: 0.9031\n",
      "Epoch 3/4\n",
      "18000000/18000000 [==============================] - 165s 9us/step - loss: 1.7708 - auc: 0.9027 - val_loss: 1.6823 - val_auc: 0.9020\n",
      "Epoch 4/4\n",
      "18000000/18000000 [==============================] - 157s 9us/step - loss: 1.7643 - auc: 0.9017 - val_loss: 1.6766 - val_auc: 0.9013\n"
     ]
    }
   ],
   "source": [
    "#Deep Learning Model\n",
    "history = model.fit([train_feat1_fin,\n",
    "                     train_feat2_fin] ,\n",
    "                     y_cat, batch_size = 1024, epochs = 4, validation_split=0.1,\n",
    "                     class_weight = {0:2 ,1:40}, \n",
    "                     verbose = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tets\n",
    "y_prob1 = model.predict([test_feat1_fin,test_feat2_fin])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ones1 = y_prob1[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tets\n",
    "y_prob2 = model.predict([test_feat1_fin,test_feat2_fin])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ones2 = y_prob2[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tets\n",
    "y_prob3 = model.predict([test_feat1_fin,test_feat2_fin])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ones3 = y_prob3[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tets\n",
    "y_prob4 = model.predict([test_feat1_fin,test_feat2_fin])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ones4 = y_prob4[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = (y_ones1+y_ones2+y_ones3+y_ones4)/4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = test_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df['is_chat'] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = sub_df[['id','is_chat']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "#z = np.load('/Users/s0c02nj/Desktop/Hike/same_node_ids.npy')\n",
    "#z_set = set(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = []\n",
    "for i in tqdm(range(0,len(sub_df))):\n",
    "    \n",
    "    i_id = sub_df['id'].iloc[i]\n",
    "    \n",
    "    if i_id in z_set:\n",
    "        k=0\n",
    "    else:\n",
    "        k = sub_df['is_chat'].iloc[i]\n",
    "        \n",
    "    out.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df['is_chat'] = out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df.to_csv('/Users/s0c02nj/Desktop/Personal Edu doc/Competitions /Hike/Submission6.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

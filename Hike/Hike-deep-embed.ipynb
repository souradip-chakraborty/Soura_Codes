{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import re\n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.manifold import TSNE\n",
    "import networkx as nx\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.layers import Dense, Flatten, LSTM, Conv1D, MaxPooling1D, Dropout, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "import keras \n",
    "import scipy\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.text import Tokenizer, one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Flatten,Activation,Dropout,Input,Embedding,RepeatVector,Permute,merge,Lambda\n",
    "from keras.layers import multiply ,concatenate ,subtract,add,Add,Reshape                   \n",
    "from keras.optimizers import RMSprop ,Adam\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('/Users/s0c02nj/Desktop/Hike/train/train.csv')\n",
    "train_feat = pd.read_csv('/Users/s0c02nj/Desktop/Hike/train/user_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('/Users/s0c02nj/Desktop/Hike/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rows to remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rem_row = np.load('/Users/s0c02nj/Desktop/Hike/same_node_train_ids.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(rem_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.drop(list(rem_row),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_new = train_data[0:6975831]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All nodes are present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data1 = train_data_new[['node1_id']]\n",
    "train_data2 = train_data_new[['node2_id']]\n",
    "\n",
    "y_train = train_data_new['is_chat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cat = to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data1 = test_data[['node1_id']]\n",
    "test_data2 = test_data[['node2_id']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bringing the Train Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feat1 = pd.merge(left = train_data1, right= train_feat, how='left', \n",
    "                 left_on=['node1_id'], right_on=['node_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feat2 = pd.merge(left = train_data2, right= train_feat, how='left', \n",
    "                 left_on=['node2_id'], right_on=['node_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bringing Test Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_feat1 = pd.merge(left = test_data1, right= train_feat, how='left', \n",
    "                 left_on=['node1_id'], right_on=['node_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_feat2 = pd.merge(left = test_data2, right= train_feat, how='left', \n",
    "                 left_on=['node2_id'], right_on=['node_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardizing Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_std = ['f1','f2','f3','f4','f5','f6','f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the Node vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/s0c02nj/Desktop/Hike/node_vec/node2vec.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "vectors_list = []\n",
    "\n",
    "for o in tqdm(open(path)):\n",
    "    \n",
    "    values = o.split()\n",
    "    values[0] = int(values[0])\n",
    "    values[1:] = list(map(float, values[1:]))\n",
    "    \n",
    "    vectors_list.append(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = []\n",
    "for i in range(0,16):\n",
    "    cols.append('data'+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['node_id']+cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_vec = pd.DataFrame(vectors_list)\n",
    "node_vec.columns = cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_vec = node_vec.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_vec.index = range(0,len(node_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Joining with the node_vec features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feat1_fin = pd.merge(left = train_feat1, right= node_vec, how='left', \n",
    "                 left_on=['node1_id'], right_on=['node_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feat2_fin = pd.merge(left = train_feat2, right= node_vec, how='left', \n",
    "                 left_on=['node2_id'], right_on=['node_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_feat1_fin = pd.merge(left = test_feat1, right= node_vec, how='left', \n",
    "                 left_on=['node1_id'], right_on=['node_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_feat2_fin = pd.merge(left = test_feat2, right= node_vec, how='left', \n",
    "                 left_on=['node2_id'], right_on=['node_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = []\n",
    "for i in range(0,16):\n",
    "    cols.append('data'+str(i))\n",
    "cols_total = cols_std + cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feat1_fin = train_feat1_fin[cols_total]\n",
    "train_feat2_fin = train_feat2_fin[cols_total]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_feat1_fin = test_feat1_fin[cols_total]\n",
    "test_feat2_fin = test_feat2_fin[cols_total]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep Learning Archi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_deep():\n",
    "    \n",
    "    #Defining the input-----> Continuous Variable\n",
    "    inputs1 = Input(shape=(29,))\n",
    "    \n",
    "    #Defining the input-----> Categorical Variable\n",
    "    inputs2 = Input(shape=(29,))\n",
    "    \n",
    "    #Defining the -----> Complaint-reason\n",
    "    layer_merge = concatenate([inputs1,inputs2])\n",
    "    \n",
    "    #Dense Layer-----> This will be the Weight Matrix W (n*k)\n",
    "    layer_dense = Dense(100, activation='relu')(layer_merge)\n",
    "    layer_dense = Dropout(0.5)(layer_dense)\n",
    "    layer_dense = Dense(60, activation='relu')(layer_merge)\n",
    "    layer_dense = Dropout(0.5)(layer_dense)\n",
    "    layer_dense = Dense(40, activation='relu')(layer_merge)\n",
    "    layer_dense = Dropout(0.5)(layer_dense)\n",
    "    layer_dense = Dense(20, activation='relu')(layer_merge)\n",
    "    layer_dense = Dropout(0.5)(layer_dense)\n",
    "    layer_dense = Dense(10, activation='relu')(layer_merge)\n",
    "    \n",
    "    \n",
    "    #Total Loss to Minimize\n",
    "    loss_total = Dense(2,activation='softmax')(layer_dense)\n",
    "    \n",
    "    \n",
    "    model = Model(inputs=[inputs1,inputs2], outputs= loss_total)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_deep()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc(y_true, y_pred):\n",
    "    auc = tf.metrics.auc(y_true, y_pred)[1]\n",
    "    K.get_session().run(tf.local_variables_initializer())\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = \"binary_crossentropy\", optimizer = Adam(lr=0.001), metrics = [auc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deep Learning Model\n",
    "history = model.fit([train_feat1_fin,\n",
    "                     train_feat2_fin] ,\n",
    "                     y_cat, batch_size = 1024, epochs = 10, validation_split=0.1,\n",
    "                     class_weight = {0:2 ,1:40}, \n",
    "                     verbose = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tets\n",
    "y_prob = model.predict([test_feat1_fin,test_feat2_fin])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ones = y_prob[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = test_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df['is_chat'] = y_ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = sub_df[['id','is_chat']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.load('/Users/s0c02nj/Desktop/Hike/same_node_test_ids.npy')\n",
    "z_set = set(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = []\n",
    "for i in tqdm(range(0,len(sub_df))):\n",
    "    \n",
    "    i_id = sub_df['id'].iloc[i]\n",
    "    \n",
    "    if i_id in z_set:\n",
    "        k=0\n",
    "    else:\n",
    "        k = sub_df['is_chat'].iloc[i]\n",
    "        \n",
    "    out.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df['is_chat'] = out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df.to_csv('/Users/s0c02nj/Desktop/Hike/Submission6.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\brsingh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import Input, Dense, Lambda, Flatten, Reshape, Concatenate,Activation\n",
    "from keras.layers import concatenate\n",
    "from keras.layers import Conv2D, Conv2DTranspose, ZeroPadding2D,MaxPooling2D, Cropping2D, BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras import metrics\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "from keras import losses\n",
    "from keras.utils import plot_model\n",
    "from keras.callbacks import Callback,ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import time\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import datetime\n",
    "\n",
    "import cv2\n",
    "%matplotlib inline\n",
    "import pydot\n",
    "from PIL import Image\n",
    "import glob\n",
    "import os\n",
    "from pyemd import emd, emd_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters initialization\n",
    "nb_rows = 224   # X dimension of the image\n",
    "nb_cols = 224   # Y dimesnion of the image\n",
    "#total_frames = 30\n",
    "\n",
    "nb_channel = 3 # numbe rof channels in images 3 for color(RGB) and 1 for Gray\n",
    "\n",
    "BS=10\n",
    "batch_size = BS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import rescale\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    rotation_range=0,\n",
    "    width_shift_range=0,\n",
    "    height_shift_range=0,\n",
    "    vertical_flip=False,)\n",
    "\n",
    "\n",
    "# batch_labels is the one hot representation of the output\n",
    "def initialize_batch_data(batch_size):\n",
    "    batch_data = np.zeros((batch_size, nb_rows, nb_cols, nb_channel)) \n",
    "    batch_labels = np.zeros((batch_size,nb_rows, nb_cols,1)) \n",
    "    return batch_data, batch_labels\n",
    "\n",
    "# Image Croping\n",
    "def crop(image):\n",
    "    if image.shape[0] != image.shape[1]:\n",
    "        return image[0:120,20:140]\n",
    "    else:\n",
    "        return image\n",
    "\n",
    "# Resizing the image based on dimension\n",
    "def resize(image):\n",
    "    return  cv2.resize(image, (nb_rows,nb_cols), interpolation = cv2.INTER_AREA)\n",
    "\n",
    "def preprocess_img(img, mode):\n",
    "    img = (img - img.min())/(img.max() - img.min())\n",
    "    if mode == 'train':\n",
    "        if np.random.randn() > 0:\n",
    "            img = datagen.random_transform(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(mode,source_path):\n",
    "    image_list=[]\n",
    "    for filename in glob.glob(str(source_path)+'images/*'):\n",
    "        path1 = os.path.basename(filename)\n",
    "        image_list.append(path1)\n",
    "#     paths = image_list[0:100]\n",
    "    return image_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBatchImage(folder_list,indexes, mode,source_path):\n",
    "    list_IDs_temp = [folder_list[k] for k in indexes]\n",
    "#     print(\"indexes\",list_IDs_temp)\n",
    "    X=[]\n",
    "    Y=[]\n",
    "    for index, h in enumerate(list_IDs_temp):\n",
    "        I = io.imread(str(source_path)+\"images/{}\".format(h))\n",
    "        resized = resize(I)\n",
    "        new_image = preprocess_img(resized, mode)\n",
    "        X.append(new_image)\n",
    "        bin_label = np.zeros((224,224))\n",
    "        label = io.imread(str(source_path)+\"salMap/{}\".format(h))\n",
    "        resized = resize(label)\n",
    "        labels = preprocess_img(resized, mode)\n",
    "        for i in range(0,224):\n",
    "            for j in range(0,224):\n",
    "                if labels[i][j]<26:\n",
    "                    bin_label[i][j] = 0\n",
    "                elif labels[i][j]<51:\n",
    "                    bin_label[i][j] = 0.111\n",
    "                elif labels[i][j]<76:\n",
    "                    bin_label[i][j] = 0.222\n",
    "                elif labels[i][j]<102:\n",
    "                    bin_label[i][j] = 0.333\n",
    "                elif labels[i][j]<128:\n",
    "                    bin_label[i][j] = 0.444\n",
    "                elif labels[i][j]<154:\n",
    "                    bin_label[i][j] = 0.556\n",
    "                elif labels[i][j]<180:\n",
    "                    bin_label[i][j] = 0.667\n",
    "                elif labels[i][j]<206:\n",
    "                    bin_label[i][j] = 0.778\n",
    "                elif labels[i][j]<230:\n",
    "                    bin_label[i][j] = 0.889                  \n",
    "                else:\n",
    "                    bin_label[i][j] = 1\n",
    "        Y.append(bin_label)\n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y)\n",
    "    Y=Y[:,:,:,np.newaxis]\n",
    "    return X,[Y,Y,Y,Y]\n",
    "\n",
    "def get_newBatch(folder_list,batch_size,index):\n",
    "    indexes = np.arange(len(folder_list))\n",
    "    np.random.shuffle(indexes)\n",
    "    indexes = indexes[index*batch_size:(index+1)*batch_size]\n",
    "    return indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generator function\n",
    "def generator(batch_size,source_path,mode='train'):\n",
    "    while True:\n",
    "        folder_list = getData(mode,source_path)\n",
    "\n",
    "        num_batches = len(folder_list)//batch_size # calculate the number of batches\n",
    "        print('No of Batch : ', num_batches,' mode: ' , mode)\n",
    "        for batch in range(num_batches): # we iterate over the number of batches\n",
    "            # you yield the batch_data and the batch_labels, remember what does yield do\n",
    "            indexes = get_newBatch(folder_list,batch_size,batch)\n",
    "            yield getBatchImage(folder_list,indexes,mode,source_path)\n",
    "\n",
    "        # Code for the remaining data points which are left after full batches\n",
    "        if (len(folder_list) != batch_size*num_batches):\n",
    "            batch_size = len(folder_list) - (batch_size*num_batches)\n",
    "            indexes = get_newBatch(folder_list,batch_size,batch)\n",
    "            yield getBatchImage(folder_list,indexes,mode,source_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BS=20\n",
    "# batch_size = BS\n",
    "training_Path = \"lagdata/train/\"\n",
    "validation_Path = \"lagdata/validation/\"\n",
    "# train_generator = generator(batch_size, training_Path, mode='train')\n",
    "# validation_generator = generator(batch_size, validation_Path, mode='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for t in validation_generator:\n",
    "#     print(t[0].shape,t[1][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_dt_time = datetime.datetime.now()\n",
    "\n",
    "def get_step_per_epoch(num_train_sequences, b_size):\n",
    "    if (num_train_sequences%b_size) == 0:\n",
    "        steps_per_epoch = int(num_train_sequences/b_size)\n",
    "    else:\n",
    "        steps_per_epoch = (num_train_sequences//b_size) + 1\n",
    "    return steps_per_epoch\n",
    "\n",
    "def get_validation_steps(num_val_sequences, b_size):\n",
    "    if (num_val_sequences%b_size) == 0:\n",
    "        validation_steps = int(num_val_sequences/b_size)\n",
    "    else:\n",
    "        validation_steps = (num_val_sequences//b_size) + 1\n",
    "    return validation_steps\n",
    "    \n",
    "\n",
    "def callbacks_list(model_name, factor_rate, epoch_patience):\n",
    "    print('factor_rate: ',factor_rate)\n",
    "    model_name = model_name + '_'+'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
    "    if not os.path.exists(model_name):\n",
    "        os.mkdir(model_name)\n",
    "    filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{bafc_accuracy:.5f}-{val_loss:.5f}-{val_bafc_accuracy:.5f}.h5'\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='val_bafc_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
    "    LR = ReduceLROnPlateau(monitor='val_bafc_loss', factor=factor_rate, patience=epoch_patience, cooldown=1, verbose=1, mode='auto', min_delta=0.0001) # write the REducelronplateau code here\n",
    "    callbacks_list = [checkpoint, LR]   \n",
    "    return callbacks_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionModel:\n",
    "  def __init__(self):\n",
    "        self.batch_size = BS\n",
    "        self.epochs = 5 #10\n",
    "        self.lr = 0.001\n",
    "\n",
    "        \n",
    "  #Defines the model architecture      \n",
    "  def DeepAttentionModel(self):\n",
    "    img_rows, img_cols, img_chns = 224, 224, 3\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        original_img_size = (img_chns, img_rows, img_cols)\n",
    "    else:\n",
    "        original_img_size = (img_rows, img_cols, img_chns)\n",
    "    \n",
    "    print(\"###########################################\")\n",
    "    print(\"original_img_size \", original_img_size)\n",
    "    print(\"###########################################\")\n",
    "    self.x = Input(shape=original_img_size)\n",
    "    padded_x = ZeroPadding2D(padding=(35), data_format=\"channels_last\")(self.x)\n",
    "    \n",
    "    \n",
    "    #'Encoder'\n",
    "    conv_1_1 = Conv2D(64, kernel_size=(3, 3),strides=(1, 1), padding='valid', activation='relu',data_format=\"channels_last\")(padded_x)\n",
    "    padded_conv_1_1 = ZeroPadding2D(padding=(1), data_format=\"channels_last\")(conv_1_1)\n",
    "    conv_1_2 = Conv2D(64, kernel_size=(3, 3),strides=(1, 1), padding='valid', activation='relu',data_format=\"channels_last\")(padded_conv_1_1)\n",
    "    pool_1 = MaxPooling2D(pool_size=(2, 2), strides=(2,2), padding='same', data_format=\"channels_last\")(conv_1_2)\n",
    "    \n",
    "    padded_input_pool_1=  ZeroPadding2D(padding=(1), data_format=\"channels_last\")(pool_1)\n",
    "    conv_2_1 = Conv2D(128, kernel_size=(3, 3),strides=(1, 1), padding='valid', activation='relu',data_format=\"channels_last\")(padded_input_pool_1)\n",
    "    padded_input_conv_2_1 = ZeroPadding2D(padding=(1), data_format=\"channels_last\")(conv_2_1)\n",
    "    conv_2_2 = Conv2D(128, kernel_size=(3, 3),strides=(1, 1), padding='valid', activation='relu',data_format=\"channels_last\")(padded_input_conv_2_1)\n",
    "    pool_2 = MaxPooling2D(pool_size=(2, 2), strides=(2,2), padding='same', data_format=\"channels_last\")(conv_2_2)\n",
    "    \n",
    "    padded_input_pool_2=  ZeroPadding2D(padding=(1), data_format=None)(pool_2)\n",
    "    conv_3_1 = Conv2D(256, kernel_size=(3, 3),strides=(1, 1), padding='valid', activation='relu')(padded_input_pool_2)\n",
    "    padded_input_conv_3_1 = ZeroPadding2D(padding=(1), data_format=None)(conv_3_1)\n",
    "    conv_3_2 = Conv2D(256, kernel_size=(3, 3),strides=(1, 1), padding='valid', activation='relu')(padded_input_conv_3_1)\n",
    "    padded_input_conv_3_2 = ZeroPadding2D(padding=(1), data_format=None)(conv_3_2)\n",
    "    conv_3_3 = Conv2D(256, kernel_size=(3, 3),strides=(1, 1), padding='valid', activation='relu')(padded_input_conv_3_2)\n",
    "    pool_3 = MaxPooling2D(pool_size=(2, 2), strides=(2,2), padding='same', data_format=None)(conv_3_3)\n",
    "    \n",
    "    padded_input_pool_3 =  ZeroPadding2D(padding=(1), data_format=None)(pool_3)\n",
    "    conv_4_1 = Conv2D(512, kernel_size=(3, 3),strides=(1, 1), padding='valid', activation='relu')(padded_input_pool_3)\n",
    "    padded_input_conv_4_1 = ZeroPadding2D(padding=(1), data_format=None)(conv_4_1)\n",
    "    conv_4_2 = Conv2D(512, kernel_size=(3, 3),strides=(1, 1), padding='valid', activation='relu')(padded_input_conv_4_1)\n",
    "    padded_input_conv_4_2 = ZeroPadding2D(padding=(1), data_format=None)(conv_4_2)\n",
    "    conv_4_3 = Conv2D(512, kernel_size=(3, 3),strides=(1, 1), padding='valid', activation='relu')(padded_input_conv_4_2)\n",
    "    pool_4 = MaxPooling2D(pool_size=(2, 2), strides=(2,2), padding='same', data_format=None)(conv_4_3)\n",
    "    \n",
    "    padded_input_pool_4 =  ZeroPadding2D(padding=(1), data_format=None)(pool_4)\n",
    "    conv_5_1 = Conv2D(512, kernel_size=(3, 3),strides=(1, 1), padding='valid', activation='relu')(padded_input_pool_4)\n",
    "    padded_input_conv_5_1 = ZeroPadding2D(padding=(1), data_format=None)(conv_5_1)\n",
    "    conv_5_2 = Conv2D(512, kernel_size=(3, 3),strides=(1, 1), padding='valid', activation='relu')(padded_input_conv_5_1)\n",
    "    padded_input_conv_5_2 = ZeroPadding2D(padding=(1), data_format=None)(conv_5_2)\n",
    "    conv_5_3 = Conv2D(512, kernel_size=(3, 3),strides=(1, 1), padding='valid', activation='relu')(padded_input_conv_5_2)\n",
    "    \n",
    "    \n",
    "    #'Decoder'\n",
    "    deconv_5_1 = Conv2DTranspose(512,kernel_size=(4, 4),strides=(2, 2), padding='valid', activation='relu')(conv_5_3)\n",
    "    deconv_5_2 = Conv2DTranspose(256,kernel_size=(4, 4),strides=(2, 2), padding='valid', activation='relu')(deconv_5_1)\n",
    "    deconv_5_3 = Conv2DTranspose(128,kernel_size=(4, 4),strides=(2, 2), padding='valid', activation='relu')(deconv_5_2)\n",
    "    deconv_5_4 = Conv2DTranspose(64,kernel_size=(4, 4),strides=(2, 2), padding='valid', activation='relu')(deconv_5_3)\n",
    "    \n",
    "    attention1 = Conv2D(1, kernel_size=(3, 3),strides=(1, 1), padding='valid', activation='relu')(deconv_5_4 )\n",
    "    attention1c = Cropping2D(cropping= ((54,54),(54,54)), data_format=None)(attention1)\n",
    "    self.bn_attention1c = BatchNormalization(name='ba1c')(attention1c)\n",
    "    \n",
    "    deconv_4_1 = Conv2DTranspose(256,kernel_size=(4, 4),strides=(2, 2), padding='valid', activation='relu')(conv_4_3)\n",
    "    deconv_4_2 = Conv2DTranspose(128,kernel_size=(4, 4),strides=(2, 2), padding='valid', activation='relu')(deconv_4_1)\n",
    "    deconv_4_3 = Conv2DTranspose(64,kernel_size=(4, 4),strides=(2, 2), padding='valid', activation='relu')(deconv_4_2)\n",
    "    \n",
    "    attention2 = Conv2D(1, kernel_size=(3, 3),strides=(1, 1), padding='valid', activation='relu')(deconv_4_3 )\n",
    "    attention2c = Cropping2D(cropping= ((42,42),(42,42)))(attention2)\n",
    "    self.bn_attention2c = BatchNormalization(name='ba2c')(attention2c)\n",
    "    \n",
    "    deconv_3_1 = Conv2DTranspose(128,kernel_size=(4, 4),strides=(2, 2), padding='valid', activation='relu')(conv_3_3)\n",
    "    deconv_3_2 = Conv2DTranspose(64,kernel_size=(4, 4),strides=(2, 2), padding='valid', activation='relu')(deconv_3_1)\n",
    "    \n",
    "    attention3 = Conv2D(1, kernel_size=(3, 3),strides=(1, 1), padding='valid', activation='relu')(deconv_3_2)\n",
    "    attention3c = Cropping2D(cropping= ((36,36),(36,36)))(attention3)\n",
    "    self.bn_attention3c = BatchNormalization(name='ba3c')(attention3c)\n",
    "    \n",
    "    attention = concatenate([attention1c,attention2c,attention3c])\n",
    "    padded_attention = ZeroPadding2D(padding=(1))(attention)\n",
    "    final_attention =  Conv2D(1, kernel_size=(3, 3),strides=(1, 1), padding='valid', activation='relu',data_format=\"channels_last\")(padded_attention)\n",
    "    self.bn_final_attention = BatchNormalization(name='bafc')(final_attention)\n",
    "    \n",
    "    \n",
    "    self.model = Model(inputs=self.x, outputs=[self.bn_attention1c,self.bn_attention2c,self.bn_attention3c,self.bn_final_attention ])\n",
    "    \n",
    "    def custom_loss(y_true, y_pred):\n",
    "             loss1=losses.binary_crossentropy(y_true,self.bn_attention1c)\n",
    "             loss2=losses.binary_crossentropy(y_true,self.bn_attention2c)\n",
    "             loss3=losses.binary_crossentropy(y_true,self.bn_attention3c)\n",
    "             loss4=losses.binary_crossentropy(y_true,self.bn_final_attention)\n",
    "             return (loss1+loss2+loss3+loss4)/4.0\n",
    "          \n",
    "    sgd = optimizers.SGD(lr=self.lr) #Stochastic Gradient Descent Optimizer\n",
    "    self.loss = custom_loss\n",
    "    self.model.compile(optimizer = sgd , loss = self.loss, metrics=['accuracy'])\n",
    "    \n",
    "\n",
    "  def Train(self):\n",
    "    global output\n",
    "    global input_image_full\n",
    "    global req_output_image_full\n",
    "    factor=0.20\n",
    "    patience=5\n",
    "    model_name_folder = 'conv2d_attention'\n",
    "    \n",
    "    num_train_sequences = len(getData('train',training_Path))\n",
    "    num_val_sequences = len(getData('val',validation_Path))\n",
    "    \n",
    "    steps_per_epoch = get_step_per_epoch(num_train_sequences, batch_size)\n",
    "    validation_steps = get_validation_steps(num_val_sequences, batch_size)\n",
    "    \n",
    "    train_generator = generator(batch_size, training_Path, mode='train')\n",
    "    validation_generator = generator(batch_size, validation_Path, mode='val')\n",
    "    \n",
    "    callbacks_model = callbacks_list(model_name_folder,factor,patience)\n",
    "    \n",
    "#     X_train,Y_train = training_generator[0]\n",
    "#     X_test,Y_test = validation_generator[0]\n",
    "    # History object stores loss and accuracy\n",
    "    hist_obj = self.model.fit_generator(train_generator,validation_data=validation_generator,\n",
    "                                        steps_per_epoch=steps_per_epoch,validation_steps=validation_steps,\n",
    "                                        epochs=self.epochs,verbose=1,callbacks=callbacks_model,initial_epoch=0)\n",
    "    \n",
    "#     ,callbacks=callbacks_list_for_Conv2D_plus_lstm_model\n",
    "#     output = self.model.predict(X_test)\n",
    "#     output = np.array(output)\n",
    "    \n",
    "    # Making data global, to be used for visualization\n",
    "#     input_image_full = X_train[:,:,:]\n",
    "#     req_output_image_full =Y_train[0][:,:,:]\n",
    "    \n",
    "    return hist_obj\n",
    " \n",
    "  \n",
    "  # Prints the model architecture\n",
    "  def get_Model_Summary(self):      \n",
    "      print(self.model.summary())\n",
    "    \n",
    "\n",
    "  def Visualise_Output(self,idx):\n",
    "    self.input_image =input_image_full[idx,:,:]\n",
    "    self.req_output_image =req_output_image_full[idx,:,:]\n",
    "    pred_image_1 = output[0,idx,:,:,:]\n",
    "    pred_image_2 = output[1,idx,:,:,:]\n",
    "    pred_image_3 = output[2,idx,:,:,:]\n",
    "    pred_image_4 = output[3,idx,:,:,:]\n",
    "    fig = plt.figure(figsize=(20,10))\n",
    "    plt.subplot(231)\n",
    "    plt.imshow((self.input_image.reshape(224,224,3)), interpolation='none')\n",
    "    plt.title(\"Input - \")\n",
    "    ax = plt.gca()\n",
    "    ax.grid(False)\n",
    "    plt.subplot(232)\n",
    "    plt.imshow(self.req_output_image.reshape(224,224)*255,interpolation='none')\n",
    "    plt.title(\"Ground Truth Attention\")\n",
    "    ax = plt.gca()\n",
    "    ax.grid(False)\n",
    "    plt.subplot(233)\n",
    "    plt.imshow(pred_image_1.reshape(224,224)*255,interpolation='none')\n",
    "    plt.title(\"Predicted Attention 1 \")\n",
    "    ax = plt.gca()\n",
    "    ax.grid(False)\n",
    "    plt.subplot(234)\n",
    "    plt.imshow(pred_image_2.reshape(224,224)*255,interpolation='none')\n",
    "    plt.title(\"Predicted Attention 2 \")\n",
    "    ax = plt.gca()\n",
    "    ax.grid(False)\n",
    "    plt.subplot(235)\n",
    "    plt.imshow(pred_image_3.reshape(224,224)*255,interpolation='none')\n",
    "    plt.title(\"Predicted Attention 3 \")\n",
    "    ax = plt.gca()\n",
    "    ax.grid(False)\n",
    "    plt.subplot(236)\n",
    "    plt.imshow(pred_image_4.reshape(224,224)*255,interpolation='none')\n",
    "    plt.title(\"Predicted Final Attention \")\n",
    "    ax = plt.gca()\n",
    "    ax.grid(False)\n",
    "    plot_name = 'plot' + '_'+str(idx)+'.png'\n",
    "    print(plot_name)\n",
    "    fig.savefig(plot_name)\n",
    "    \n",
    "    \n",
    " \n",
    "  \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###########################################\n",
      "original_img_size  (224, 224, 3)\n",
      "###########################################\n"
     ]
    }
   ],
   "source": [
    "deconvNet = AttentionModel()\n",
    "deconvNet.DeepAttentionModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D (None, 294, 294, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 292, 292, 64) 1792        zero_padding2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPadding2D (None, 294, 294, 64) 0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 292, 292, 64) 36928       zero_padding2d_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 146, 146, 64) 0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPadding2D (None, 148, 148, 64) 0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 146, 146, 128 73856       zero_padding2d_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPadding2D (None, 148, 148, 128 0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 146, 146, 128 147584      zero_padding2d_4[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 73, 73, 128)  0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_5 (ZeroPadding2D (None, 75, 75, 128)  0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 73, 73, 256)  295168      zero_padding2d_5[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_6 (ZeroPadding2D (None, 75, 75, 256)  0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 73, 73, 256)  590080      zero_padding2d_6[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_7 (ZeroPadding2D (None, 75, 75, 256)  0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 73, 73, 256)  590080      zero_padding2d_7[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 37, 37, 256)  0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_8 (ZeroPadding2D (None, 39, 39, 256)  0           max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 37, 37, 512)  1180160     zero_padding2d_8[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_9 (ZeroPadding2D (None, 39, 39, 512)  0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 37, 37, 512)  2359808     zero_padding2d_9[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_10 (ZeroPadding2 (None, 39, 39, 512)  0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 37, 37, 512)  2359808     zero_padding2d_10[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 19, 19, 512)  0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_11 (ZeroPadding2 (None, 21, 21, 512)  0           max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 19, 19, 512)  2359808     zero_padding2d_11[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_12 (ZeroPadding2 (None, 21, 21, 512)  0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 19, 19, 512)  2359808     zero_padding2d_12[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_13 (ZeroPadding2 (None, 21, 21, 512)  0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 19, 19, 512)  2359808     zero_padding2d_13[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 40, 40, 512)  4194816     conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 82, 82, 256)  2097408     conv2d_transpose_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTrans (None, 76, 76, 256)  2097408     conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 166, 166, 128 524416      conv2d_transpose_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_6 (Conv2DTrans (None, 154, 154, 128 524416      conv2d_transpose_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_8 (Conv2DTrans (None, 148, 148, 128 524416      conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTrans (None, 334, 334, 64) 131136      conv2d_transpose_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_7 (Conv2DTrans (None, 310, 310, 64) 131136      conv2d_transpose_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_9 (Conv2DTrans (None, 298, 298, 64) 131136      conv2d_transpose_8[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 332, 332, 1)  577         conv2d_transpose_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 308, 308, 1)  577         conv2d_transpose_7[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 296, 296, 1)  577         conv2d_transpose_9[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d_1 (Cropping2D)       (None, 224, 224, 1)  0           conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d_2 (Cropping2D)       (None, 224, 224, 1)  0           conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d_3 (Cropping2D)       (None, 224, 224, 1)  0           conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 224, 224, 3)  0           cropping2d_1[0][0]               \n",
      "                                                                 cropping2d_2[0][0]               \n",
      "                                                                 cropping2d_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_14 (ZeroPadding2 (None, 226, 226, 3)  0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 224, 224, 1)  28          zero_padding2d_14[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "ba1c (BatchNormalization)       (None, 224, 224, 1)  4           cropping2d_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "ba2c (BatchNormalization)       (None, 224, 224, 1)  4           cropping2d_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "ba3c (BatchNormalization)       (None, 224, 224, 1)  4           cropping2d_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bafc (BatchNormalization)       (None, 224, 224, 1)  4           conv2d_17[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 25,072,751\n",
      "Trainable params: 25,072,743\n",
      "Non-trainable params: 8\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "deconvNet.get_Model_Summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "factor_rate:  0.2\n",
      "Epoch 1/5\n",
      "No of Batch :  43  mode:  val\n",
      "No of Batch :  101  mode:  train\n",
      "  2/102 [..............................] - ETA: 1:50:57 - loss: 0.0020 - ba1c_loss: 4.9771e-04 - ba2c_loss: 4.9771e-04 - ba3c_loss: 4.9771e-04 - bafc_loss: 4.9771e-04 - ba1c_accuracy: 1.0000 - ba2c_accuracy: 1.0000 - ba3c_accuracy: 1.0000 - bafc_accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\brsingh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\training_generator.py\", line 220, in fit_generator\n",
      "    reset_metrics=False)\n",
      "  File \"c:\\users\\brsingh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\training.py\", line 1514, in train_on_batch\n",
      "    outputs = self.train_function(ins)\n",
      "  File \"c:\\users\\brsingh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\", line 3740, in __call__\n",
      "    outputs = self._graph_fn(*converted_inputs)\n",
      "  File \"c:\\users\\brsingh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\", line 1081, in __call__\n",
      "    return self._call_impl(args, kwargs)\n",
      "  File \"c:\\users\\brsingh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\", line 1121, in _call_impl\n",
      "    return self._call_flat(args, self.captured_inputs, cancellation_manager)\n",
      "  File \"c:\\users\\brsingh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\", line 1224, in _call_flat\n",
      "    ctx, args, cancellation_manager=cancellation_manager)\n",
      "  File \"c:\\users\\brsingh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\", line 511, in call\n",
      "    ctx=ctx)\n",
      "  File \"c:\\users\\brsingh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\", line 61, in quick_execute\n",
      "    num_outputs)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\brsingh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2963, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-13-1e944e6043cb>\", line 1, in <module>\n",
      "    hist_obj = deconvNet.Train()\n",
      "  File \"<ipython-input-10-36040123b87e>\", line 128, in Train\n",
      "    epochs=self.epochs,verbose=1,callbacks=callbacks_model,initial_epoch=0)\n",
      "  File \"c:\\users\\brsingh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\legacy\\interfaces.py\", line 91, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\users\\brsingh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\training.py\", line 1732, in fit_generator\n",
      "    initial_epoch=initial_epoch)\n",
      "  File \"c:\\users\\brsingh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\training_generator.py\", line 290, in fit_generator\n",
      "    val_enqueuer.stop()\n",
      "  File \"c:\\users\\brsingh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\utils\\data_utils.py\", line 499, in stop\n",
      "    self.queue.unfinished_tasks = 0\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\brsingh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 1863, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\brsingh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"c:\\users\\brsingh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 311, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"c:\\users\\brsingh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 345, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"c:\\users\\brsingh\\appdata\\local\\programs\\python\\python36\\lib\\inspect.py\", line 1483, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"c:\\users\\brsingh\\appdata\\local\\programs\\python\\python36\\lib\\inspect.py\", line 1441, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"c:\\users\\brsingh\\appdata\\local\\programs\\python\\python36\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"c:\\users\\brsingh\\appdata\\local\\programs\\python\\python36\\lib\\inspect.py\", line 739, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"c:\\users\\brsingh\\appdata\\local\\programs\\python\\python36\\lib\\inspect.py\", line 708, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"c:\\users\\brsingh\\appdata\\local\\programs\\python\\python36\\lib\\inspect.py\", line 693, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"c:\\users\\brsingh\\appdata\\local\\programs\\python\\python36\\lib\\genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\brsingh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\training_generator.py\", line 220, in fit_generator\n",
      "    reset_metrics=False)\n",
      "  File \"c:\\users\\brsingh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\training.py\", line 1514, in train_on_batch\n",
      "    outputs = self.train_function(ins)\n",
      "  File \"c:\\users\\brsingh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\", line 3740, in __call__\n",
      "    outputs = self._graph_fn(*converted_inputs)\n",
      "  File \"c:\\users\\brsingh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\", line 1081, in __call__\n",
      "    return self._call_impl(args, kwargs)\n",
      "  File \"c:\\users\\brsingh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\", line 1121, in _call_impl\n",
      "    return self._call_flat(args, self.captured_inputs, cancellation_manager)\n",
      "  File \"c:\\users\\brsingh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\", line 1224, in _call_flat\n",
      "    ctx, args, cancellation_manager=cancellation_manager)\n",
      "  File \"c:\\users\\brsingh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\", line 511, in call\n",
      "    ctx=ctx)\n",
      "  File \"c:\\users\\brsingh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\", line 61, in quick_execute\n",
      "    num_outputs)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\brsingh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2963, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-13-1e944e6043cb>\", line 1, in <module>\n",
      "    hist_obj = deconvNet.Train()\n",
      "  File \"<ipython-input-10-36040123b87e>\", line 128, in Train\n",
      "    epochs=self.epochs,verbose=1,callbacks=callbacks_model,initial_epoch=0)\n",
      "  File \"c:\\users\\brsingh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\legacy\\interfaces.py\", line 91, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"c:\\users\\brsingh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\training.py\", line 1732, in fit_generator\n",
      "    initial_epoch=initial_epoch)\n",
      "  File \"c:\\users\\brsingh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\training_generator.py\", line 290, in fit_generator\n",
      "    val_enqueuer.stop()\n",
      "  File \"c:\\users\\brsingh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\utils\\data_utils.py\", line 499, in stop\n",
      "    self.queue.unfinished_tasks = 0\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\brsingh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 1863, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\brsingh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2903, in run_ast_nodes\n",
      "    if self.run_code(code, result):\n",
      "  File \"c:\\users\\brsingh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2980, in run_code\n",
      "    self.showtraceback(running_compiled_code=True)\n",
      "  File \"c:\\users\\brsingh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 1866, in showtraceback\n",
      "    value, tb, tb_offset=tb_offset)\n",
      "  File \"c:\\users\\brsingh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1373, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
      "  File \"c:\\users\\brsingh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1281, in structured_traceback\n",
      "    self, etype, value, tb, tb_offset, number_of_lines_of_context\n",
      "  File \"c:\\users\\brsingh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1144, in structured_traceback\n",
      "    formatted_exceptions += self.prepare_chained_exception_message(evalue.__cause__)\n",
      "TypeError: must be str, not list\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\brsingh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 1863, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\brsingh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"c:\\users\\brsingh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 311, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"c:\\users\\brsingh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 345, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"c:\\users\\brsingh\\appdata\\local\\programs\\python\\python36\\lib\\inspect.py\", line 1483, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"c:\\users\\brsingh\\appdata\\local\\programs\\python\\python36\\lib\\inspect.py\", line 1441, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"c:\\users\\brsingh\\appdata\\local\\programs\\python\\python36\\lib\\inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"c:\\users\\brsingh\\appdata\\local\\programs\\python\\python36\\lib\\inspect.py\", line 739, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"c:\\users\\brsingh\\appdata\\local\\programs\\python\\python36\\lib\\inspect.py\", line 708, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"c:\\users\\brsingh\\appdata\\local\\programs\\python\\python36\\lib\\inspect.py\", line 693, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"c:\\users\\brsingh\\appdata\\local\\programs\\python\\python36\\lib\\genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "must be str, not list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\brsingh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    219\u001b[0m                                             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 220\u001b[1;33m                                             reset_metrics=False)\n\u001b[0m\u001b[0;32m    221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\brsingh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[0;32m   1513\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1514\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\brsingh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3739\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3740\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\brsingh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1080\u001b[0m     \"\"\"\n\u001b[1;32m-> 1081\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1082\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\brsingh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1120\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[1;32m-> 1121\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\brsingh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[1;32m-> 1224\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1225\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\brsingh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    512\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\brsingh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\brsingh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   1862\u001b[0m                         \u001b[1;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1863\u001b[1;33m                         \u001b[0mstb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1864\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\brsingh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mrun_code\u001b[1;34m(self, code_obj, result)\u001b[0m\n\u001b[0;32m   2978\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2979\u001b[0m                 \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_in_exec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2980\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshowtraceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrunning_compiled_code\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2981\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2982\u001b[0m             \u001b[0moutflag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\brsingh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   1864\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1865\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[1;32m-> 1866\u001b[1;33m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[0;32m   1867\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1868\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_showtraceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\brsingh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1371\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1372\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[1;32m-> 1373\u001b[1;33m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[0;32m   1374\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1375\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\brsingh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1279\u001b[0m             \u001b[1;31m# Verbose modes need a full traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1280\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[1;32m-> 1281\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1282\u001b[0m             )\n\u001b[0;32m   1283\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\brsingh\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1142\u001b[0m         \u001b[0mexception\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_parts_of_chained_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1143\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1144\u001b[1;33m             \u001b[0mformatted_exceptions\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprepare_chained_exception_message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__cause__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1145\u001b[0m             \u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0metb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1146\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: must be str, not list"
     ]
    }
   ],
   "source": [
    "hist_obj = deconvNet.Train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import csv\n",
    "import nltk as nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "import pyreadr\n",
    "from mlutils import dataset\n",
    "import multiprocessing as mp\n",
    "from multiprocessing import Pool\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import re\n",
    "from collections import OrderedDict\n",
    "from torch.autograd import Variable\n",
    "from IPython.core.display import display, HTML\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mkt = 'SAMS'\n",
    "sbu = 'FOOD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------- Node Parameters ----------------------#\n",
    "#mkt = getArgument(\"mkt\", \"PARAMS\")\n",
    "#sbu = getArgument(\"sbu\", \"PARAMS\")\n",
    "\n",
    "\n",
    "#----------------------------- Input_Path -------------------------------------#\n",
    "inp_path = '/data/'+mkt+'/'+sbu+'/'\n",
    "\n",
    "#Master_data_paths\n",
    "model_data_path = inp_path +'01_raw_data/ing_nut_model_data.rds'\n",
    "\n",
    "#Reading the Master File\n",
    "#master_file = dataset.load(name = 'us_food_upc_master_data')\n",
    "result = pyreadr.read_r(model_data_path)\n",
    "total_nutrient = result[None] # extr\n",
    "\n",
    "\n",
    "#Secondary_mapping_files\n",
    "data_unimp_extract_path = inp_path + '04_clean_ing/sec_unimp_cleaned'\n",
    "df_secondary_path =   inp_path + '03_ing_matches/sec_ing_match'\n",
    "df_primary_path = inp_path + '03_ing_matches/prim_ing_match'\n",
    "total_sec_path = inp_path + '04_clean_ing/sec_total_cleaned'\n",
    "constraint_path = inp_path + '00_base_files/Ingredients_constraints.xlsx'\n",
    "\n",
    "\n",
    "#-----------------Input to ALgorithm------------------------------------------#\n",
    "sec_path = inp_path + '05_ing_share/sec_input/'\n",
    "\n",
    "\n",
    "df_prim_filt = pd.read_pickle(sec_path + 'df_prim_filt.pkl')\n",
    "df_sec_ingred_nutr = pd.read_pickle(sec_path + 'df_sec_ingred_nutr.pkl')\n",
    "data_unimp_extract = pd.read_pickle(sec_path + 'data_unimp_extract.pkl')\n",
    "df_total = pd.read_pickle(sec_path + 'df_total.pkl')\n",
    "\n",
    "#-----------------Output from ALgorithm------------------------------------------#\n",
    "output_path_name = inp_path + '05_ing_share/sec_temp_output/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15182/15182 [00:01<00:00, 12262.64it/s]\n"
     ]
    }
   ],
   "source": [
    "#df_prop_dict has the relevant information regarding each secondary ingredient and the corresponding rank\n",
    "df_prop_dict_sec = {}\n",
    "for i in tqdm(range(0,len(df_sec_ingred_nutr))):\n",
    "    upc =  df_sec_ingred_nutr['UPC'].iloc[i]\n",
    "    prim = df_sec_ingred_nutr['Primary Ingredient'].iloc[i]\n",
    "    sec =  df_sec_ingred_nutr['Secondary Ingredient'].iloc[i]\n",
    "    prop = df_sec_ingred_nutr['Proportion'].iloc[i]\n",
    "    \n",
    "    df_prop_dict_sec[upc,prim,sec] = prop\n",
    "\n",
    "\n",
    "# In[23]:\n",
    "\n",
    "\n",
    "nutritional_components = ['protein_per_100grams','total_fat_per_100grams',\n",
    "                         'carbohydrates_per_100grams','calories_per_100grams',\n",
    "                         'saturated_fat_per_100grams','cholesterol_per_100grams',\n",
    "                         'sodium_per_100grams', 'dietary_fiber_per_100grams',\n",
    "                         'sugar_per_100grams']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_updated_nutrition(nutritional_components,primary_data,upc,prim_ingred):\n",
    "    \n",
    "    x= primary_data\n",
    "    temp = x[(x['UPC']==upc) & (x['Primary Ingredient']==prim_ingred)]\n",
    "    nutritional_components_updated=[]\n",
    "    \n",
    "    #Checking for zero values in y and removing the nutrients\n",
    "    for i in nutritional_components:\n",
    "        if temp[i].values[0] != 0:\n",
    "            nutritional_components_updated.append(i)\n",
    "            \n",
    "    return nutritional_components_updated\n",
    "\n",
    "\n",
    "# In[25]:\n",
    "\n",
    "\n",
    "def get_food_comp_dict(primary_data,upc,prim_ingred,secondary_data):\n",
    "    \n",
    "    #Food_comp dict\n",
    "    food_composition = {}\n",
    "    \n",
    "    #Secondary ingredient data\n",
    "    sec_ingredient_data = secondary_data[(secondary_data['UPC']==upc) & \n",
    "                                         (secondary_data['Primary Ingredient']==prim_ingred)]\n",
    "    \n",
    "    \n",
    "    #Adding the Nutrient share of the ingredient\n",
    "    for i in range(0,len(sec_ingredient_data)):\n",
    "        ing = sec_ingredient_data['Secondary Ingredient'].iloc[i]\n",
    "        nut = sec_ingredient_data.iloc[i]\n",
    "        food_composition[ing]= nut\n",
    "    \n",
    "    \n",
    "    #Adding the Nutrient share of the Item\n",
    "    temp = primary_data[(primary_data['UPC']==upc) & (primary_data['Primary Ingredient']==prim_ingred)]\n",
    "    prim_ing_desc = temp['Primary Ingredient'].values[0]\n",
    "    food_composition[prim_ing_desc] =  temp.iloc[0]\n",
    "    \n",
    "    return food_composition\n",
    "\n",
    "\n",
    "# In[26]:\n",
    "\n",
    "\n",
    "def get_unimp_ingredients(upc,prim_ingred,data_unimp_extract):\n",
    "    \n",
    "    x= data_unimp_extract[(data_unimp_extract['UPC']==upc) & \n",
    "                          (data_unimp_extract['Primary_Ingredient']==prim_ingred)]\n",
    "    \n",
    "    #Getting Ingredient information for item\n",
    "    if len(x['Unimportant_Clean'].values[0]) !=0:\n",
    "        ingred_unimp = x['Unimportant_Clean'].values[0].split(',')\n",
    "        percent_unimp = int(x['Percent_unimp'].values[0])\n",
    "        \n",
    "    else :\n",
    "        ingred_unimp =''\n",
    "        percent_unimp = 0\n",
    "\n",
    "    return ingred_unimp,percent_unimp\n",
    "\n",
    "\n",
    "# In[27]:\n",
    "\n",
    "\n",
    "def get_matrix_opt(upc,prim_ingred,primary_data,secondary_data,nutritional_components):\n",
    "    \n",
    "    #Taking the primary data\n",
    "    x= primary_data\n",
    "    \n",
    "    #Getting Updated Nutritional component for the item\n",
    "    nutritional_components = get_updated_nutrition(nutritional_components,primary_data,upc,prim_ingred)\n",
    "\n",
    "    #Getting the total list\n",
    "    #ingredients_total ,ingred_unimp,unimp_percent = get_ingredients(x,upc)\n",
    "    \n",
    "    #Naming the target\n",
    "    temp = primary_data[(primary_data['UPC']==upc) & (primary_data['Primary Ingredient']==prim_ingred)]\n",
    "    prim_ing_desc = temp['Primary Ingredient'].values[0]\n",
    "    target = prim_ing_desc\n",
    "    \n",
    "    #Ingredient data for upc\n",
    "    ingredient_data = secondary_data[(secondary_data['UPC']==upc) & (secondary_data['Primary Ingredient']==prim_ingred)]\n",
    "\n",
    "    #Getting the Ingredients\n",
    "    ingredients = list(ingredient_data['Secondary Ingredient'])\n",
    "    \n",
    "    #Computing the ingredient weights\n",
    "    ingredient_weights = [None]*len(ingredients)\n",
    "    \n",
    "    ig_weights = OrderedDict(zip(ingredients, ingredient_weights))\n",
    "    #print \"%s ingredients:\" % target, json.dumps(ig_weights, indent=2)\n",
    "    \n",
    "    #Get the Food composition dict\n",
    "    food_composition = get_food_comp_dict(primary_data,upc,prim_ingred,secondary_data)\n",
    "    \n",
    "    # Formulate the problem as an optimization task:\n",
    "    # - linear model without bias\n",
    "    # - one training sample per nutritional component (proteins, carbs, etc.)\n",
    "    # - each sample Xi from X is a row vector containing the percentage of a given nutritional component in each ingredient\n",
    "    # - each output Yi from Y is a scalar corresponding to the total amount of this nutrinional component in the final product\n",
    "    # - after training, the weights are the amount of unknown ingredients in grams\n",
    "\n",
    "    X = torch.zeros(len(nutritional_components), len(ingredients))\n",
    "    W = torch.zeros(len(ingredients), 1)\n",
    "    Y = torch.zeros(len(nutritional_components), 1)\n",
    "\n",
    "    for i, nutritional_component in enumerate(nutritional_components):\n",
    "        for j, ingredient in enumerate(ingredients):\n",
    "            X[i,j] = float(food_composition[ingredient][nutritional_component])\n",
    "        Y[i,0] = food_composition[target][nutritional_component]\n",
    "\n",
    "    #initializing weights with what we know\n",
    "    for i, ingredient in enumerate(ingredients):\n",
    "        if ingredient_weights[i] is not None:\n",
    "            W[i,0] = ingredient_weights[i]\n",
    "\n",
    "    #print(\"X=\", X)\n",
    "    #print(\"W=\", W)\n",
    "    #print(\"Y=\", Y)\n",
    "\n",
    "    #normalization to be more efficient on smaller nutritional amounts\n",
    "    Y_scaler = Y.clone()\n",
    "    X.div_(Y_scaler)\n",
    "    _ = Y.div_(Y_scaler)\n",
    "    \n",
    "    #print(\"X=\", X)\n",
    "    #print(\"W=\", W)\n",
    "    #print(\"Y=\", Y)\n",
    "\n",
    "    \n",
    "    #Defining the variables\n",
    "    X = Variable(X, requires_grad=False)\n",
    "    W = Variable(W, requires_grad=True)\n",
    "    Y = Variable(Y, requires_grad=False)\n",
    "    \n",
    "    return X,W,Y,ingredient_weights\n",
    "\n",
    "\n",
    "# In[28]:\n",
    "\n",
    "\n",
    "def get_positional_rank (upc,prim,df_sec_ingred_nutr,df_prop_dict_sec) :\n",
    "    ingredient = list(df_sec_ingred_nutr[(df_sec_ingred_nutr['UPC']== upc) & (df_sec_ingred_nutr['Primary Ingredient']== prim)]['Secondary Ingredient'])\n",
    "    pos_rank = []\n",
    "\n",
    "    for ingred in ingredient :\n",
    "        pos_rank.append(df_prop_dict_sec[upc,prim,ingred])\n",
    "    \n",
    "    return np.array(pos_rank)\n",
    "\n",
    "\n",
    "# In[29]:\n",
    "\n",
    "\n",
    "def get_unimp_vec(upc ,prim, data_unimp_extract, df_sec_ingred_nutr):\n",
    "    \n",
    "    df_temp1 = data_unimp_extract[(data_unimp_extract['UPC'] == upc) & (data_unimp_extract['Primary_Ingredient'] == prim)]\n",
    "    \n",
    "    #Get unimp sec_ingred\n",
    "    ingred =  df_temp1['Unimportant_Clean'].values[0].split(',')[0]\n",
    "    \n",
    "    #Get the percent\n",
    "    per = df_temp1['Percent_unimp'].values[0]\n",
    "    \n",
    "    #Getting the array for the output vec\n",
    "    df_temp2 = df_sec_ingred_nutr[(df_sec_ingred_nutr['UPC'] == upc) & (df_sec_ingred_nutr['Primary Ingredient'] == prim)]['Secondary Ingredient']\n",
    "    list_unimp = list(df_temp2)\n",
    "    \n",
    "    #Checking\n",
    "    check = len(set(list_unimp).intersection(ingred))\n",
    "    \n",
    "    if check != 0 :\n",
    "        #Getting the position of the first unimp element\n",
    "        ind_ingred = list_unimp.index(ingred)\n",
    "        \n",
    "        #Length of array computation\n",
    "        len_arr = len(list_unimp)\n",
    "        arr = np.zeros(len_arr)\n",
    "\n",
    "        #final vector\n",
    "        arr[ind_ingred] = 1\n",
    "    \n",
    "    else :\n",
    "        arr = [None] * 5\n",
    "    \n",
    "    return arr,per\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# In[30]:\n",
    "\n",
    "\n",
    "def get_final_weights_reparam(epochs,upc,prim_ingred,df_prim_filt,df_sec_ingred_nutr,nutritional_components,data_unimp_extract,df_prop_dict_sec):\n",
    "    \n",
    "    #Defining the data\n",
    "    primary_data = df_prim_filt\n",
    "    secondary_data = df_sec_ingred_nutr\n",
    "    data_unimp_extract= data_unimp_extract\n",
    "    prim = prim_ingred\n",
    "    df_prop_dict_sec = df_prop_dict_sec\n",
    "    \n",
    "    #getting matrices\n",
    "    X,W,Y,ingredient_weights = get_matrix_opt(upc,prim_ingred,primary_data,secondary_data,nutritional_components)\n",
    "    \n",
    "    #Getting ingredient total information ----- to be done\n",
    "    ingred_unimp,unimp_percent = get_unimp_ingredients(upc,prim_ingred,data_unimp_extract)\n",
    "    \n",
    "    #Ingredient data for upc\n",
    "    ingredient_data = secondary_data[(secondary_data['UPC']==upc) & (secondary_data['Primary Ingredient']==prim_ingred)]\n",
    "\n",
    "    #Getting the Ingredients\n",
    "    ingredients = list(ingredient_data['Secondary Ingredient'])\n",
    "    \n",
    "    #Initializing V\n",
    "    V = torch.ones(len(ingredients), 1)/np.sqrt(len(ingredients))\n",
    "    #print V\n",
    "    V = Variable(V, requires_grad=True)\n",
    "    \n",
    "    #Defining the Setup for Intialisation\n",
    "    one_mat = torch.ones(len(ingredients), len(ingredients))\n",
    "    inv_seq = get_positional_rank (upc,prim,df_sec_ingred_nutr,df_prop_dict_sec)\n",
    "    inv_diag = torch.diag(torch.from_numpy(inv_seq)).type('torch.FloatTensor')\n",
    "    \n",
    "    #print inv_diag\n",
    "    one_mat_inv = one_mat.mm(inv_diag)\n",
    "    upper_tr = one_mat_inv.triu()\n",
    "    \n",
    "   \n",
    "    ####################################################################################\n",
    "    \n",
    "    #Unimportant Ingredients Constraint\n",
    "    if len(ingred_unimp) != 0 :\n",
    "        unimp_vec , per = get_unimp_vec(upc ,prim, data_unimp_extract, df_sec_ingred_nutr)\n",
    "        \n",
    "        if unimp_vec[0] != None :\n",
    "            percent = (float(per)/100.0) + 0.0001\n",
    "            unimp_tensor = torch.from_numpy(unimp_vec).type('torch.FloatTensor')\n",
    "            unimp_tensor1 = unimp_tensor.view(1,len(unimp_tensor))\n",
    "            lamda = 1\n",
    "        else :\n",
    "            lamda = 0\n",
    "\n",
    "    else :\n",
    "        lamda = 0\n",
    "        \n",
    "    ########################################################################################\n",
    "    \n",
    "    \n",
    "    #Running the Optimization\n",
    "    #alpha=1e-20\n",
    "    loss_history_par = np.zeros((epochs))\n",
    "    \n",
    "  \n",
    "    for epoch in range(epochs):\n",
    "    #Matrix multiply\n",
    "\n",
    "        Y_pred = X.mm(upper_tr.mm(V**2))\n",
    "\n",
    "        # l2 loss\n",
    "        loss_par = (Y_pred - Y).pow(2).sum()\n",
    "        #print loss\n",
    "\n",
    "        #try to go and stay at 100g total\n",
    "        V_sq = V**2\n",
    "        \n",
    "        loss_par += (V_sq.sum() - 1.).abs()*5\n",
    "        #loss_par += (V_sq.sum() - 1.)**2\n",
    "        \n",
    "        #print loss\n",
    "        \n",
    "        #If ingredient unimportant is present\n",
    "        if  lamda == 1:\n",
    "            temp1 = upper_tr.mm(V**2)\n",
    "            loss_par +=  (unimp_tensor1.mm(temp1)[0][0] - percent)\n",
    "        \n",
    "        \n",
    "        loss_history_par[epoch] = loss_par.data.item()\n",
    "        loss_par.backward()\n",
    "        \n",
    "        #Early Stopping\n",
    "        if epoch > 10 :\n",
    "            cur_loss_avg =  np.mean(loss_history_par[(epoch-5):(epoch)])\n",
    "            prev_loss_avg = np.mean(loss_history_par[(epoch-10):(epoch-6)]) \n",
    "            if np.abs(cur_loss_avg - prev_loss_avg) < 1e-6 :\n",
    "                loss_history_par = loss_history_par[0:epoch]\n",
    "                break\n",
    "\n",
    "        for i in range(V.size(0)):\n",
    "            if ingredient_weights[i] is None:  #update only unknown quantities\n",
    "                \n",
    "                #Clipping the Gradient\n",
    "                torch.nn.utils.clip_grad_norm_(V, 1)\n",
    "                \n",
    "                #performing the gradient descent algo\n",
    "                V.data[i].sub_(1e-4 * V.grad[i].data)\n",
    "                \n",
    "                \n",
    "        #V.data.sub_(1e-5 * V.grad.data)\n",
    "        V.grad.data.zero_()\n",
    "    \n",
    "    W_par = upper_tr.mm(V**2)\n",
    "        \n",
    "    return W_par,loss_history_par ,loss_par\n",
    "\n",
    "\n",
    "# In[30]:\n",
    "\n",
    "\n",
    "def get_prop_ingred_sec(list_reqd,epochs,df_prim_filt,df_sec_ingred_nutr,nutritional_components,data_unimp_extract,df_prop_dict_sec):\n",
    "\n",
    "    #Saves the proportion of ingredients\n",
    "    prob=[]\n",
    "    #Prop Ingredient\n",
    "    prop_ing=[]\n",
    "\n",
    "    #loss_history for item\n",
    "    #loss_his = []\n",
    "\n",
    "    #loss_final for each item\n",
    "    loss_final = []\n",
    "\n",
    "    #Weight sum acheived\n",
    "    weight_sum = []\n",
    "\n",
    "    #Defining the modified data\n",
    "    primary_data = df_prim_filt\n",
    "    secondary_data = df_sec_ingred_nutr\n",
    "    data_unimp_extract= data_unimp_extract\n",
    "\n",
    "    #Saving the final upc and prim_ingredient\n",
    "    #upc_final=[]\n",
    "    #prim_ingred_final=[]\n",
    "    upc_prim_output = []\n",
    "    \n",
    "    #Saving the err\n",
    "    #upc_err = []\n",
    "    #prim_err = []\n",
    "    upc_prim_err = []\n",
    "\n",
    "    #Getting the list\n",
    "    list_current = list_reqd\n",
    "    \n",
    "    \n",
    "    for i in tqdm(range(0,len(list_current))):\n",
    "\n",
    "        #Getting the UPC Information\n",
    "        upc,prim_ingred = list_current[i]\n",
    "        prim = prim_ingred\n",
    "        \n",
    "        try :\n",
    "            upc_final.append(upc)\n",
    "            prim_ingred_final.append(prim_ingred)\n",
    "\n",
    "            #Getting the Food comp dict\n",
    "            food_composition = get_food_comp_dict(primary_data,upc,prim_ingred,secondary_data)\n",
    "\n",
    "            #Get Ingredient Percentages\n",
    "            W,loss_history,loss = get_final_weights_reparam(epochs,upc,prim_ingred,df_prim_filt,\n",
    "                                                        df_sec_ingred_nutr,nutritional_components,\n",
    "                                                        data_unimp_extract,df_prop_dict_sec)\n",
    "            #Array format from tensor\n",
    "            W_arr = W.data.numpy()\n",
    "\n",
    "            #Appending the same in a list\n",
    "            prop_ing.append(W_arr)\n",
    "            loss_final.append(loss.item())\n",
    "            weight_sum.append(W.sum().item())\n",
    "            #upc_final.append(upc)\n",
    "            #prim_ingred_final.append(prim_ingred)\n",
    "            upc_prim_output.append((upc,prim_ingred))\n",
    "\n",
    "        except :\n",
    "            #print i\n",
    "            #upc_err.append(upc)\n",
    "            #prim_err.append(prim_ingred)\n",
    "            upc_prim_err.append((upc,prim_ingred))\n",
    "\n",
    "        \n",
    "        \n",
    "    return prop_ing, loss_final,weight_sum,upc_prim_output,upc_prim_err\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the List_Upc\n",
    "list_reqd = list(df_total['UPC_and_Prim'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2243/2243 [01:32<00:00, 24.37it/s]\n"
     ]
    }
   ],
   "source": [
    "#Workflow\n",
    "epochs = 1\n",
    "\n",
    "#Getting the most important ingredient\n",
    "prop_ing, loss_final, weight_sum, upc_prim_output, upc_prim_err = get_prop_ingred_sec(list_reqd,epochs,df_prim_filt,\n",
    "                                                                                  df_sec_ingred_nutr,nutritional_components,\n",
    "                                                                                  data_unimp_extract,df_prop_dict_sec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the Output\n",
    "np.save(output_path_name + 'prop_ing',np.array(prop_ing))\n",
    "np.save(output_path_name + 'loss_final',np.array(loss_final))\n",
    "np.save(output_path_name + 'weight_sum',np.array(weight_sum))\n",
    "np.save(output_path_name + 'upc_prim_output',np.array(upc_prim_output))\n",
    "\n",
    "#np.save(output_path_name + 'upc_final',np.array(upc_final))\n",
    "#np.save(output_path_name + 'prim_ingred_final',np.array(prim_ingred_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

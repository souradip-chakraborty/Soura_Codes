{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "south\n",
      "florida\n",
      "muslim\n",
      "leader\n",
      "sofian\n",
      "zakkout\n",
      "david\n",
      "duke\n",
      "day\n",
      "south florida muslim leader sofian zakkout david duke day\n",
      "['0', '0', '0', '0', '0', '0', '0', '0', '0']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Tesla P100-PCIE-16GB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0751daed476040868a0e222bff34928f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "south florida muslim leader sofian zakkout david duke day\n",
      "['south', 'florida', 'muslim', 'leader', 'sofia', '##n', 'za', '##kko', '##ut', 'david', 'duke', 'day']\n",
      "(14885, 128)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88a90609e8574c8181ce5a1204696e5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=362.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5a8178494e642379907453bb389c1f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1344997306.0, style=ProgressStyle(descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.4325159308160835\n",
      "Validation loss: 0.5662897429787196\n",
      "Validation Accuracy: 0.7369423179359702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  33%|███▎      | 1/3 [10:12<20:25, 612.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.5400203187082189\n",
      "Train loss: 0.2413677900485982\n",
      "Validation loss: 0.3941093214715903\n",
      "Validation Accuracy: 0.8996389962576485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  67%|██████▋   | 2/3 [20:34<10:15, 615.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.5694015089239872\n",
      "Train loss: 0.15713482717044108\n",
      "Validation loss: 0.42192077973427683\n",
      "Validation Accuracy: 0.9010846331402972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 3/3 [30:52<00:00, 617.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score: 0.5805552950412681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertConfig,WordpieceTokenizer\n",
    "from transformers import DistilBertForTokenClassification,DistilBertTokenizer,DistilBertConfig\n",
    "from transformers import RobertaForTokenClassification,RobertaTokenizer,RobertaConfig\n",
    "from transformers import BertForTokenClassification,BertTokenizer,BertConfig\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from transformers import AdamW\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "global max_len\n",
    "data = pd.read_csv(\"../input/data-propcsv/data_prop.csv\")\n",
    "data = data.fillna(method=\"ffill\")\n",
    "\n",
    "data['label'] = data['label'].astype(str)\n",
    "\n",
    "class SentenceGetter(object):\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.n_sent = 0\n",
    "        self.data = data\n",
    "        self.empty = False\n",
    "        agg_func = lambda s: [(w, p) for w, p in zip(s[\"word_corrected\"].values.tolist(),\n",
    "                                                           s[\"label\"].values.tolist())]\n",
    "        \n",
    "        self.grouped = self.data.groupby(\"sent_id\").apply(agg_func)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "    \n",
    "    def get_next(self):\n",
    "        try:\n",
    "            s = self.grouped[self.n_sent]\n",
    "            self.n_sent += 1\n",
    "            return s\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "getter = SentenceGetter(data)\n",
    "\n",
    "\n",
    "sent = getter.sentences\n",
    "\n",
    "for s in sent[0]:\n",
    "    print(s[0].split()[0])\n",
    "    \n",
    "\n",
    "##keeping only the first word after removing the special characters\n",
    "sentences = [\" \".join([s[0].split()[0] for s in sent]) for sent in getter.sentences]\n",
    "print(sentences[0])\n",
    "\n",
    "labels = [[s[1] for s in sent] for sent in getter.sentences]\n",
    "print(labels[0])\n",
    "\n",
    "# tags_vals = list(set(data[\"label\"].values))\n",
    "# tag2idx = {t: i for i, t in enumerate(tags_vals)}\n",
    "\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler,WeightedRandomSampler\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "MAX_LEN = 128\n",
    "bs = 32\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "n_gpu = torch.cuda.device_count()\n",
    "\n",
    "print(n_gpu)\n",
    "print(torch.cuda.get_device_name(0))\n",
    "# tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased', do_lower_case=True)\n",
    "# tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased', do_lower_case=True)\n",
    "\n",
    "### Now we tokenize all sentences\n",
    "\n",
    "\n",
    "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
    "\n",
    "\n",
    "print(sentences[0])\n",
    "print(tokenized_texts[0])\n",
    "\n",
    "def reg_encoding(cleaned: list, labels: list, hash_token:list) -> list:\n",
    "    label_l = []\n",
    "    for oindex, x in enumerate(cleaned):\n",
    "        #print(oindex)\n",
    "        tlist = []        \n",
    "        i=0\n",
    "        j=0\n",
    "        while i < len(x): \n",
    "            if x[i][0]=='#':        \n",
    "                tlist.append(hash_token)\n",
    "            else:\n",
    "                #print(x[i])\n",
    "                tlist.append(labels[oindex][j])\n",
    "                j=j+1\n",
    "            i=i+1\n",
    "            \n",
    "        label_l.append(tlist)\n",
    "    return label_l\n",
    "\n",
    "def reg_encoding_generic(sentences,labels, hash_token):\n",
    "    tokens_all=[]\n",
    "    labels_all=[]\n",
    "    for (sentence,label) in zip(sentences,labels):\n",
    "        tokens_per_sentence=[]\n",
    "        labels_per_sentence=[]\n",
    "        for word, label in zip(sentence.split(), label):\n",
    "            word_tokens = tokenizer.tokenize(word)\n",
    "            if len(word_tokens) > 0:\n",
    "                tokens_per_sentence.extend(word_tokens)\n",
    "                labels_per_sentence.extend([label] + [hash_token] * (len(word_tokens) - 1))\n",
    "#                 labels_per_sentence.extend([label] + [label] * (len(word_tokens) - 1))\n",
    "\n",
    "        \n",
    "        tokens_all.append(tokens_per_sentence)\n",
    "        labels_all.append(labels_per_sentence)\n",
    "                \n",
    "    return tokens_all,labels_all\n",
    "\n",
    "def reg_encoding_modify(cleaned: list, labels: list, hash_token, end_token) -> list:\n",
    "    label_l = []\n",
    "    for oindex, x in enumerate(cleaned):\n",
    "        #print(oindex)\n",
    "        tlist = []        \n",
    "        i=0\n",
    "        j=0\n",
    "        while i < len(x): \n",
    "            if x[i][0]=='#':        \n",
    "                #tlist.append(hash_token)\n",
    "                tlist.append(labels[oindex][j-1])\n",
    "                \n",
    "            else:\n",
    "                #print(x[i])\n",
    "                tlist.append(labels[oindex][j])\n",
    "                j=j+1\n",
    "            i=i+1\n",
    "            \n",
    "        label_l.append(tlist)\n",
    "    return label_l\n",
    "\n",
    "\n",
    "tokenized_texts,label_l = reg_encoding_generic(sentences,labels,'X')\n",
    "\n",
    "\n",
    "flat_list = [item for sublist in label_l for item in sublist]\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "#label_l_modify = reg_encoding_modify(tokenized_texts,labels,'X','E')\n",
    "\n",
    "# data['label'].unique()\n",
    "\n",
    "tags_vals=['0','1','X']\n",
    "tag2idx={'0':0,'1':1,'X':2}\n",
    "\n",
    "# tags_vals=['0','1']\n",
    "# tag2idx={'0':0,'1':1}\n",
    "\n",
    "\n",
    "\n",
    "input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts],maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "\n",
    "\n",
    "tags = pad_sequences([[tag2idx.get(l) for l in lab] for lab in label_l],maxlen=MAX_LEN, value =0, padding=\"post\",dtype=\"long\", truncating=\"post\")\n",
    "\n",
    "attention_masks = [[float(i>0) for i in ii] for ii in input_ids]\n",
    "\n",
    "tr_inputs, val_inputs, tr_tags, val_tags = train_test_split(input_ids, tags,random_state=2018, test_size=0.1)\n",
    "tr_masks, val_masks, _, _ = train_test_split(attention_masks, input_ids,random_state=2018, test_size=0.1)\n",
    "\n",
    "sent_labels=np.zeros(tr_tags.shape[0],dtype=int)\n",
    "for i in range(len(tr_tags)):\n",
    "    if 1 in tr_tags[i,:]:\n",
    "        sent_labels[i]=1\n",
    "    \n",
    "        \n",
    "print(tr_inputs.shape)\n",
    "\n",
    "tr_inputs = torch.tensor(tr_inputs)\n",
    "val_inputs = torch.tensor(val_inputs)\n",
    "tr_tags = torch.tensor(tr_tags)\n",
    "val_tags = torch.tensor(val_tags)\n",
    "tr_masks = torch.tensor(tr_masks)\n",
    "val_masks = torch.tensor(val_masks)\n",
    "\n",
    "train_data = TensorDataset(tr_inputs, tr_masks, tr_tags) \n",
    "train_sampler = RandomSampler(train_data)\n",
    "_,class_sample_count=np.unique( sent_labels , return_counts=True)   \n",
    "class_sample_counts=list(class_sample_count)\n",
    "# class_sample_count = [10, 1, 20, 3, 4] # dataset has 10 class-1 samples, 1 class-2 samples, etc.\n",
    "weights = 1. / torch.tensor(class_sample_counts, dtype=torch.float)\n",
    "samples_weights = weights[sent_labels]\n",
    "sampler = torch.utils.data.sampler.WeightedRandomSampler(samples_weights, num_samples=len(samples_weights),replacement=True)\n",
    "train_dataloader = DataLoader(train_data, batch_size = bs, sampler = sampler)\n",
    "\n",
    "# train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=bs)\n",
    "valid_data = TensorDataset(val_inputs, val_masks, val_tags)\n",
    "valid_sampler = SequentialSampler(valid_data)\n",
    "valid_dataloader = DataLoader(valid_data, sampler=valid_sampler, batch_size=bs)\n",
    "\n",
    "\n",
    "# model = DistilBertForTokenClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=len(tag2idx))\n",
    "# model = RobertaForTokenClassification.from_pretrained(\"roberta-base\", num_labels=len(tag2idx))\n",
    "\n",
    "model = BertForTokenClassification.from_pretrained(\"bert-large-uncased\", num_labels=len(tag2idx))\n",
    "\n",
    "\n",
    "model.cuda()\n",
    "\n",
    "FULL_FINETUNING = True\n",
    "\n",
    "if FULL_FINETUNING:\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = ['bias', 'gamma', 'beta']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "         'weight_decay_rate': 0.01},\n",
    "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "         'weight_decay_rate': 0.0}\n",
    "    ]\n",
    "else:\n",
    "    param_optimizer = list(model.classifier.named_parameters()) \n",
    "    optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]\n",
    "optimizer = Adam(optimizer_grouped_parameters, lr=3e-5)\n",
    "# scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=2, num_training_steps=5)\n",
    "# opt = SWA(optimizer, swa_start=10, swa_freq=2, swa_lr=0.05)\n",
    "\n",
    "\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=2).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "\n",
    "import pickle\n",
    "\n",
    "\n",
    "\n",
    "epochs = 3\n",
    "max_grad_norm = 1.0\n",
    "tmp=0\n",
    "\n",
    "\n",
    "for _ in trange(epochs, desc=\"Epoch\"):\n",
    "    # TRAIN loop\n",
    "    model.train()\n",
    "    tr_loss = 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    \n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        # add batch to gpu\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        inputs = {\"input_ids\": batch[0], \"attention_mask\": batch[1], \"labels\": batch[2]}\n",
    "        # forward pass\n",
    "        outputs = model(**inputs)\n",
    "        loss = outputs[0]\n",
    "#         loss = model(b_input_ids, token_type_ids=None,\n",
    "#                      attention_mask=b_input_mask, labels=b_labels)\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # track train loss\n",
    "        tr_loss += loss.item()\n",
    "        nb_tr_examples += b_input_ids.size(0)\n",
    "        nb_tr_steps += 1\n",
    "        \n",
    "        # gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=max_grad_norm)\n",
    "        \n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "#         scheduler.step()\n",
    "#         opt.step()\n",
    "        model.zero_grad()\n",
    "    \n",
    "    # print train loss per epoch\n",
    "    print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
    "#     opt.swap_swa_sgd()\n",
    "\n",
    "    # VALIDATION on validation set\n",
    "    model.eval()\n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "    predictions , true_labels = [], []\n",
    "    pred=[]\n",
    "    \n",
    "    for batch in (valid_dataloader):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        inputs = {\"input_ids\": batch[0], \"attention_mask\": batch[1], \"labels\": batch[2]}\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            tmp_eval_loss, logits = outputs[:2]\n",
    "#             tmp_eval_loss = model(b_input_ids, token_type_ids=None,\n",
    "#                                   attention_mask=b_input_mask, labels=b_labels)\n",
    "#             logits = model(b_input_ids, token_type_ids=None,\n",
    "#                            attention_mask=b_input_mask)\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        \n",
    "        #print(logits.shape)\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        predictions.extend([list(p) for p in np.argmax(logits, axis=2)])\n",
    "        #\n",
    "        pred.append(list(p) for p in np.argmax(logits, axis=2))\n",
    "        \n",
    "        #\n",
    "        true_labels.append(label_ids)\n",
    "        \n",
    "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
    "        \n",
    "        eval_loss += tmp_eval_loss.mean().item()\n",
    "        eval_accuracy += tmp_eval_accuracy\n",
    "        \n",
    "        nb_eval_examples += b_input_ids.size(0)\n",
    "        nb_eval_steps += 1\n",
    "    eval_loss = eval_loss/nb_eval_steps\n",
    "    \n",
    "    print(\"Validation loss: {}\".format(eval_loss))\n",
    "    print(\"Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps))\n",
    "    \n",
    "    pred_tags = [tags_vals[p_i] for p in predictions for p_i in p]\n",
    "    valid_tags = [tags_vals[l_ii] for l in true_labels for l_i in l for l_ii in l_i]\n",
    "    \n",
    "    torch.save(model.state_dict(), 'bert_uncased_attentionmask.pth')\n",
    "    \n",
    "    from sklearn.metrics import f1_score\n",
    "    tmp_f1=f1_score(pred_tags , valid_tags,average='macro')\n",
    "    if tmp_f1>tmp:\n",
    "        torch.save(model.state_dict(), 'bert_uncased_SI.pth')\n",
    "    print(\"F1-Score: {}\".format(f1_score(pred_tags , valid_tags,average='macro')))\n",
    "    \n",
    " \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/75 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bf20435b45d498590723abc66453cb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 9/75 [00:20<02:06,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Escaping empty dataframe :\n",
      "8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 23/75 [00:49<01:31,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Escaping empty dataframe :\n",
      "22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▊  | 59/75 [02:18<00:31,  1.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Escaping empty dataframe :\n",
      "58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75/75 [02:54<00:00,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(993, 3)\n",
      "(991, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Loading the model\n",
    "# model = BertForTokenClassification.from_pretrained(\"bert-base-uncased\", num_labels=len(tag2idx))    \n",
    "\n",
    "# model.load_state_dict(torch.load('/kaggle/output/bert-new/bert_uncased_SI.pth'))\n",
    "# model.load_state_dict(torch.load('/kaggle/working/bert-new/bert_uncased_SI.pth'))\n",
    "\n",
    "\n",
    "# model.cuda()\n",
    "\n",
    "\n",
    "\n",
    "# Fetching test data\n",
    "\n",
    "def text_preprocessing(text):\n",
    "    text= text.lower()\n",
    "    text= re.sub(r'[^a-z]',' ',text)\n",
    "    text= ' '.join(text.split())\n",
    "    return(text)\n",
    "def get_wordchar_indicies(sent):\n",
    "    k_l = list(sent)\n",
    "    k_l_b = [0 if i==' ' else 1 for i in k_l]\n",
    "    k_df = pd.DataFrame({'char':k_l, 'space_mark':k_l_b})\n",
    "    k_df = k_df.reset_index()\n",
    "    k_df['u1'] = k_df['space_mark'].diff()\n",
    "    k_df['u1'].fillna(1, inplace=True)\n",
    "    k_df.loc[k_df['u1']==1, 'u2']= k_df.loc[k_df['u1']==1, 'u1'].cumsum()\n",
    "    k_df.loc[k_df['u1']==-1, 'u2']= k_df.loc[k_df['u1']==-1, 'u1']\n",
    "    k_df['u2'] = k_df['u2'].ffill(axis=0)\n",
    "    k_df = k_df[k_df['u2']!=-1]\n",
    "    k_df_gb = pd.DataFrame(k_df.groupby(['u2'])['index'].min())\n",
    "    k_df_gb['last_index_word'] = k_df.groupby(['u2'])['index'].max()\n",
    "    k_df_gb = k_df_gb.reset_index().rename(columns={'u2':'word_index','index':'first_index_word'})\n",
    "    try:\n",
    "        k_df_gb['words'] = sent.split()\n",
    "    except:\n",
    "        print(k_df_gb, sent)\n",
    "    return k_df_gb\n",
    "\n",
    "def indices_sentence(article_id,path):\n",
    "    f= open(path + 'article' + str(article_id) + '.txt',\"r\")\n",
    "    indices={}\n",
    "    start_index = 0\n",
    "    for i, line in enumerate(f):\n",
    "        indices[i] = {}\n",
    "        indices[i]['article_id']=article_id\n",
    "        indices[i]['span_present'] = 0\n",
    "        indices[i]['sentence'] = line\n",
    "        indices[i]['start_index'] = start_index\n",
    "        indices[i]['end_index'] = start_index + len(line)\n",
    "        start_index = indices[i]['end_index']   \n",
    "        \n",
    "        if line == '\\n':\n",
    "            indices[i]['word_st_index'] = [0]\n",
    "            indices[i]['word_en_index'] = [0]\n",
    "        else:\n",
    "            wordchar_df = get_wordchar_indicies(line)\n",
    "            indices[i]['word_st_index'] = list(wordchar_df['first_index_word'])\n",
    "            indices[i]['word_en_index'] = list(wordchar_df['last_index_word'])        \n",
    "        \n",
    "    return indices\n",
    "def get_test_sentences(article_ids, dev_id, articles_path):\n",
    "    se_dict=indices_sentence(article_ids[dev_id],articles_path)\n",
    "    test_sent=[]\n",
    "    for i in range(len(se_dict)):\n",
    "                   test_sent.append(se_dict[i]['sentence'])\n",
    "    return se_dict, test_sent\n",
    "\n",
    "\n",
    "\n",
    "def prep_test_dataloader(article_ids, dev_id, articles_path):\n",
    "    se_dict,test_sentences=get_test_sentences(article_ids,dev_id,articles_path)\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "    \n",
    "    tokenized_test_sentences = [tokenizer.tokenize(sent) for sent in test_sentences]\n",
    "    input_test_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_test_sentences],\n",
    "                          maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "    attention_test_masks = [[float(i>0) for i in ii] for ii in input_test_ids]\n",
    "    test_inputs = torch.tensor(input_test_ids)\n",
    "\n",
    "    test_masks = torch.tensor(attention_test_masks)\n",
    "    test_data = TensorDataset(test_inputs, test_masks)\n",
    "\n",
    "    test_sampler = SequentialSampler(test_data)\n",
    "    test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=bs)\n",
    "    return test_dataloader,test_sentences\n",
    "\n",
    "\n",
    "\n",
    "bs=64\n",
    "MAX_LEN=128\n",
    "\n",
    "def inverse_reg_enco(sentences,labels_tok):\n",
    "    label_inverse=[]\n",
    "    for i,sent in enumerate(sentences) :\n",
    "        label_o=[]\n",
    "        word_count=0\n",
    "        tok_count=0\n",
    "        for word in sent.split():            \n",
    "            #print(word)\n",
    "            tok=tokenizer.tokenize(word)\n",
    "            tok_count=len(tok)+tok_count\n",
    "            #print(tok_count)\n",
    "            if tok_count>MAX_LEN:\n",
    "                break    \n",
    "            #print(word_count)\n",
    "            if len(tok)>1:\n",
    "                #print('True')\n",
    "                label_word_token=labels_tok[i][word_count:word_count+len(tok)]\n",
    "                #print(label_word_token)\n",
    "                if '1' in label_word_token:\n",
    "                    label_o.append('1')\n",
    "                else:\n",
    "                    label_o.append('0')\n",
    "                word_count=word_count+len(tok)\n",
    "            else:\n",
    "                #print(labels_tok[i][word_count])\n",
    "                label_o.append(labels_tok[i][word_count])\n",
    "                word_count=word_count+1    \n",
    "        label_inverse.append(label_o)\n",
    "    return label_inverse\n",
    "\n",
    "def thresh_logit(logits,thresh):\n",
    "    predictions_per_batch=[]\n",
    "    for i in range(logits.shape[0]):\n",
    "        predictions_per_sentence=[]\n",
    "        for j in range(logits.shape[1]):\n",
    "            if (np.argmax(logits[i][j])==1 and logits[i][j][1]>=thresh):\n",
    "                predictions_per_sentence.append(1)\n",
    "            else:\n",
    "                predictions_per_sentence.append(0)\n",
    "        predictions_per_batch.append(predictions_per_sentence)\n",
    "    return predictions_per_batch \n",
    "\n",
    "\n",
    "#from seqeval.metrics import f1_score\n",
    "def predict_bert(model,test_dataloader,test_sentences,thresh,threshold=False):\n",
    "    \n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    l=[]\n",
    "    #true_labels = []\n",
    "    #eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_steps, nb_eval_examples = 0, 0\n",
    "    for batch in test_dataloader:\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask = batch\n",
    "        inputs = {\"input_ids\": batch[0], \"attention_mask\": batch[1]}\n",
    "        with torch.no_grad():\n",
    "            #tmp_eval_loss = model(b_input_ids, token_type_ids=None,\n",
    "            #                      attention_mask=b_input_mask, labels=b_labels)\n",
    "#             logits = model(b_input_ids, token_type_ids=None,\n",
    "#                            attention_mask=b_input_mask)\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs[0]\n",
    "            \n",
    "\n",
    "        m=torch.nn.Softmax(dim=2)\n",
    "        logits_softmax=m(logits)\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        logits_softmax = logits_softmax.detach().cpu().numpy()\n",
    "        #print(logits.shape)\n",
    "        #print(logits_softmax.shape)\n",
    "        #l.extend(logits_softmax)\n",
    "        if threshold:\n",
    "            predictions_per_batch=thresh_logit(logits,thresh)\n",
    "            predictions.extend(predictions_per_batch)\n",
    "        else:\n",
    "            predictions.extend([list(p) for p in np.argmax(logits, axis=2)])\n",
    "            \n",
    "        nb_eval_examples += b_input_ids.size(0)\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "    pred_tags = [[tags_vals[p_i] for p_i in p] for p in predictions]\n",
    "    pred_tags_l=inverse_reg_enco(test_sentences,pred_tags)\n",
    "    padded_pred_tags_l=pad_sequences([[tag2idx.get(l) for l in lab] for lab in pred_tags_l],\n",
    "                     maxlen=MAX_LEN, value = tag2idx['0'], padding=\"post\",\n",
    "                     dtype=\"long\", truncating=\"post\")\n",
    "    return padded_pred_tags_l,pred_tags\n",
    "\n",
    "\n",
    "def get_spans_article(article_ids, dev_id, articles_path,padded_pred_tags_l):\n",
    "    pad_style='Post'\n",
    "    spangaps_to_merge = [1, 2]\n",
    "    def get_truewordindex(wi, sl):\n",
    "        if sl>=max_len:\n",
    "            return wi\n",
    "        else:\n",
    "            return wi-(max_len-sl)\n",
    "    ar=np.array(padded_pred_tags_l)\n",
    "    #print(padded_pred_tags_l.shape)\n",
    "    a,b=np.where(ar==1)\n",
    "    \n",
    "    df_pred=pd.DataFrame({'sent_id':a,'word_index':b})\n",
    "    #print(len(df_pred))\n",
    "    meta_dict, test_sentences= get_test_sentences(article_ids, dev_id, articles_path)\n",
    "    org_sent_len = len(test_sentences)\n",
    "\n",
    "    len_sentence={i:len(test_sentences[i].split()) for i in range(len(test_sentences))}\n",
    "    #print(len_sentence)\n",
    "    df_pred['sent_length']=df_pred['sent_id'].map(len_sentence)\n",
    "    df_pred = df_pred[df_pred['sent_id']<org_sent_len]\n",
    "\n",
    "    # if len(df_pred)==0:\n",
    "    #     return df_pred, df_pred, df_pred\n",
    "    # df_pred['true_word_index']=df_pred['word_index']-(max_len-df_pred['sent_length'])\n",
    "    if pad_style == 'pre':\n",
    "        df_pred['true_word_index'] = list(map(lambda x, y: get_truewordindex(x, y) , \n",
    "                                          df_pred['word_index'], df_pred['sent_length']))\n",
    "    else:\n",
    "        df_pred['true_word_index'] = df_pred['word_index'].values\n",
    "    #print(df_pred)\n",
    "    df_pred = df_pred[~(df_pred['true_word_index']>=df_pred['sent_length'])] \n",
    "    \n",
    "    #print(len(df_pred))\n",
    "    df_pred['diff_pred']=df_pred.groupby(['sent_id'])['true_word_index'].diff()\n",
    "    df_pred['diff_pred'] = df_pred['diff_pred'].apply(\n",
    "                        lambda x:-1 if x in spangaps_to_merge else np.nan)\n",
    "    #print (len(df_pred))\n",
    "    #print(df_pred)\n",
    "    if len(df_pred)<1:\n",
    "        print(\"Escaping empty dataframe :\")\n",
    "        print(dev_id)\n",
    "        submsn_df=pd.DataFrame()\n",
    "        sent_pred=pd.DataFrame()\n",
    "        return df_pred, sent_pred, submsn_df\n",
    "        pass\n",
    "        \n",
    "    else:\n",
    "        df_pred.loc[df_pred['diff_pred'].isnull(), 'diff_pred_1'] = \\\n",
    "                    df_pred.groupby(['sent_id'])['diff_pred'].cumcount()\n",
    "        df_pred['diff_pred_1'] = df_pred['diff_pred_1'].ffill(axis=0)\n",
    "        df_pred['span_id'] = list(map(lambda x, y: str(int(x)) + '_' + str(int(y)), \n",
    "                                      df_pred['sent_id'], df_pred['diff_pred_1']))\n",
    "        # req_cols = ['sent_id', 'word_index', 'sent_length', 'true_word_index', 'span_id']\n",
    "        # df_pred = df_pred[req_cols]\n",
    "        # df_pred.loc[df_pred['true_word_index']==-1, 'true_word_index'] = 0\n",
    "        sent_pred = pd.DataFrame(df_pred.groupby(['sent_id', 'span_id'])['true_word_index'].min())\n",
    "        sent_pred['span_max_word_index'] = df_pred.groupby(['sent_id', 'span_id'])['true_word_index'].max()\n",
    "        sent_pred = sent_pred.rename(columns={'true_word_index':'span_min_word_index'}).reset_index()\n",
    "        #print(sent_pred)\n",
    "        submsn_df = pd.DataFrame()\n",
    "        for i, _id in enumerate(sent_pred['span_id'].tolist()):\n",
    "            #print(_id)\n",
    "            submsn_df.loc[i, 'article_id'] = article_ids[dev_id]\n",
    "            span_min_word = sent_pred.loc[sent_pred['span_id']==_id, 'span_min_word_index'].values[0]\n",
    "            #print(span_min_word)\n",
    "            span_max_word = sent_pred.loc[sent_pred['span_id']==_id, 'span_max_word_index'].values[0]\n",
    "            #print(span_max_word)\n",
    "            sentence_id = int(_id.split('_')[0])\n",
    "            sent_start_index = meta_dict[sentence_id]['start_index']\n",
    "            try:\n",
    "                submsn_df.loc[i, 'span_start'] = sent_start_index + meta_dict[sentence_id]['word_st_index'][span_min_word]\n",
    "                submsn_df.loc[i, 'span_end'] = sent_start_index + meta_dict[sentence_id]['word_en_index'][span_max_word]\n",
    "                \n",
    "                \n",
    "                \n",
    "            except:\n",
    "                print(\"Escaping submsn_df :\" )\n",
    "                print(dev_id,_id)\n",
    "\n",
    "        return df_pred, sent_pred, submsn_df\n",
    "\n",
    "\n",
    "import os\n",
    "dev_articles_path = '/kaggle/input/devarticles/dev-articles/'\n",
    "dev_article_ids = [int(file.replace('article', '').replace('.txt', '')) for file in os.listdir(dev_articles_path)]\n",
    "thresh=0.8\n",
    "main_span_df = pd.DataFrame()\n",
    "for dev_id in tqdm(range(len(dev_article_ids))):\n",
    "    test_dataloader,test_sentences=prep_test_dataloader(dev_article_ids, dev_id, dev_articles_path)\n",
    "    padded_pred_tags_l,_=predict_bert(model,test_dataloader,test_sentences,thresh,threshold=False)\n",
    "    a, s,submsn_df = get_spans_article(dev_article_ids, dev_id, dev_articles_path,padded_pred_tags_l)\n",
    "    #print(dev_id)\n",
    "    #print(len(submsn_df))\n",
    "    main_span_df = pd.concat([main_span_df,submsn_df],sort=False,axis=0)\n",
    "print(main_span_df.shape)\n",
    "\n",
    "mdf=main_span_df[(main_span_df['span_end']>main_span_df['span_start'])]\n",
    "print(mdf.shape)\n",
    "\n",
    "_sub_ver='0'\n",
    "np.savetxt('bert_submsn'+str(_sub_ver)+'.txt',mdf.values, fmt='%d', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0751daed476040868a0e222bff34928f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_8aed42e807f1492087896ffdb0bb0ef2",
        "IPY_MODEL_6ac79747b0a04eda87da1aa768820001"
       ],
       "layout": "IPY_MODEL_56aaaea73021494e91452726a10e96b0"
      }
     },
     "0c3d257d9b0943f5baafdbcd6fcfd3a5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "0f73449cca134091890c80faaea1e03c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "Downloading: 100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_a1065900629d499493725f036f099e72",
       "max": 362,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_4617b17d0e134d82957b76fbcd051681",
       "value": 362
      }
     },
     "13c355e9b4d9483aa2e7cba2647d18f9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "30e2dfb787484f1180a2bc350497f633": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3bf20435b45d498590723abc66453cb1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_4bc1b1728bd0432e8a0cc68df0bab6a1",
        "IPY_MODEL_cf84576a49384f0b941b0ba0f794bb7b"
       ],
       "layout": "IPY_MODEL_bc8cc4b63dab44d59c056966bb954f8a"
      }
     },
     "3ef436732f764919a1fc8f5968d67dc7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "Downloading: 100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_e689956e5267496cb63a70958b4c9edf",
       "max": 1344997306,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_681b733e111e49b793a8c4f411781ae6",
       "value": 1344997306
      }
     },
     "4617b17d0e134d82957b76fbcd051681": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "4bc1b1728bd0432e8a0cc68df0bab6a1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "Downloading: 100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_ca0139870e6d408992384bafb3119549",
       "max": 231508,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_9b971580660d4b459ec633b4a381f9e4",
       "value": 231508
      }
     },
     "56aaaea73021494e91452726a10e96b0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "681b733e111e49b793a8c4f411781ae6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "6839233aa1a0404098d7ab6d10cd7edb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6ac79747b0a04eda87da1aa768820001": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_8c83c5f3c5574763bd1d626df6969436",
       "placeholder": "​",
       "style": "IPY_MODEL_b35d5d94b4ea4bf39613c53bd8a80aad",
       "value": " 232k/232k [00:00&lt;00:00, 2.53MB/s]"
      }
     },
     "824e26b5c4184bf8a9cd98a435db6d5a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "88a90609e8574c8181ce5a1204696e5b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_0f73449cca134091890c80faaea1e03c",
        "IPY_MODEL_b4261c04c0ae418b9dc2caa6f8514194"
       ],
       "layout": "IPY_MODEL_a8560d17255248e4a059ee4c35f4fe5a"
      }
     },
     "8aed42e807f1492087896ffdb0bb0ef2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "Downloading: 100%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_aa8ecb0ae9be469d9cbb94eab2ecd447",
       "max": 231508,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_8e0a3e3f0607448d85acc2e3e27c6b6a",
       "value": 231508
      }
     },
     "8c83c5f3c5574763bd1d626df6969436": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8e0a3e3f0607448d85acc2e3e27c6b6a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "948132d79a42432fb352c756f6ce4837": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9b971580660d4b459ec633b4a381f9e4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     },
     "a1065900629d499493725f036f099e72": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a8560d17255248e4a059ee4c35f4fe5a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "aa8ecb0ae9be469d9cbb94eab2ecd447": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b35d5d94b4ea4bf39613c53bd8a80aad": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "b4261c04c0ae418b9dc2caa6f8514194": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_30e2dfb787484f1180a2bc350497f633",
       "placeholder": "​",
       "style": "IPY_MODEL_bad72788ed1143cfb6b746d668bb9311",
       "value": " 362/362 [00:00&lt;00:00, 1.63kB/s]"
      }
     },
     "bad72788ed1143cfb6b746d668bb9311": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "bc8cc4b63dab44d59c056966bb954f8a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ca0139870e6d408992384bafb3119549": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cf84576a49384f0b941b0ba0f794bb7b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_13c355e9b4d9483aa2e7cba2647d18f9",
       "placeholder": "​",
       "style": "IPY_MODEL_824e26b5c4184bf8a9cd98a435db6d5a",
       "value": " 232k/232k [00:00&lt;00:00, 2.16MB/s]"
      }
     },
     "d5a8178494e642379907453bb389c1f5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_3ef436732f764919a1fc8f5968d67dc7",
        "IPY_MODEL_f8b25cc61b9349fba1926a62b1841226"
       ],
       "layout": "IPY_MODEL_6839233aa1a0404098d7ab6d10cd7edb"
      }
     },
     "e689956e5267496cb63a70958b4c9edf": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f8b25cc61b9349fba1926a62b1841226": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_948132d79a42432fb352c756f6ce4837",
       "placeholder": "​",
       "style": "IPY_MODEL_0c3d257d9b0943f5baafdbcd6fcfd3a5",
       "value": " 1.34G/1.34G [00:34&lt;00:00, 38.9MB/s]"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

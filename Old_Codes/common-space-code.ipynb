{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image similarity for product recommendation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First step, importing all necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.layers import Dense, Input, Flatten, Bidirectional, GRU, SpatialDropout1D, Embedding, GlobalAveragePooling1D, GlobalMaxPooling1D, concatenate\n",
    "        \n",
    "        \n",
    "\n",
    "from tensorflow.keras.preprocessing.image import load_img,img_to_array\n",
    "from tensorflow.keras.applications.resnet import preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>masterCategory</th>\n",
       "      <th>subCategory</th>\n",
       "      <th>articleType</th>\n",
       "      <th>baseColour</th>\n",
       "      <th>season</th>\n",
       "      <th>year</th>\n",
       "      <th>usage</th>\n",
       "      <th>productDisplayName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15970</td>\n",
       "      <td>Men</td>\n",
       "      <td>Apparel</td>\n",
       "      <td>Topwear</td>\n",
       "      <td>Shirts</td>\n",
       "      <td>Navy Blue</td>\n",
       "      <td>Fall</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Turtle Check Men Navy Blue Shirt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39386</td>\n",
       "      <td>Men</td>\n",
       "      <td>Apparel</td>\n",
       "      <td>Bottomwear</td>\n",
       "      <td>Jeans</td>\n",
       "      <td>Blue</td>\n",
       "      <td>Summer</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Peter England Men Party Blue Jeans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59263</td>\n",
       "      <td>Women</td>\n",
       "      <td>Accessories</td>\n",
       "      <td>Watches</td>\n",
       "      <td>Watches</td>\n",
       "      <td>Silver</td>\n",
       "      <td>Winter</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Titan Women Silver Watch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21379</td>\n",
       "      <td>Men</td>\n",
       "      <td>Apparel</td>\n",
       "      <td>Bottomwear</td>\n",
       "      <td>Track Pants</td>\n",
       "      <td>Black</td>\n",
       "      <td>Fall</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Manchester United Men Solid Black Track Pants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>53759</td>\n",
       "      <td>Men</td>\n",
       "      <td>Apparel</td>\n",
       "      <td>Topwear</td>\n",
       "      <td>Tshirts</td>\n",
       "      <td>Grey</td>\n",
       "      <td>Summer</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>Casual</td>\n",
       "      <td>Puma Men Grey T-shirt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id gender masterCategory subCategory  articleType baseColour  season  \\\n",
       "0  15970    Men        Apparel     Topwear       Shirts  Navy Blue    Fall   \n",
       "1  39386    Men        Apparel  Bottomwear        Jeans       Blue  Summer   \n",
       "2  59263  Women    Accessories     Watches      Watches     Silver  Winter   \n",
       "3  21379    Men        Apparel  Bottomwear  Track Pants      Black    Fall   \n",
       "4  53759    Men        Apparel     Topwear      Tshirts       Grey  Summer   \n",
       "\n",
       "     year   usage                             productDisplayName  \n",
       "0  2011.0  Casual               Turtle Check Men Navy Blue Shirt  \n",
       "1  2012.0  Casual             Peter England Men Party Blue Jeans  \n",
       "2  2016.0  Casual                       Titan Women Silver Watch  \n",
       "3  2011.0  Casual  Manchester United Men Solid Black Track Pants  \n",
       "4  2012.0  Casual                          Puma Men Grey T-shirt  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/kaggle/input/fashion-product-images-dataset/fashion-dataset/fashion-dataset/styles.csv\", \n",
    "                 error_bad_lines = False, \n",
    "                 warn_bad_lines=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                      0\n",
       "gender                  0\n",
       "masterCategory          0\n",
       "subCategory             0\n",
       "articleType             0\n",
       "baseColour             15\n",
       "season                 21\n",
       "year                    1\n",
       "usage                 317\n",
       "productDisplayName      7\n",
       "dtype: int64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44424, 10)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                      0\n",
       "gender                  0\n",
       "masterCategory          0\n",
       "subCategory             0\n",
       "articleType             0\n",
       "baseColour             10\n",
       "season                 21\n",
       "year                    1\n",
       "usage                 312\n",
       "productDisplayName      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[df['productDisplayName'].notna()]\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGES_PATH = \"/kaggle/input/fashion-product-images-dataset/fashion-dataset/fashion-dataset/images/\"\n",
    "\n",
    "df['id'] = df['id'].apply(lambda x: IMAGES_PATH+str(x) +'.jpg')\n",
    "image_ids = df.pop('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rows = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10000it [07:20, 22.69it/s]\n"
     ]
    }
   ],
   "source": [
    "IMAGE_DIMS = (64, 64, 3)\n",
    "\n",
    "def load_image(path):\n",
    "    image = cv2.imread(path)\n",
    "    image = cv2.resize(image, (IMAGE_DIMS[1], IMAGE_DIMS[0]))\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = preprocess_input(image)\n",
    "    return image\n",
    "\n",
    "image_data = []\n",
    "failed = []\n",
    "\n",
    "for i, img_path in tqdm(enumerate(image_ids[:n_rows])):\n",
    "    try:\n",
    "        image_data.append(load_image(img_path))\n",
    "    except:\n",
    "        failed.append(i)\n",
    "        continue\n",
    "    \n",
    "image_data = np.array(image_data, dtype=\"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = df[\"productDisplayName\"].tolist()[:n_rows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6694]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fail in failed:\n",
    "    del titles[fail]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[187, 2, 37, 13]\n",
      "[116 117   1 831   5  64   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=25000)\n",
    "tokenizer.fit_on_texts(titles)\n",
    "\n",
    "titles_train = tokenizer.texts_to_sequences(titles)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1  # Adding 1 because of reserved 0 index\n",
    "print(titles_train[2])\n",
    "\n",
    "maxlen = 25\n",
    "\n",
    "titles_train_padded = pad_sequences(titles_train, padding='post', maxlen=maxlen)\n",
    "print(titles_train_padded[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "#### shuffling the exsiting data and getting the negative samples.. pretty naive approach which can be improved. \n",
    "titles_neg= titles_train_padded.copy()\n",
    "image_data_neg = image_data.copy()\n",
    "\n",
    "random.shuffle(titles_neg)\n",
    "random.shuffle(image_data_neg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9999, 64, 64, 3)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_data_neg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9999, 25)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "titles_neg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_train = list(image_data) + list(image_data_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_train = list(titles_train_padded) + list(titles_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "res50 = ResNet50(weights='imagenet', \n",
    "                 include_top=False, \n",
    "                 input_shape=IMAGE_DIMS)\n",
    "\n",
    "res50.trainable=False\n",
    "\n",
    "image_input = Input(shape=IMAGE_DIMS)\n",
    "x = res50(image_input, training=False)\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "\n",
    "\n",
    "sequence_input = Input(shape=(maxlen, ))\n",
    "z = Embedding(vocab_size, \n",
    "              50,\n",
    "              trainable = False)(sequence_input)\n",
    "\n",
    "z = SpatialDropout1D(0.5)(z)\n",
    "z = Bidirectional(GRU(32, \n",
    "                        return_sequences=True,\n",
    "                        dropout=0.1,\n",
    "                        recurrent_dropout=0.1))(z)\n",
    "\n",
    "avg_pool = GlobalAveragePooling1D()(z)\n",
    "max_pool = GlobalMaxPooling1D()(z)\n",
    "\n",
    "z = concatenate([avg_pool, max_pool])\n",
    "z = Dense(128, activation='relu')(z)\n",
    "\n",
    "\n",
    "### projectting to common space.\n",
    "common = Dense(64, activation='relu')\n",
    "x_s = common(x)\n",
    "z_s = common(z)\n",
    "\n",
    "### we can try with dot product of x_s and x_z \n",
    "\n",
    "conc = concatenate([x_s, z_s]) \n",
    "output = Dense(1, activation=\"sigmoid\")(conc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs = [image_input, sequence_input], outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_12 (InputLayer)           [(None, 25)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 25, 50)       200000      input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "spatial_dropout1d_3 (SpatialDro (None, 25, 50)       0           embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "input_11 (InputLayer)           [(None, 64, 64, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, 25, 64)       16128       spatial_dropout1d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "resnet50 (Model)                (None, 2, 2, 2048)   23587712    input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_3 (Glo (None, 64)           0           bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_3 (GlobalM (None, 64)           0           bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 8192)         0           resnet50[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 128)          0           global_average_pooling1d_3[0][0] \n",
      "                                                                 global_max_pooling1d_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 128)          1048704     flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 128)          16512       concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 64)           8256        dense_12[0][0]                   \n",
      "                                                                 dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 128)          0           dense_14[0][0]                   \n",
      "                                                                 dense_14[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 1)            129         concatenate_7[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 24,877,441\n",
      "Trainable params: 1,089,729\n",
      "Non-trainable params: 23,787,712\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [1] * len(titles_train_padded)  + [0] * len(titles_train_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19998, 19998, 19998)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(im_train), len(titles_train), len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17998 samples, validate on 2000 samples\n",
      "Epoch 1/10\n",
      "17998/17998 [==============================] - 176s 10ms/sample - loss: 0.7371 - accuracy: 0.5267 - val_loss: 0.7444 - val_accuracy: 0.4250\n",
      "Epoch 2/10\n",
      "17998/17998 [==============================] - 166s 9ms/sample - loss: 0.6941 - accuracy: 0.5505 - val_loss: 0.8400 - val_accuracy: 0.1635\n",
      "Epoch 3/10\n",
      "17998/17998 [==============================] - 166s 9ms/sample - loss: 0.6868 - accuracy: 0.5613 - val_loss: 0.7699 - val_accuracy: 0.1445\n",
      "Epoch 4/10\n",
      " 7072/17998 [==========>...................] - ETA: 1:31 - loss: 0.6800 - accuracy: 0.5748"
     ]
    }
   ],
   "source": [
    "model.fit([np.array(im_train), np.array(titles_train)], \n",
    "          np.array(y), \n",
    "          validation_split=0.1, \n",
    "          shuffle=True, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
